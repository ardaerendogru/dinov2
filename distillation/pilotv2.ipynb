{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYOBU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/disk0/arda/dinov2/distillation/../../dinov2/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/storage/disk0/arda/dinov2/distillation/../../dinov2/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/storage/disk0/arda/dinov2/distillation/../../dinov2/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "from models import DINOv2ViT, CustomResNet\n",
    "import torch\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/arda/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "teacher = DINOv2ViT().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arda/miniconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage_data_ptr = tensors[0].storage().data_ptr()\n",
      "/home/arda/miniconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if x.storage().data_ptr() != storage_data_ptr:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536, 16, 16])\n",
      "Matched Features Shape: torch.Size([1, 1536, 16, 16])\n",
      "Shape of 'res5' feature map: torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "out = teacher(x)\n",
    "print(out[\"patch_embeddings\"].shape)\n",
    "print(out[\"embedding\"].shape)\n",
    "print(out[\"feature_map\"].shape)\n",
    "\n",
    "# tests/test_resnet.py\n",
    "import torch\n",
    "from models.resnet import ResNet, BasicStem, BottleneckBlock, make_resnet_stages\n",
    "\n",
    "import torch\n",
    "from models.student_model_wrapper import ModelWrapper\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Sample input\n",
    "x = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Feature matcher configuration (customize as needed)\n",
    "feature_matcher_config = {\n",
    "    'in_channels': 2048,\n",
    "    'out_channels': 1536,\n",
    "    'kernel_size': 1,\n",
    "    'stride': 1,\n",
    "    'padding': 0,\n",
    "    'activation': 'ReLU'  # Options: 'ReLU', 'LeakyReLU', etc.\n",
    "}\n",
    "\n",
    "# Initialize the ModelWrapper with desired parameters\n",
    "model_wrapper = ModelWrapper(\n",
    "    model_type='resnet',\n",
    "    model_depth=50,\n",
    "    block_class=BottleneckBlock,\n",
    "    norm_type='BN',\n",
    "    in_channels=3,\n",
    "    feature_matcher_config=feature_matcher_config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Forward pass through the wrapper\n",
    "matched_features, student_output = model_wrapper(x)\n",
    "\n",
    "# Display the shape of the matched features\n",
    "if matched_features is not None:\n",
    "    print(f\"Matched Features Shape: {matched_features.shape}\")\n",
    "else:\n",
    "    print(\"Feature Matcher is not configured.\")\n",
    "\n",
    "# Optionally, get the shape of 'res5' feature map\n",
    "res5_shape = model_wrapper.get_feature_map_shape(x, feature_key='res5')\n",
    "print(f\"Shape of 'res5' feature map: {res5_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['student.stem.conv1.weight', 'student.stem.conv1.norm.weight', 'student.stem.conv1.norm.bias', 'student.stem.conv1.norm.running_mean', 'student.stem.conv1.norm.running_var', 'student.stem.conv1.norm.num_batches_tracked', 'student.res2.0.shortcut.weight', 'student.res2.0.shortcut.norm.weight', 'student.res2.0.shortcut.norm.bias', 'student.res2.0.shortcut.norm.running_mean', 'student.res2.0.shortcut.norm.running_var', 'student.res2.0.shortcut.norm.num_batches_tracked', 'student.res2.0.conv1.weight', 'student.res2.0.conv1.norm.weight', 'student.res2.0.conv1.norm.bias', 'student.res2.0.conv1.norm.running_mean', 'student.res2.0.conv1.norm.running_var', 'student.res2.0.conv1.norm.num_batches_tracked', 'student.res2.0.conv2.weight', 'student.res2.0.conv2.norm.weight', 'student.res2.0.conv2.norm.bias', 'student.res2.0.conv2.norm.running_mean', 'student.res2.0.conv2.norm.running_var', 'student.res2.0.conv2.norm.num_batches_tracked', 'student.res2.0.conv3.weight', 'student.res2.0.conv3.norm.weight', 'student.res2.0.conv3.norm.bias', 'student.res2.0.conv3.norm.running_mean', 'student.res2.0.conv3.norm.running_var', 'student.res2.0.conv3.norm.num_batches_tracked', 'student.res2.1.conv1.weight', 'student.res2.1.conv1.norm.weight', 'student.res2.1.conv1.norm.bias', 'student.res2.1.conv1.norm.running_mean', 'student.res2.1.conv1.norm.running_var', 'student.res2.1.conv1.norm.num_batches_tracked', 'student.res2.1.conv2.weight', 'student.res2.1.conv2.norm.weight', 'student.res2.1.conv2.norm.bias', 'student.res2.1.conv2.norm.running_mean', 'student.res2.1.conv2.norm.running_var', 'student.res2.1.conv2.norm.num_batches_tracked', 'student.res2.1.conv3.weight', 'student.res2.1.conv3.norm.weight', 'student.res2.1.conv3.norm.bias', 'student.res2.1.conv3.norm.running_mean', 'student.res2.1.conv3.norm.running_var', 'student.res2.1.conv3.norm.num_batches_tracked', 'student.res2.2.conv1.weight', 'student.res2.2.conv1.norm.weight', 'student.res2.2.conv1.norm.bias', 'student.res2.2.conv1.norm.running_mean', 'student.res2.2.conv1.norm.running_var', 'student.res2.2.conv1.norm.num_batches_tracked', 'student.res2.2.conv2.weight', 'student.res2.2.conv2.norm.weight', 'student.res2.2.conv2.norm.bias', 'student.res2.2.conv2.norm.running_mean', 'student.res2.2.conv2.norm.running_var', 'student.res2.2.conv2.norm.num_batches_tracked', 'student.res2.2.conv3.weight', 'student.res2.2.conv3.norm.weight', 'student.res2.2.conv3.norm.bias', 'student.res2.2.conv3.norm.running_mean', 'student.res2.2.conv3.norm.running_var', 'student.res2.2.conv3.norm.num_batches_tracked', 'student.res3.0.shortcut.weight', 'student.res3.0.shortcut.norm.weight', 'student.res3.0.shortcut.norm.bias', 'student.res3.0.shortcut.norm.running_mean', 'student.res3.0.shortcut.norm.running_var', 'student.res3.0.shortcut.norm.num_batches_tracked', 'student.res3.0.conv1.weight', 'student.res3.0.conv1.norm.weight', 'student.res3.0.conv1.norm.bias', 'student.res3.0.conv1.norm.running_mean', 'student.res3.0.conv1.norm.running_var', 'student.res3.0.conv1.norm.num_batches_tracked', 'student.res3.0.conv2.weight', 'student.res3.0.conv2.norm.weight', 'student.res3.0.conv2.norm.bias', 'student.res3.0.conv2.norm.running_mean', 'student.res3.0.conv2.norm.running_var', 'student.res3.0.conv2.norm.num_batches_tracked', 'student.res3.0.conv3.weight', 'student.res3.0.conv3.norm.weight', 'student.res3.0.conv3.norm.bias', 'student.res3.0.conv3.norm.running_mean', 'student.res3.0.conv3.norm.running_var', 'student.res3.0.conv3.norm.num_batches_tracked', 'student.res3.1.conv1.weight', 'student.res3.1.conv1.norm.weight', 'student.res3.1.conv1.norm.bias', 'student.res3.1.conv1.norm.running_mean', 'student.res3.1.conv1.norm.running_var', 'student.res3.1.conv1.norm.num_batches_tracked', 'student.res3.1.conv2.weight', 'student.res3.1.conv2.norm.weight', 'student.res3.1.conv2.norm.bias', 'student.res3.1.conv2.norm.running_mean', 'student.res3.1.conv2.norm.running_var', 'student.res3.1.conv2.norm.num_batches_tracked', 'student.res3.1.conv3.weight', 'student.res3.1.conv3.norm.weight', 'student.res3.1.conv3.norm.bias', 'student.res3.1.conv3.norm.running_mean', 'student.res3.1.conv3.norm.running_var', 'student.res3.1.conv3.norm.num_batches_tracked', 'student.res3.2.conv1.weight', 'student.res3.2.conv1.norm.weight', 'student.res3.2.conv1.norm.bias', 'student.res3.2.conv1.norm.running_mean', 'student.res3.2.conv1.norm.running_var', 'student.res3.2.conv1.norm.num_batches_tracked', 'student.res3.2.conv2.weight', 'student.res3.2.conv2.norm.weight', 'student.res3.2.conv2.norm.bias', 'student.res3.2.conv2.norm.running_mean', 'student.res3.2.conv2.norm.running_var', 'student.res3.2.conv2.norm.num_batches_tracked', 'student.res3.2.conv3.weight', 'student.res3.2.conv3.norm.weight', 'student.res3.2.conv3.norm.bias', 'student.res3.2.conv3.norm.running_mean', 'student.res3.2.conv3.norm.running_var', 'student.res3.2.conv3.norm.num_batches_tracked', 'student.res3.3.conv1.weight', 'student.res3.3.conv1.norm.weight', 'student.res3.3.conv1.norm.bias', 'student.res3.3.conv1.norm.running_mean', 'student.res3.3.conv1.norm.running_var', 'student.res3.3.conv1.norm.num_batches_tracked', 'student.res3.3.conv2.weight', 'student.res3.3.conv2.norm.weight', 'student.res3.3.conv2.norm.bias', 'student.res3.3.conv2.norm.running_mean', 'student.res3.3.conv2.norm.running_var', 'student.res3.3.conv2.norm.num_batches_tracked', 'student.res3.3.conv3.weight', 'student.res3.3.conv3.norm.weight', 'student.res3.3.conv3.norm.bias', 'student.res3.3.conv3.norm.running_mean', 'student.res3.3.conv3.norm.running_var', 'student.res3.3.conv3.norm.num_batches_tracked', 'student.res4.0.shortcut.weight', 'student.res4.0.shortcut.norm.weight', 'student.res4.0.shortcut.norm.bias', 'student.res4.0.shortcut.norm.running_mean', 'student.res4.0.shortcut.norm.running_var', 'student.res4.0.shortcut.norm.num_batches_tracked', 'student.res4.0.conv1.weight', 'student.res4.0.conv1.norm.weight', 'student.res4.0.conv1.norm.bias', 'student.res4.0.conv1.norm.running_mean', 'student.res4.0.conv1.norm.running_var', 'student.res4.0.conv1.norm.num_batches_tracked', 'student.res4.0.conv2.weight', 'student.res4.0.conv2.norm.weight', 'student.res4.0.conv2.norm.bias', 'student.res4.0.conv2.norm.running_mean', 'student.res4.0.conv2.norm.running_var', 'student.res4.0.conv2.norm.num_batches_tracked', 'student.res4.0.conv3.weight', 'student.res4.0.conv3.norm.weight', 'student.res4.0.conv3.norm.bias', 'student.res4.0.conv3.norm.running_mean', 'student.res4.0.conv3.norm.running_var', 'student.res4.0.conv3.norm.num_batches_tracked', 'student.res4.1.conv1.weight', 'student.res4.1.conv1.norm.weight', 'student.res4.1.conv1.norm.bias', 'student.res4.1.conv1.norm.running_mean', 'student.res4.1.conv1.norm.running_var', 'student.res4.1.conv1.norm.num_batches_tracked', 'student.res4.1.conv2.weight', 'student.res4.1.conv2.norm.weight', 'student.res4.1.conv2.norm.bias', 'student.res4.1.conv2.norm.running_mean', 'student.res4.1.conv2.norm.running_var', 'student.res4.1.conv2.norm.num_batches_tracked', 'student.res4.1.conv3.weight', 'student.res4.1.conv3.norm.weight', 'student.res4.1.conv3.norm.bias', 'student.res4.1.conv3.norm.running_mean', 'student.res4.1.conv3.norm.running_var', 'student.res4.1.conv3.norm.num_batches_tracked', 'student.res4.2.conv1.weight', 'student.res4.2.conv1.norm.weight', 'student.res4.2.conv1.norm.bias', 'student.res4.2.conv1.norm.running_mean', 'student.res4.2.conv1.norm.running_var', 'student.res4.2.conv1.norm.num_batches_tracked', 'student.res4.2.conv2.weight', 'student.res4.2.conv2.norm.weight', 'student.res4.2.conv2.norm.bias', 'student.res4.2.conv2.norm.running_mean', 'student.res4.2.conv2.norm.running_var', 'student.res4.2.conv2.norm.num_batches_tracked', 'student.res4.2.conv3.weight', 'student.res4.2.conv3.norm.weight', 'student.res4.2.conv3.norm.bias', 'student.res4.2.conv3.norm.running_mean', 'student.res4.2.conv3.norm.running_var', 'student.res4.2.conv3.norm.num_batches_tracked', 'student.res4.3.conv1.weight', 'student.res4.3.conv1.norm.weight', 'student.res4.3.conv1.norm.bias', 'student.res4.3.conv1.norm.running_mean', 'student.res4.3.conv1.norm.running_var', 'student.res4.3.conv1.norm.num_batches_tracked', 'student.res4.3.conv2.weight', 'student.res4.3.conv2.norm.weight', 'student.res4.3.conv2.norm.bias', 'student.res4.3.conv2.norm.running_mean', 'student.res4.3.conv2.norm.running_var', 'student.res4.3.conv2.norm.num_batches_tracked', 'student.res4.3.conv3.weight', 'student.res4.3.conv3.norm.weight', 'student.res4.3.conv3.norm.bias', 'student.res4.3.conv3.norm.running_mean', 'student.res4.3.conv3.norm.running_var', 'student.res4.3.conv3.norm.num_batches_tracked', 'student.res4.4.conv1.weight', 'student.res4.4.conv1.norm.weight', 'student.res4.4.conv1.norm.bias', 'student.res4.4.conv1.norm.running_mean', 'student.res4.4.conv1.norm.running_var', 'student.res4.4.conv1.norm.num_batches_tracked', 'student.res4.4.conv2.weight', 'student.res4.4.conv2.norm.weight', 'student.res4.4.conv2.norm.bias', 'student.res4.4.conv2.norm.running_mean', 'student.res4.4.conv2.norm.running_var', 'student.res4.4.conv2.norm.num_batches_tracked', 'student.res4.4.conv3.weight', 'student.res4.4.conv3.norm.weight', 'student.res4.4.conv3.norm.bias', 'student.res4.4.conv3.norm.running_mean', 'student.res4.4.conv3.norm.running_var', 'student.res4.4.conv3.norm.num_batches_tracked', 'student.res4.5.conv1.weight', 'student.res4.5.conv1.norm.weight', 'student.res4.5.conv1.norm.bias', 'student.res4.5.conv1.norm.running_mean', 'student.res4.5.conv1.norm.running_var', 'student.res4.5.conv1.norm.num_batches_tracked', 'student.res4.5.conv2.weight', 'student.res4.5.conv2.norm.weight', 'student.res4.5.conv2.norm.bias', 'student.res4.5.conv2.norm.running_mean', 'student.res4.5.conv2.norm.running_var', 'student.res4.5.conv2.norm.num_batches_tracked', 'student.res4.5.conv3.weight', 'student.res4.5.conv3.norm.weight', 'student.res4.5.conv3.norm.bias', 'student.res4.5.conv3.norm.running_mean', 'student.res4.5.conv3.norm.running_var', 'student.res4.5.conv3.norm.num_batches_tracked', 'student.res5.0.shortcut.weight', 'student.res5.0.shortcut.norm.weight', 'student.res5.0.shortcut.norm.bias', 'student.res5.0.shortcut.norm.running_mean', 'student.res5.0.shortcut.norm.running_var', 'student.res5.0.shortcut.norm.num_batches_tracked', 'student.res5.0.conv1.weight', 'student.res5.0.conv1.norm.weight', 'student.res5.0.conv1.norm.bias', 'student.res5.0.conv1.norm.running_mean', 'student.res5.0.conv1.norm.running_var', 'student.res5.0.conv1.norm.num_batches_tracked', 'student.res5.0.conv2.weight', 'student.res5.0.conv2.norm.weight', 'student.res5.0.conv2.norm.bias', 'student.res5.0.conv2.norm.running_mean', 'student.res5.0.conv2.norm.running_var', 'student.res5.0.conv2.norm.num_batches_tracked', 'student.res5.0.conv3.weight', 'student.res5.0.conv3.norm.weight', 'student.res5.0.conv3.norm.bias', 'student.res5.0.conv3.norm.running_mean', 'student.res5.0.conv3.norm.running_var', 'student.res5.0.conv3.norm.num_batches_tracked', 'student.res5.1.conv1.weight', 'student.res5.1.conv1.norm.weight', 'student.res5.1.conv1.norm.bias', 'student.res5.1.conv1.norm.running_mean', 'student.res5.1.conv1.norm.running_var', 'student.res5.1.conv1.norm.num_batches_tracked', 'student.res5.1.conv2.weight', 'student.res5.1.conv2.norm.weight', 'student.res5.1.conv2.norm.bias', 'student.res5.1.conv2.norm.running_mean', 'student.res5.1.conv2.norm.running_var', 'student.res5.1.conv2.norm.num_batches_tracked', 'student.res5.1.conv3.weight', 'student.res5.1.conv3.norm.weight', 'student.res5.1.conv3.norm.bias', 'student.res5.1.conv3.norm.running_mean', 'student.res5.1.conv3.norm.running_var', 'student.res5.1.conv3.norm.num_batches_tracked', 'student.res5.2.conv1.weight', 'student.res5.2.conv1.norm.weight', 'student.res5.2.conv1.norm.bias', 'student.res5.2.conv1.norm.running_mean', 'student.res5.2.conv1.norm.running_var', 'student.res5.2.conv1.norm.num_batches_tracked', 'student.res5.2.conv2.weight', 'student.res5.2.conv2.norm.weight', 'student.res5.2.conv2.norm.bias', 'student.res5.2.conv2.norm.running_mean', 'student.res5.2.conv2.norm.running_var', 'student.res5.2.conv2.norm.num_batches_tracked', 'student.res5.2.conv3.weight', 'student.res5.2.conv3.norm.weight', 'student.res5.2.conv3.norm.bias', 'student.res5.2.conv3.norm.running_mean', 'student.res5.2.conv3.norm.running_var', 'student.res5.2.conv3.norm.num_batches_tracked', 'feature_matcher.0.weight', 'feature_matcher.0.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets.GTA5 import GTA5Dataset\n",
    "import sys\n",
    "sys.path.append('./datasets')  # Add the datasets directory to the Python path\n",
    "from GTA5 import GTA5Dataset\n",
    "from collate_fn import collate_data_and_cast\n",
    "from dinov2.data.augmentations import DataAugmentationDINO\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Load configurations\n",
    "with open(\"config/config.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# Data Transformation\n",
    "data_transform = DataAugmentationDINO(\n",
    "    global_crops_scale=tuple(cfg['data_transform']['global_crops_scale']),\n",
    "    local_crops_scale=tuple(cfg['data_transform']['local_crops_scale']),\n",
    "    local_crops_number=cfg['data_transform']['n_local_crops'],\n",
    "    global_crops_size=tuple(cfg['data_transform']['global_crops_size']),\n",
    "    local_crops_size=tuple(cfg['data_transform']['local_crops_size']),\n",
    ")\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = GTA5Dataset(img_dir = '/home/arda/data/train2017', transform=data_transform)\n",
    "# data_loader = DataLoader(\n",
    "#     dataset,\n",
    "#     batch_size=cfg['data_loader']['batch_size'],\n",
    "#     num_workers=cfg['data_loader']['num_workers'],\n",
    "#     shuffle=cfg['data_loader']['shuffle'],\n",
    "#     collate_fn=collate_data_and_cast\n",
    "# )\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "from torch.utils.data import random_split, Subset\n",
    "import random\n",
    "\n",
    "# Sample a smaller subset of the data\n",
    "total_size = len(dataset)\n",
    "\n",
    "# Split sampled dataset into train/test\n",
    "train_size = int(0.9 * total_size)  # 90% for training\n",
    "test_size = total_size - train_size  # 10% for testing\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create train and test dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cfg['data_loader']['batch_size'], \n",
    "    num_workers=cfg['data_loader']['num_workers'],\n",
    "    shuffle=cfg['data_loader']['shuffle'],\n",
    "    collate_fn=collate_data_and_cast\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg['data_loader']['batch_size'],\n",
    "    num_workers=cfg['data_loader']['num_workers'], \n",
    "    shuffle=False,\n",
    "    collate_fn=collate_data_and_cast\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = getattr(torch.optim, cfg['optimizer']['type'])([\n",
    "    {\"params\": model_wrapper.parameters()},\n",
    "], lr=1e-3)\n",
    "\n",
    "# Freeze teacher model\n",
    "for param in teacher.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data iterator:   0%|                                                                                                                              | 0/832 [00:00<?, ?it/s]/home/arda/miniconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage_data_ptr = tensors[0].storage().data_ptr()\n",
      "/home/arda/miniconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if x.storage().data_ptr() != storage_data_ptr:\n",
      "Preparing data iterator:  49%|████████████████████████████████████████████████████████▋                                                           | 407/832 [49:01<50:54,  7.19s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import logging\n",
    "from pytorch_metric_learning import miners, losses\n",
    "import torch.optim.lr_scheduler as lr_scheduler  # Added for scheduler\n",
    "\n",
    "miner = miners.BatchHardMiner()\n",
    "contrastive_loss = losses.ContrastiveLoss()\n",
    "logging.basicConfig(filename='training.log', level=logging.INFO)\n",
    "\n",
    "\n",
    "best_test_similarity = 0\n",
    "save_frequency = 5\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "scaler = GradScaler()  # For mixed precision training\n",
    "\n",
    "def compute_feature_similarity(feat1, feat2):\n",
    "    f1 = feat1.reshape(-1, feat1.shape[-1])\n",
    "    f2 = feat2.reshape(-1, feat2.shape[-1])\n",
    "    similarity = F.cosine_similarity(f1, f2, dim=1)\n",
    "    return similarity.mean()\n",
    "\n",
    "def compound_loss(mse_loss, cosine_sim_loss, alpha=1.0, beta=1.0):\n",
    "    return alpha * mse_loss + beta * cosine_sim_loss\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"latest_checkpoint.pth\")\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model_wrapper.student.load_state_dict(checkpoint['student_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_iteration = checkpoint['iteration'] + 1\n",
    "    best_test_similarity = checkpoint['best_test_similarity']\n",
    "    print(f\"Resuming from iteration {start_iteration}\")\n",
    "\n",
    "total_iterations = 30 * len(train_loader)  # Example: 30 epochs worth of iterations\n",
    "\n",
    "# Initialize the Cosine Annealing Scheduler\n",
    "total_epochs = 30  # Adjust this based on your actual number of epochs\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_epochs, eta_min=1e-6)\n",
    "\n",
    "data_iterator = iter(tqdm(train_loader, desc=\"Preparing data iterator\"))\n",
    "\n",
    "for iteration in range(start_iteration if 'start_iteration' in locals() else 0, total_iterations):\n",
    "    try:\n",
    "        data = next(data_iterator)\n",
    "    except StopIteration:\n",
    "        data_iterator = iter(tqdm(train_loader, desc=\"Restarting data iterator\"))\n",
    "        data = next(data_iterator)\n",
    "    \n",
    "    if iteration % len(train_loader) == 0:\n",
    "        model_wrapper.train()\n",
    "        teacher.eval()\n",
    "        epoch = iteration // len(train_loader)\n",
    "        epoch_loss = []\n",
    "        similarities = []\n",
    "        embedding_losses = []\n",
    "\n",
    "    global_crops = data[\"collated_global_crops\"].to(device)\n",
    "    # local_crops = data[\"collated_local_crops\"].to(device)\n",
    "    batch_size = int(global_crops.shape[0]//2)\n",
    "    labels = torch.arange(batch_size).repeat(2)  # Creates [0,1,2,...,batch_size-1, 0,1,2,...,batch_size-1]\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        teacher_output = teacher(global_crops)\n",
    "        teacher_feature_maps = teacher_output[\"feature_map\"]\n",
    "\n",
    "    with autocast():  # Mixed precision\n",
    "        student_output = model_wrapper(global_crops)\n",
    "        student_feature_maps = student_output[\"dinov2_feature_map\"]\n",
    "        # student_contrastive_embeddings = student_output[\"contrastive_embeddings\"]\n",
    "        mse_loss = F.mse_loss(student_feature_maps, teacher_feature_maps)\n",
    "        student_feature_normalized = F.normalize(student_feature_maps, p=2, dim=1)\n",
    "        teacher_feature_normalized = F.normalize(teacher_feature_maps, p=2, dim=1)\n",
    "        cosine_similarity = F.cosine_similarity(student_feature_normalized, teacher_feature_normalized, dim=1)\n",
    "        cosine_similarity_loss = 1 - cosine_similarity.mean()\n",
    "        # embedding_loss = contrastive_loss(student_contrastive_embeddings, labels)\n",
    "        # embedding_losses.append(embedding_loss.item())\n",
    "        total_loss = compound_loss(mse_loss, cosine_similarity_loss, alpha=1.0, beta=0) # + embedding_loss\n",
    "\n",
    "    scaler.scale(total_loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    similarity = compute_feature_similarity(student_feature_maps, teacher_feature_maps)\n",
    "    similarities.append(similarity.item())\n",
    "    epoch_loss.append(total_loss.item())\n",
    "\n",
    "    if (iteration + 1) % len(train_loader) == 0:\n",
    "        # Evaluation at the end of each epoch-equivalent\n",
    "        model_wrapper.eval()\n",
    "        test_losses = []\n",
    "        test_similarities = []\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(test_loader, desc=\"Testing\")):\n",
    "                global_crops = data[\"collated_global_crops\"].to(device)\n",
    "                teacher_output = teacher(global_crops)\n",
    "                student_output = model_wrapper(global_crops)\n",
    "\n",
    "                test_mse = F.mse_loss(student_output[\"dinov2_feature_map\"], teacher_output[\"feature_map\"])\n",
    "                test_similarity = compute_feature_similarity(student_output[\"dinov2_feature_map\"], teacher_output[\"feature_map\"])\n",
    "\n",
    "                test_losses.append(test_mse.item())\n",
    "                test_similarities.append(test_similarity.item())\n",
    "\n",
    "        avg_train_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "        avg_train_similarity = sum(similarities) / len(similarities)\n",
    "        avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "        avg_test_similarity = sum(test_similarities) / len(test_similarities)\n",
    "        current_epoch = (iteration + 1) // len(train_loader)\n",
    "        print(f\"Epoch {current_epoch}\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"Train Similarity: {avg_train_similarity:.4f}\")\n",
    "        print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Test Similarity: {avg_test_similarity:.4f}\")\n",
    "        # print(f\"Embedding Loss: {avg_embedding_loss:.4f}\")\n",
    "\n",
    "        logging.info(f\"Epoch {current_epoch}\")\n",
    "        logging.info(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "        logging.info(f\"Train Similarity: {avg_train_similarity:.4f}\")\n",
    "        logging.info(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "        logging.info(f\"Test Similarity: {avg_test_similarity:.4f}\")\n",
    "        \n",
    "        if (current_epoch) % save_frequency == 0:\n",
    "            checkpoint = {\n",
    "                'iteration': iteration,\n",
    "                'student_state_dict': model_wrapper.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'test_loss': avg_test_loss,\n",
    "                'train_similarity': avg_train_similarity,\n",
    "                'test_similarity': avg_test_similarity,\n",
    "                'best_test_similarity': best_test_similarity\n",
    "            }\n",
    "            torch.save(checkpoint, os.path.join(checkpoint_dir, f\"checkpoint_iter_{iteration}.pth\"))\n",
    "            torch.save(checkpoint, os.path.join(checkpoint_dir, \"latest_checkpoint.pth\"))\n",
    "\n",
    "        if avg_test_similarity > best_test_similarity:\n",
    "            best_test_similarity = avg_test_similarity\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'student_state_dict': model_wrapper.state_dict(),\n",
    "                'test_similarity': avg_test_similarity\n",
    "            }, os.path.join(checkpoint_dir, \"best_model.pth\"))\n",
    "        \n",
    "        # Step the scheduler at the end of the epoch\n",
    "        scheduler.step()\n",
    "        print(f\"Learning Rate adjusted to: {scheduler.get_last_lr()[0]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # TODO\n",
    "\n",
    "1 - Match the feature map sizes, then apply dino and ibot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the backbone weights of student model\n",
    "torch.save({\n",
    "    'backbone_state_dict': student.state_dict(),\n",
    "}, 'student_backbone_checkpoint.pth')\n",
    "\n",
    "print(\"Student backbone weights saved successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch    \n",
    "vitb8 = torch.hub.load('facebookresearch/dino:main', 'dino_vitb8')\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load('../../checkpoints/dino_vitbase8_pretrain_full_checkpoint.pth')\n",
    "\n",
    "# Check if the checkpoint contains the state_dict for the model\n",
    "if 'state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['state_dict']\n",
    "else:\n",
    "    state_dict = checkpoint  # If the checkpoint is directly the state_dict\n",
    "\n",
    "# Load the state_dict into the model\n",
    "vitb8.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# Print a message to confirm successful loading\n",
    "print(\"Weights loaded successfully into the DINO model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['module.backbone.cls_token', 'module.backbone.pos_embed', 'module.backbone.patch_embed.proj.weight', 'module.backbone.patch_embed.proj.bias', 'module.backbone.blocks.0.norm1.weight', 'module.backbone.blocks.0.norm1.bias', 'module.backbone.blocks.0.attn.qkv.weight', 'module.backbone.blocks.0.attn.qkv.bias', 'module.backbone.blocks.0.attn.proj.weight', 'module.backbone.blocks.0.attn.proj.bias', 'module.backbone.blocks.0.norm2.weight', 'module.backbone.blocks.0.norm2.bias', 'module.backbone.blocks.0.mlp.fc1.weight', 'module.backbone.blocks.0.mlp.fc1.bias', 'module.backbone.blocks.0.mlp.fc2.weight', 'module.backbone.blocks.0.mlp.fc2.bias', 'module.backbone.blocks.1.norm1.weight', 'module.backbone.blocks.1.norm1.bias', 'module.backbone.blocks.1.attn.qkv.weight', 'module.backbone.blocks.1.attn.qkv.bias', 'module.backbone.blocks.1.attn.proj.weight', 'module.backbone.blocks.1.attn.proj.bias', 'module.backbone.blocks.1.norm2.weight', 'module.backbone.blocks.1.norm2.bias', 'module.backbone.blocks.1.mlp.fc1.weight', 'module.backbone.blocks.1.mlp.fc1.bias', 'module.backbone.blocks.1.mlp.fc2.weight', 'module.backbone.blocks.1.mlp.fc2.bias', 'module.backbone.blocks.2.norm1.weight', 'module.backbone.blocks.2.norm1.bias', 'module.backbone.blocks.2.attn.qkv.weight', 'module.backbone.blocks.2.attn.qkv.bias', 'module.backbone.blocks.2.attn.proj.weight', 'module.backbone.blocks.2.attn.proj.bias', 'module.backbone.blocks.2.norm2.weight', 'module.backbone.blocks.2.norm2.bias', 'module.backbone.blocks.2.mlp.fc1.weight', 'module.backbone.blocks.2.mlp.fc1.bias', 'module.backbone.blocks.2.mlp.fc2.weight', 'module.backbone.blocks.2.mlp.fc2.bias', 'module.backbone.blocks.3.norm1.weight', 'module.backbone.blocks.3.norm1.bias', 'module.backbone.blocks.3.attn.qkv.weight', 'module.backbone.blocks.3.attn.qkv.bias', 'module.backbone.blocks.3.attn.proj.weight', 'module.backbone.blocks.3.attn.proj.bias', 'module.backbone.blocks.3.norm2.weight', 'module.backbone.blocks.3.norm2.bias', 'module.backbone.blocks.3.mlp.fc1.weight', 'module.backbone.blocks.3.mlp.fc1.bias', 'module.backbone.blocks.3.mlp.fc2.weight', 'module.backbone.blocks.3.mlp.fc2.bias', 'module.backbone.blocks.4.norm1.weight', 'module.backbone.blocks.4.norm1.bias', 'module.backbone.blocks.4.attn.qkv.weight', 'module.backbone.blocks.4.attn.qkv.bias', 'module.backbone.blocks.4.attn.proj.weight', 'module.backbone.blocks.4.attn.proj.bias', 'module.backbone.blocks.4.norm2.weight', 'module.backbone.blocks.4.norm2.bias', 'module.backbone.blocks.4.mlp.fc1.weight', 'module.backbone.blocks.4.mlp.fc1.bias', 'module.backbone.blocks.4.mlp.fc2.weight', 'module.backbone.blocks.4.mlp.fc2.bias', 'module.backbone.blocks.5.norm1.weight', 'module.backbone.blocks.5.norm1.bias', 'module.backbone.blocks.5.attn.qkv.weight', 'module.backbone.blocks.5.attn.qkv.bias', 'module.backbone.blocks.5.attn.proj.weight', 'module.backbone.blocks.5.attn.proj.bias', 'module.backbone.blocks.5.norm2.weight', 'module.backbone.blocks.5.norm2.bias', 'module.backbone.blocks.5.mlp.fc1.weight', 'module.backbone.blocks.5.mlp.fc1.bias', 'module.backbone.blocks.5.mlp.fc2.weight', 'module.backbone.blocks.5.mlp.fc2.bias', 'module.backbone.blocks.6.norm1.weight', 'module.backbone.blocks.6.norm1.bias', 'module.backbone.blocks.6.attn.qkv.weight', 'module.backbone.blocks.6.attn.qkv.bias', 'module.backbone.blocks.6.attn.proj.weight', 'module.backbone.blocks.6.attn.proj.bias', 'module.backbone.blocks.6.norm2.weight', 'module.backbone.blocks.6.norm2.bias', 'module.backbone.blocks.6.mlp.fc1.weight', 'module.backbone.blocks.6.mlp.fc1.bias', 'module.backbone.blocks.6.mlp.fc2.weight', 'module.backbone.blocks.6.mlp.fc2.bias', 'module.backbone.blocks.7.norm1.weight', 'module.backbone.blocks.7.norm1.bias', 'module.backbone.blocks.7.attn.qkv.weight', 'module.backbone.blocks.7.attn.qkv.bias', 'module.backbone.blocks.7.attn.proj.weight', 'module.backbone.blocks.7.attn.proj.bias', 'module.backbone.blocks.7.norm2.weight', 'module.backbone.blocks.7.norm2.bias', 'module.backbone.blocks.7.mlp.fc1.weight', 'module.backbone.blocks.7.mlp.fc1.bias', 'module.backbone.blocks.7.mlp.fc2.weight', 'module.backbone.blocks.7.mlp.fc2.bias', 'module.backbone.blocks.8.norm1.weight', 'module.backbone.blocks.8.norm1.bias', 'module.backbone.blocks.8.attn.qkv.weight', 'module.backbone.blocks.8.attn.qkv.bias', 'module.backbone.blocks.8.attn.proj.weight', 'module.backbone.blocks.8.attn.proj.bias', 'module.backbone.blocks.8.norm2.weight', 'module.backbone.blocks.8.norm2.bias', 'module.backbone.blocks.8.mlp.fc1.weight', 'module.backbone.blocks.8.mlp.fc1.bias', 'module.backbone.blocks.8.mlp.fc2.weight', 'module.backbone.blocks.8.mlp.fc2.bias', 'module.backbone.blocks.9.norm1.weight', 'module.backbone.blocks.9.norm1.bias', 'module.backbone.blocks.9.attn.qkv.weight', 'module.backbone.blocks.9.attn.qkv.bias', 'module.backbone.blocks.9.attn.proj.weight', 'module.backbone.blocks.9.attn.proj.bias', 'module.backbone.blocks.9.norm2.weight', 'module.backbone.blocks.9.norm2.bias', 'module.backbone.blocks.9.mlp.fc1.weight', 'module.backbone.blocks.9.mlp.fc1.bias', 'module.backbone.blocks.9.mlp.fc2.weight', 'module.backbone.blocks.9.mlp.fc2.bias', 'module.backbone.blocks.10.norm1.weight', 'module.backbone.blocks.10.norm1.bias', 'module.backbone.blocks.10.attn.qkv.weight', 'module.backbone.blocks.10.attn.qkv.bias', 'module.backbone.blocks.10.attn.proj.weight', 'module.backbone.blocks.10.attn.proj.bias', 'module.backbone.blocks.10.norm2.weight', 'module.backbone.blocks.10.norm2.bias', 'module.backbone.blocks.10.mlp.fc1.weight', 'module.backbone.blocks.10.mlp.fc1.bias', 'module.backbone.blocks.10.mlp.fc2.weight', 'module.backbone.blocks.10.mlp.fc2.bias', 'module.backbone.blocks.11.norm1.weight', 'module.backbone.blocks.11.norm1.bias', 'module.backbone.blocks.11.attn.qkv.weight', 'module.backbone.blocks.11.attn.qkv.bias', 'module.backbone.blocks.11.attn.proj.weight', 'module.backbone.blocks.11.attn.proj.bias', 'module.backbone.blocks.11.norm2.weight', 'module.backbone.blocks.11.norm2.bias', 'module.backbone.blocks.11.mlp.fc1.weight', 'module.backbone.blocks.11.mlp.fc1.bias', 'module.backbone.blocks.11.mlp.fc2.weight', 'module.backbone.blocks.11.mlp.fc2.bias', 'module.backbone.norm.weight', 'module.backbone.norm.bias', 'module.head.mlp.0.weight', 'module.head.mlp.0.bias', 'module.head.mlp.2.weight', 'module.head.mlp.2.bias', 'module.head.mlp.4.weight', 'module.head.mlp.4.bias', 'module.head.last_layer.weight'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['student'].keys()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65536, 256])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "checkpoint['student']['module.head.last_layer.weight'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
