{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets_gta5 import GTA5\n",
    "import albumentations as A\n",
    "import torch\n",
    "\n",
    "GTA5_PATH = '/home/arda/.cache/kagglehub/datasets/ardaerendoru/gtagta/versions/1/GTA5/GTA5'\n",
    "GTA5_IMAGES = os.path.join(GTA5_PATH, 'images')\n",
    "GTA5_LABELS = os.path.join(GTA5_PATH, 'labels')\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(512, 1024)\n",
    "])\n",
    "GTA5_dataset = GTA5(GTA5_path=GTA5_PATH, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/disk0/arda/dinov2/distillation/../../dinov2/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/storage/disk0/arda/dinov2/distillation/../../dinov2/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/storage/disk0/arda/dinov2/distillation/../../dinov2/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (feature_matcher): Conv2d(2048, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import CustomResNet\n",
    "encoder = CustomResNet()\n",
    "# encoder.load_state_dict(torch.load('student_backbone_checkpoint.pth')['backbone_state_dict'])\n",
    "\n",
    "encoder.eval()\n",
    "encoder.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = torch.randn(1, 3, 512, 1024).to(device)\n",
    "encoder(asd)[\"feature_map\"].shape\n",
    "\n",
    "# Freeze all parameters of the encoder\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [05:04<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Loss: 1.0042\n",
      "Pixel Accuracy: 0.8131\n",
      "Mean Class Accuracy: 0.3035\n",
      "Mean IoU: 0.2119\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9479, IoU: 0.9112\n",
      "Class  1 - Acc: 0.4739, IoU: 0.3257\n",
      "Class  2 - Acc: 0.6635, IoU: 0.5876\n",
      "Class  3 - Acc: 0.3823, IoU: 0.0700\n",
      "Class  4 - Acc: 0.0076, IoU: 0.0012\n",
      "Class  5 - Acc: 0.0200, IoU: 0.0007\n",
      "Class  6 - Acc: 0.0012, IoU: 0.0005\n",
      "Class  7 - Acc: 0.0030, IoU: 0.0016\n",
      "Class  8 - Acc: 0.6669, IoU: 0.4891\n",
      "Class  9 - Acc: 0.6008, IoU: 0.2622\n",
      "Class 10 - Acc: 0.8642, IoU: 0.8031\n",
      "Class 11 - Acc: 0.0023, IoU: 0.0003\n",
      "Class 12 - Acc: 0.0005, IoU: 0.0000\n",
      "Class 13 - Acc: 0.5293, IoU: 0.4233\n",
      "Class 14 - Acc: 0.5114, IoU: 0.1243\n",
      "Class 15 - Acc: 0.0106, IoU: 0.0013\n",
      "Class 16 - Acc: 0.0783, IoU: 0.0213\n",
      "Class 17 - Acc: 0.0027, IoU: 0.0020\n",
      "Class 18 - Acc: 0.0001, IoU: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [05:02<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "Loss: 0.5420\n",
      "Pixel Accuracy: 0.8578\n",
      "Mean Class Accuracy: 0.3853\n",
      "Mean IoU: 0.2714\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9575, IoU: 0.9333\n",
      "Class  1 - Acc: 0.6296, IoU: 0.4457\n",
      "Class  2 - Acc: 0.7383, IoU: 0.6627\n",
      "Class  3 - Acc: 0.5219, IoU: 0.2756\n",
      "Class  4 - Acc: 0.0285, IoU: 0.0000\n",
      "Class  5 - Acc: 0.5090, IoU: 0.0061\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0207, IoU: 0.0028\n",
      "Class  8 - Acc: 0.7244, IoU: 0.5757\n",
      "Class  9 - Acc: 0.6691, IoU: 0.4452\n",
      "Class 10 - Acc: 0.8985, IoU: 0.8491\n",
      "Class 11 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.7140, IoU: 0.5871\n",
      "Class 14 - Acc: 0.5454, IoU: 0.3653\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.2911, IoU: 0.0080\n",
      "Class 17 - Acc: 0.0736, IoU: 0.0001\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [05:09<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n",
      "Loss: 0.4474\n",
      "Pixel Accuracy: 0.8694\n",
      "Mean Class Accuracy: 0.4404\n",
      "Mean IoU: 0.2925\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9605, IoU: 0.9393\n",
      "Class  1 - Acc: 0.6845, IoU: 0.4889\n",
      "Class  2 - Acc: 0.7617, IoU: 0.6874\n",
      "Class  3 - Acc: 0.5666, IoU: 0.3313\n",
      "Class  4 - Acc: 0.5337, IoU: 0.0441\n",
      "Class  5 - Acc: 0.4405, IoU: 0.0674\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0418, IoU: 0.0063\n",
      "Class  8 - Acc: 0.7413, IoU: 0.5980\n",
      "Class  9 - Acc: 0.7017, IoU: 0.4898\n",
      "Class 10 - Acc: 0.9103, IoU: 0.8633\n",
      "Class 11 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.7591, IoU: 0.6366\n",
      "Class 14 - Acc: 0.5490, IoU: 0.3969\n",
      "Class 15 - Acc: 0.0137, IoU: 0.0000\n",
      "Class 16 - Acc: 0.1809, IoU: 0.0080\n",
      "Class 17 - Acc: 0.5217, IoU: 0.0001\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [05:21<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n",
      "Loss: 0.3998\n",
      "Pixel Accuracy: 0.8774\n",
      "Mean Class Accuracy: 0.4623\n",
      "Mean IoU: 0.3114\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9630, IoU: 0.9424\n",
      "Class  1 - Acc: 0.6986, IoU: 0.5060\n",
      "Class  2 - Acc: 0.7858, IoU: 0.7109\n",
      "Class  3 - Acc: 0.6149, IoU: 0.3757\n",
      "Class  4 - Acc: 0.5206, IoU: 0.1590\n",
      "Class  5 - Acc: 0.4578, IoU: 0.1030\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0656, IoU: 0.0054\n",
      "Class  8 - Acc: 0.7545, IoU: 0.6145\n",
      "Class  9 - Acc: 0.7230, IoU: 0.5221\n",
      "Class 10 - Acc: 0.9161, IoU: 0.8715\n",
      "Class 11 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.7828, IoU: 0.6665\n",
      "Class 14 - Acc: 0.5560, IoU: 0.4277\n",
      "Class 15 - Acc: 0.7750, IoU: 0.0002\n",
      "Class 16 - Acc: 0.1692, IoU: 0.0113\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [05:18<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n",
      "Loss: 0.3691\n",
      "Pixel Accuracy: 0.8840\n",
      "Mean Class Accuracy: 0.5277\n",
      "Mean IoU: 0.3295\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9657, IoU: 0.9464\n",
      "Class  1 - Acc: 0.7189, IoU: 0.5318\n",
      "Class  2 - Acc: 0.7985, IoU: 0.7254\n",
      "Class  3 - Acc: 0.6484, IoU: 0.4077\n",
      "Class  4 - Acc: 0.5407, IoU: 0.2147\n",
      "Class  5 - Acc: 0.4760, IoU: 0.1247\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.1132, IoU: 0.0053\n",
      "Class  8 - Acc: 0.7630, IoU: 0.6253\n",
      "Class  9 - Acc: 0.7370, IoU: 0.5430\n",
      "Class 10 - Acc: 0.9210, IoU: 0.8773\n",
      "Class 11 - Acc: 1.0000, IoU: 0.0000\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.7987, IoU: 0.6872\n",
      "Class 14 - Acc: 0.6004, IoU: 0.4685\n",
      "Class 15 - Acc: 0.5672, IoU: 0.0035\n",
      "Class 16 - Acc: 0.3776, IoU: 0.0990\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [05:21<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n",
      "Loss: 0.3422\n",
      "Pixel Accuracy: 0.8916\n",
      "Mean Class Accuracy: 0.5649\n",
      "Mean IoU: 0.3674\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9678, IoU: 0.9492\n",
      "Class  1 - Acc: 0.7343, IoU: 0.5554\n",
      "Class  2 - Acc: 0.8114, IoU: 0.7392\n",
      "Class  3 - Acc: 0.6759, IoU: 0.4458\n",
      "Class  4 - Acc: 0.5666, IoU: 0.2546\n",
      "Class  5 - Acc: 0.4890, IoU: 0.1428\n",
      "Class  6 - Acc: 0.0053, IoU: 0.0000\n",
      "Class  7 - Acc: 0.3257, IoU: 0.0115\n",
      "Class  8 - Acc: 0.7729, IoU: 0.6382\n",
      "Class  9 - Acc: 0.7548, IoU: 0.5681\n",
      "Class 10 - Acc: 0.9247, IoU: 0.8828\n",
      "Class 11 - Acc: 0.8371, IoU: 0.0013\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8124, IoU: 0.7043\n",
      "Class 14 - Acc: 0.7332, IoU: 0.5560\n",
      "Class 15 - Acc: 0.7383, IoU: 0.1539\n",
      "Class 16 - Acc: 0.5842, IoU: 0.3779\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [05:01<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n",
      "Loss: 0.3161\n",
      "Pixel Accuracy: 0.8988\n",
      "Mean Class Accuracy: 0.6234\n",
      "Mean IoU: 0.4084\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9703, IoU: 0.9527\n",
      "Class  1 - Acc: 0.7466, IoU: 0.5767\n",
      "Class  2 - Acc: 0.8263, IoU: 0.7558\n",
      "Class  3 - Acc: 0.7073, IoU: 0.4823\n",
      "Class  4 - Acc: 0.6031, IoU: 0.3065\n",
      "Class  5 - Acc: 0.5035, IoU: 0.1583\n",
      "Class  6 - Acc: 0.5900, IoU: 0.0231\n",
      "Class  7 - Acc: 0.7235, IoU: 0.1230\n",
      "Class  8 - Acc: 0.7802, IoU: 0.6478\n",
      "Class  9 - Acc: 0.7666, IoU: 0.5857\n",
      "Class 10 - Acc: 0.9281, IoU: 0.8875\n",
      "Class 11 - Acc: 0.6169, IoU: 0.0523\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8327, IoU: 0.7291\n",
      "Class 14 - Acc: 0.8073, IoU: 0.6301\n",
      "Class 15 - Acc: 0.7692, IoU: 0.3528\n",
      "Class 16 - Acc: 0.6729, IoU: 0.4956\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [05:01<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n",
      "Loss: 0.2998\n",
      "Pixel Accuracy: 0.9030\n",
      "Mean Class Accuracy: 0.6303\n",
      "Mean IoU: 0.4445\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9711, IoU: 0.9539\n",
      "Class  1 - Acc: 0.7571, IoU: 0.5845\n",
      "Class  2 - Acc: 0.8360, IoU: 0.7655\n",
      "Class  3 - Acc: 0.7286, IoU: 0.5109\n",
      "Class  4 - Acc: 0.6284, IoU: 0.3354\n",
      "Class  5 - Acc: 0.5278, IoU: 0.1734\n",
      "Class  6 - Acc: 0.5810, IoU: 0.0764\n",
      "Class  7 - Acc: 0.6968, IoU: 0.2643\n",
      "Class  8 - Acc: 0.7860, IoU: 0.6541\n",
      "Class  9 - Acc: 0.7736, IoU: 0.6015\n",
      "Class 10 - Acc: 0.9303, IoU: 0.8904\n",
      "Class 11 - Acc: 0.5340, IoU: 0.1885\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8442, IoU: 0.7447\n",
      "Class 14 - Acc: 0.8279, IoU: 0.6598\n",
      "Class 15 - Acc: 0.8079, IoU: 0.4820\n",
      "Class 16 - Acc: 0.7457, IoU: 0.5606\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [05:06<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n",
      "Loss: 0.2808\n",
      "Pixel Accuracy: 0.9083\n",
      "Mean Class Accuracy: 0.6407\n",
      "Mean IoU: 0.4691\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9735, IoU: 0.9573\n",
      "Class  1 - Acc: 0.7711, IoU: 0.6084\n",
      "Class  2 - Acc: 0.8466, IoU: 0.7781\n",
      "Class  3 - Acc: 0.7457, IoU: 0.5347\n",
      "Class  4 - Acc: 0.6598, IoU: 0.3831\n",
      "Class  5 - Acc: 0.5488, IoU: 0.1873\n",
      "Class  6 - Acc: 0.5466, IoU: 0.1055\n",
      "Class  7 - Acc: 0.6838, IoU: 0.3030\n",
      "Class  8 - Acc: 0.7932, IoU: 0.6649\n",
      "Class  9 - Acc: 0.7872, IoU: 0.6204\n",
      "Class 10 - Acc: 0.9330, IoU: 0.8935\n",
      "Class 11 - Acc: 0.5515, IoU: 0.2404\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8499, IoU: 0.7519\n",
      "Class 14 - Acc: 0.8496, IoU: 0.6852\n",
      "Class 15 - Acc: 0.8560, IoU: 0.5703\n",
      "Class 16 - Acc: 0.7770, IoU: 0.6282\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [05:02<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n",
      "Loss: 0.2632\n",
      "Pixel Accuracy: 0.9133\n",
      "Mean Class Accuracy: 0.6571\n",
      "Mean IoU: 0.4930\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9747, IoU: 0.9590\n",
      "Class  1 - Acc: 0.7830, IoU: 0.6237\n",
      "Class  2 - Acc: 0.8578, IoU: 0.7914\n",
      "Class  3 - Acc: 0.7660, IoU: 0.5668\n",
      "Class  4 - Acc: 0.6851, IoU: 0.4189\n",
      "Class  5 - Acc: 0.5689, IoU: 0.2065\n",
      "Class  6 - Acc: 0.5763, IoU: 0.1325\n",
      "Class  7 - Acc: 0.7205, IoU: 0.3465\n",
      "Class  8 - Acc: 0.7998, IoU: 0.6733\n",
      "Class  9 - Acc: 0.7946, IoU: 0.6361\n",
      "Class 10 - Acc: 0.9361, IoU: 0.8980\n",
      "Class 11 - Acc: 0.5662, IoU: 0.2605\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8638, IoU: 0.7721\n",
      "Class 14 - Acc: 0.8702, IoU: 0.7258\n",
      "Class 15 - Acc: 0.8836, IoU: 0.6627\n",
      "Class 16 - Acc: 0.8378, IoU: 0.6929\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First, let's create a simple decoder network\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "class SegmentationDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels=2048, num_classes=19):\n",
    "        super().__init__()\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            # 16x32 -> 32x64\n",
    "            torch.nn.ConvTranspose2d(in_channels, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(1024),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 32x64 -> 64x128\n",
    "            torch.nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 64x128 -> 128x256\n",
    "            torch.nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 128x256 -> 256x512\n",
    "            torch.nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 256x512 -> 512x1024\n",
    "            torch.nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # Final 1x1 conv to get to num_classes\n",
    "            torch.nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        # Ensure exact output size\n",
    "        if x.shape[-2:] != (512, 1024):\n",
    "            x = torch.nn.functional.interpolate(\n",
    "                x, size=(512, 1024), \n",
    "                mode='bilinear', \n",
    "                align_corners=False\n",
    "            )\n",
    "        return x\n",
    "\n",
    "# Initialize decoder, optimizer, and loss function\n",
    "decoder = SegmentationDecoder().to(device)\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "def fast_hist(a: np.ndarray, b: np.ndarray, n: int) -> np.ndarray:\n",
    "    k = (b >= 0) & (b < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "def per_class_iou(hist: np.ndarray) -> np.ndarray:\n",
    "    epsilon = 1e-5\n",
    "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)\n",
    "\n",
    "def train_epoch(encoder, decoder, dataloader, optimizer, criterion, device, num_classes=19):\n",
    "    decoder.train()\n",
    "    encoder.train()  # Keep DINO frozen\n",
    "    \n",
    "    total_loss = 0\n",
    "    hist = np.zeros((num_classes, num_classes))  # Single histogram for entire epoch\n",
    "    total_pixels = 0\n",
    "    correct_pixels = 0\n",
    "    \n",
    "    for images, labels in tqdm.tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Get DINO features\n",
    "        # with torch.no_grad():\n",
    "        features = encoder(images)[\"feature_map\"]\n",
    "        \n",
    "        # Forward pass through decoder\n",
    "        outputs = decoder(features)\n",
    "        \n",
    "        # Resize outputs to match label size if needed\n",
    "        if outputs.shape[-2:] != labels.shape[-2:]:\n",
    "            outputs = torch.nn.functional.interpolate(\n",
    "                outputs, size=labels.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        preds = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
    "        \n",
    "        # Pixel Accuracy\n",
    "        valid_mask = labels != 255  # Ignore index\n",
    "        total_pixels += valid_mask.sum().item()\n",
    "        correct_pixels += ((preds == labels) & valid_mask).sum().item()\n",
    "        \n",
    "        # IoU\n",
    "        preds = preds.cpu().numpy()\n",
    "        target = labels.cpu().numpy()\n",
    "        hist += fast_hist(preds.flatten(), target.flatten(), num_classes)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    pixel_acc = correct_pixels / total_pixels\n",
    "    \n",
    "    # Per-class accuracy (mean class accuracy)\n",
    "    class_acc = np.diag(hist) / (hist.sum(1) + np.finfo(np.float32).eps)\n",
    "    mean_class_acc = np.nanmean(class_acc)\n",
    "    \n",
    "    # IoU metrics\n",
    "    iou = per_class_iou(hist)\n",
    "    mean_iou = np.nanmean(iou)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'pixel_acc': pixel_acc,\n",
    "        'mean_class_acc': mean_class_acc,\n",
    "        'mean_iou': mean_iou,\n",
    "        'class_iou': iou,\n",
    "        'class_acc': class_acc\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    GTA5_dataset, \n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    metrics = train_epoch(encoder, decoder, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    print(f\"Pixel Accuracy: {metrics['pixel_acc']:.4f}\")\n",
    "    print(f\"Mean Class Accuracy: {metrics['mean_class_acc']:.4f}\")\n",
    "    print(f\"Mean IoU: {metrics['mean_iou']:.4f}\")\n",
    "    \n",
    "    # Optionally print per-class metrics\n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    for i in range(19):  # Assuming 19 classes\n",
    "        print(f\"Class {i:2d} - Acc: {metrics['class_acc'][i]:.4f}, IoU: {metrics['class_iou'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 3/10\n",
    "# Loss: 1.2027\n",
    "# Pixel Accuracy: 0.6440\n",
    "# Mean Class Accuracy: 0.1213\n",
    "# Mean IoU: 0.0818\n",
    "\n",
    "# Per-class metrics:\n",
    "# Class  0 - Acc: 0.6736, IoU: 0.6670\n",
    "# Class  1 - Acc: 0.1000, IoU: 0.0000\n",
    "# Class  2 - Acc: 0.3823, IoU: 0.1999\n",
    "# Class  3 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class  4 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class  5 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class  6 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class  7 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class  8 - Acc: 0.4519, IoU: 0.0889\n",
    "# Class  9 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 10 - Acc: 0.6970, IoU: 0.5976\n",
    "# Class 11 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 12 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 13 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 14 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 15 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 16 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 17 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 18 - Acc: 0.0000, IoU: 0.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_id_to_color' from 'datasets' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_id_to_color   \n\u001b[1;32m      5\u001b[0m img_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m310\u001b[39m\n\u001b[1;32m      7\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mget_intermediate_layers(GTA5_dataset[img_idx][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device), n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, reshape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_class_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_id_to_color' from 'datasets' (unknown location)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datasets import get_id_to_color   \n",
    "\n",
    "\n",
    "img_idx = 310\n",
    "\n",
    "embeddings = encoder.get_intermediate_layers(GTA5_dataset[img_idx][0].unsqueeze(0).to(device), n=1, reshape=True, return_class_token=False, norm=False)[0]\n",
    "out = decoder(embeddings)\n",
    "id_to_color = get_id_to_color()\n",
    "\n",
    "pred = out.argmax(1).cpu().numpy()\n",
    "pred = pred.reshape(518, 1036)\n",
    "# Convert class IDs to RGB colors\n",
    "color_map = np.array([id_to_color.get(i, (0, 0, 0)) for i in range(max(id_to_color.keys()) + 1)])\n",
    "pred_rgb = color_map[pred]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(pred_rgb)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "labels = GTA5_dataset[img_idx][1].cpu().numpy()\n",
    "color_map = np.array([id_to_color.get(i, (0, 0, 0)) for i in range(max(id_to_color.keys()) + 1)])\n",
    "pred_rgb = np.zeros((*labels.shape, 3), dtype=np.uint8)\n",
    "mask = labels < len(color_map)\n",
    "pred_rgb[mask] = color_map[labels[mask]]\n",
    "plt.imshow(pred_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([518, 1036])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GTA5_dataset[img_idx][1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
