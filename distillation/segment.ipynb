{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets_gta5 import GTA5\n",
    "import albumentations as A\n",
    "import torch\n",
    "\n",
    "GTA5_PATH = '/home/arda/.cache/kagglehub/datasets/ardaerendoru/gtagta/versions/1/GTA5/GTA5'\n",
    "GTA5_IMAGES = os.path.join(GTA5_PATH, 'images')\n",
    "GTA5_LABELS = os.path.join(GTA5_PATH, 'labels')\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'feature_matcher.weight', 'feature_matcher.bias', 'attention.in_proj_weight', 'attention.in_proj_bias', 'attention.out_proj.weight', 'attention.out_proj.bias'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(512, 1024)\n",
    "    # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "GTA5_dataset = GTA5(GTA5_path=GTA5_PATH, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "state_dict = resnet50.state_dict()\n",
    "\n",
    "print(ckp.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['stem.conv1.weight', 'stem.conv1.norm.weight', 'stem.conv1.norm.bias', 'stem.conv1.norm.running_mean', 'stem.conv1.norm.running_var', 'stem.conv1.norm.num_batches_tracked', 'res2.0.shortcut.weight', 'res2.0.shortcut.norm.weight', 'res2.0.shortcut.norm.bias', 'res2.0.shortcut.norm.running_mean', 'res2.0.shortcut.norm.running_var', 'res2.0.shortcut.norm.num_batches_tracked', 'res2.0.conv1.weight', 'res2.0.conv1.norm.weight', 'res2.0.conv1.norm.bias', 'res2.0.conv1.norm.running_mean', 'res2.0.conv1.norm.running_var', 'res2.0.conv1.norm.num_batches_tracked', 'res2.0.conv2.weight', 'res2.0.conv2.norm.weight', 'res2.0.conv2.norm.bias', 'res2.0.conv2.norm.running_mean', 'res2.0.conv2.norm.running_var', 'res2.0.conv2.norm.num_batches_tracked', 'res2.0.conv3.weight', 'res2.0.conv3.norm.weight', 'res2.0.conv3.norm.bias', 'res2.0.conv3.norm.running_mean', 'res2.0.conv3.norm.running_var', 'res2.0.conv3.norm.num_batches_tracked', 'res2.1.conv1.weight', 'res2.1.conv1.norm.weight', 'res2.1.conv1.norm.bias', 'res2.1.conv1.norm.running_mean', 'res2.1.conv1.norm.running_var', 'res2.1.conv1.norm.num_batches_tracked', 'res2.1.conv2.weight', 'res2.1.conv2.norm.weight', 'res2.1.conv2.norm.bias', 'res2.1.conv2.norm.running_mean', 'res2.1.conv2.norm.running_var', 'res2.1.conv2.norm.num_batches_tracked', 'res2.1.conv3.weight', 'res2.1.conv3.norm.weight', 'res2.1.conv3.norm.bias', 'res2.1.conv3.norm.running_mean', 'res2.1.conv3.norm.running_var', 'res2.1.conv3.norm.num_batches_tracked', 'res2.2.conv1.weight', 'res2.2.conv1.norm.weight', 'res2.2.conv1.norm.bias', 'res2.2.conv1.norm.running_mean', 'res2.2.conv1.norm.running_var', 'res2.2.conv1.norm.num_batches_tracked', 'res2.2.conv2.weight', 'res2.2.conv2.norm.weight', 'res2.2.conv2.norm.bias', 'res2.2.conv2.norm.running_mean', 'res2.2.conv2.norm.running_var', 'res2.2.conv2.norm.num_batches_tracked', 'res2.2.conv3.weight', 'res2.2.conv3.norm.weight', 'res2.2.conv3.norm.bias', 'res2.2.conv3.norm.running_mean', 'res2.2.conv3.norm.running_var', 'res2.2.conv3.norm.num_batches_tracked', 'res3.0.shortcut.weight', 'res3.0.shortcut.norm.weight', 'res3.0.shortcut.norm.bias', 'res3.0.shortcut.norm.running_mean', 'res3.0.shortcut.norm.running_var', 'res3.0.shortcut.norm.num_batches_tracked', 'res3.0.conv1.weight', 'res3.0.conv1.norm.weight', 'res3.0.conv1.norm.bias', 'res3.0.conv1.norm.running_mean', 'res3.0.conv1.norm.running_var', 'res3.0.conv1.norm.num_batches_tracked', 'res3.0.conv2.weight', 'res3.0.conv2.norm.weight', 'res3.0.conv2.norm.bias', 'res3.0.conv2.norm.running_mean', 'res3.0.conv2.norm.running_var', 'res3.0.conv2.norm.num_batches_tracked', 'res3.0.conv3.weight', 'res3.0.conv3.norm.weight', 'res3.0.conv3.norm.bias', 'res3.0.conv3.norm.running_mean', 'res3.0.conv3.norm.running_var', 'res3.0.conv3.norm.num_batches_tracked', 'res3.1.conv1.weight', 'res3.1.conv1.norm.weight', 'res3.1.conv1.norm.bias', 'res3.1.conv1.norm.running_mean', 'res3.1.conv1.norm.running_var', 'res3.1.conv1.norm.num_batches_tracked', 'res3.1.conv2.weight', 'res3.1.conv2.norm.weight', 'res3.1.conv2.norm.bias', 'res3.1.conv2.norm.running_mean', 'res3.1.conv2.norm.running_var', 'res3.1.conv2.norm.num_batches_tracked', 'res3.1.conv3.weight', 'res3.1.conv3.norm.weight', 'res3.1.conv3.norm.bias', 'res3.1.conv3.norm.running_mean', 'res3.1.conv3.norm.running_var', 'res3.1.conv3.norm.num_batches_tracked', 'res3.2.conv1.weight', 'res3.2.conv1.norm.weight', 'res3.2.conv1.norm.bias', 'res3.2.conv1.norm.running_mean', 'res3.2.conv1.norm.running_var', 'res3.2.conv1.norm.num_batches_tracked', 'res3.2.conv2.weight', 'res3.2.conv2.norm.weight', 'res3.2.conv2.norm.bias', 'res3.2.conv2.norm.running_mean', 'res3.2.conv2.norm.running_var', 'res3.2.conv2.norm.num_batches_tracked', 'res3.2.conv3.weight', 'res3.2.conv3.norm.weight', 'res3.2.conv3.norm.bias', 'res3.2.conv3.norm.running_mean', 'res3.2.conv3.norm.running_var', 'res3.2.conv3.norm.num_batches_tracked', 'res3.3.conv1.weight', 'res3.3.conv1.norm.weight', 'res3.3.conv1.norm.bias', 'res3.3.conv1.norm.running_mean', 'res3.3.conv1.norm.running_var', 'res3.3.conv1.norm.num_batches_tracked', 'res3.3.conv2.weight', 'res3.3.conv2.norm.weight', 'res3.3.conv2.norm.bias', 'res3.3.conv2.norm.running_mean', 'res3.3.conv2.norm.running_var', 'res3.3.conv2.norm.num_batches_tracked', 'res3.3.conv3.weight', 'res3.3.conv3.norm.weight', 'res3.3.conv3.norm.bias', 'res3.3.conv3.norm.running_mean', 'res3.3.conv3.norm.running_var', 'res3.3.conv3.norm.num_batches_tracked', 'res4.0.shortcut.weight', 'res4.0.shortcut.norm.weight', 'res4.0.shortcut.norm.bias', 'res4.0.shortcut.norm.running_mean', 'res4.0.shortcut.norm.running_var', 'res4.0.shortcut.norm.num_batches_tracked', 'res4.0.conv1.weight', 'res4.0.conv1.norm.weight', 'res4.0.conv1.norm.bias', 'res4.0.conv1.norm.running_mean', 'res4.0.conv1.norm.running_var', 'res4.0.conv1.norm.num_batches_tracked', 'res4.0.conv2.weight', 'res4.0.conv2.norm.weight', 'res4.0.conv2.norm.bias', 'res4.0.conv2.norm.running_mean', 'res4.0.conv2.norm.running_var', 'res4.0.conv2.norm.num_batches_tracked', 'res4.0.conv3.weight', 'res4.0.conv3.norm.weight', 'res4.0.conv3.norm.bias', 'res4.0.conv3.norm.running_mean', 'res4.0.conv3.norm.running_var', 'res4.0.conv3.norm.num_batches_tracked', 'res4.1.conv1.weight', 'res4.1.conv1.norm.weight', 'res4.1.conv1.norm.bias', 'res4.1.conv1.norm.running_mean', 'res4.1.conv1.norm.running_var', 'res4.1.conv1.norm.num_batches_tracked', 'res4.1.conv2.weight', 'res4.1.conv2.norm.weight', 'res4.1.conv2.norm.bias', 'res4.1.conv2.norm.running_mean', 'res4.1.conv2.norm.running_var', 'res4.1.conv2.norm.num_batches_tracked', 'res4.1.conv3.weight', 'res4.1.conv3.norm.weight', 'res4.1.conv3.norm.bias', 'res4.1.conv3.norm.running_mean', 'res4.1.conv3.norm.running_var', 'res4.1.conv3.norm.num_batches_tracked', 'res4.2.conv1.weight', 'res4.2.conv1.norm.weight', 'res4.2.conv1.norm.bias', 'res4.2.conv1.norm.running_mean', 'res4.2.conv1.norm.running_var', 'res4.2.conv1.norm.num_batches_tracked', 'res4.2.conv2.weight', 'res4.2.conv2.norm.weight', 'res4.2.conv2.norm.bias', 'res4.2.conv2.norm.running_mean', 'res4.2.conv2.norm.running_var', 'res4.2.conv2.norm.num_batches_tracked', 'res4.2.conv3.weight', 'res4.2.conv3.norm.weight', 'res4.2.conv3.norm.bias', 'res4.2.conv3.norm.running_mean', 'res4.2.conv3.norm.running_var', 'res4.2.conv3.norm.num_batches_tracked', 'res4.3.conv1.weight', 'res4.3.conv1.norm.weight', 'res4.3.conv1.norm.bias', 'res4.3.conv1.norm.running_mean', 'res4.3.conv1.norm.running_var', 'res4.3.conv1.norm.num_batches_tracked', 'res4.3.conv2.weight', 'res4.3.conv2.norm.weight', 'res4.3.conv2.norm.bias', 'res4.3.conv2.norm.running_mean', 'res4.3.conv2.norm.running_var', 'res4.3.conv2.norm.num_batches_tracked', 'res4.3.conv3.weight', 'res4.3.conv3.norm.weight', 'res4.3.conv3.norm.bias', 'res4.3.conv3.norm.running_mean', 'res4.3.conv3.norm.running_var', 'res4.3.conv3.norm.num_batches_tracked', 'res4.4.conv1.weight', 'res4.4.conv1.norm.weight', 'res4.4.conv1.norm.bias', 'res4.4.conv1.norm.running_mean', 'res4.4.conv1.norm.running_var', 'res4.4.conv1.norm.num_batches_tracked', 'res4.4.conv2.weight', 'res4.4.conv2.norm.weight', 'res4.4.conv2.norm.bias', 'res4.4.conv2.norm.running_mean', 'res4.4.conv2.norm.running_var', 'res4.4.conv2.norm.num_batches_tracked', 'res4.4.conv3.weight', 'res4.4.conv3.norm.weight', 'res4.4.conv3.norm.bias', 'res4.4.conv3.norm.running_mean', 'res4.4.conv3.norm.running_var', 'res4.4.conv3.norm.num_batches_tracked', 'res4.5.conv1.weight', 'res4.5.conv1.norm.weight', 'res4.5.conv1.norm.bias', 'res4.5.conv1.norm.running_mean', 'res4.5.conv1.norm.running_var', 'res4.5.conv1.norm.num_batches_tracked', 'res4.5.conv2.weight', 'res4.5.conv2.norm.weight', 'res4.5.conv2.norm.bias', 'res4.5.conv2.norm.running_mean', 'res4.5.conv2.norm.running_var', 'res4.5.conv2.norm.num_batches_tracked', 'res4.5.conv3.weight', 'res4.5.conv3.norm.weight', 'res4.5.conv3.norm.bias', 'res4.5.conv3.norm.running_mean', 'res4.5.conv3.norm.running_var', 'res4.5.conv3.norm.num_batches_tracked', 'res5.0.shortcut.weight', 'res5.0.shortcut.norm.weight', 'res5.0.shortcut.norm.bias', 'res5.0.shortcut.norm.running_mean', 'res5.0.shortcut.norm.running_var', 'res5.0.shortcut.norm.num_batches_tracked', 'res5.0.conv1.weight', 'res5.0.conv1.norm.weight', 'res5.0.conv1.norm.bias', 'res5.0.conv1.norm.running_mean', 'res5.0.conv1.norm.running_var', 'res5.0.conv1.norm.num_batches_tracked', 'res5.0.conv2.weight', 'res5.0.conv2.norm.weight', 'res5.0.conv2.norm.bias', 'res5.0.conv2.norm.running_mean', 'res5.0.conv2.norm.running_var', 'res5.0.conv2.norm.num_batches_tracked', 'res5.0.conv3.weight', 'res5.0.conv3.norm.weight', 'res5.0.conv3.norm.bias', 'res5.0.conv3.norm.running_mean', 'res5.0.conv3.norm.running_var', 'res5.0.conv3.norm.num_batches_tracked', 'res5.1.conv1.weight', 'res5.1.conv1.norm.weight', 'res5.1.conv1.norm.bias', 'res5.1.conv1.norm.running_mean', 'res5.1.conv1.norm.running_var', 'res5.1.conv1.norm.num_batches_tracked', 'res5.1.conv2.weight', 'res5.1.conv2.norm.weight', 'res5.1.conv2.norm.bias', 'res5.1.conv2.norm.running_mean', 'res5.1.conv2.norm.running_var', 'res5.1.conv2.norm.num_batches_tracked', 'res5.1.conv3.weight', 'res5.1.conv3.norm.weight', 'res5.1.conv3.norm.bias', 'res5.1.conv3.norm.running_mean', 'res5.1.conv3.norm.running_var', 'res5.1.conv3.norm.num_batches_tracked', 'res5.2.conv1.weight', 'res5.2.conv1.norm.weight', 'res5.2.conv1.norm.bias', 'res5.2.conv1.norm.running_mean', 'res5.2.conv1.norm.running_var', 'res5.2.conv1.norm.num_batches_tracked', 'res5.2.conv2.weight', 'res5.2.conv2.norm.weight', 'res5.2.conv2.norm.bias', 'res5.2.conv2.norm.running_mean', 'res5.2.conv2.norm.running_var', 'res5.2.conv2.norm.num_batches_tracked', 'res5.2.conv3.weight', 'res5.2.conv3.norm.weight', 'res5.2.conv3.norm.bias', 'res5.2.conv3.norm.running_mean', 'res5.2.conv3.norm.running_var', 'res5.2.conv3.norm.num_batches_tracked'])\n"
     ]
    }
   ],
   "source": [
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/disk0/arda/dinov2/distillation/../../dinov2/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/storage/disk0/arda/dinov2/distillation/../../dinov2/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/storage/disk0/arda/dinov2/distillation/../../dinov2/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (feature_matcher): Conv2d(2048, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=1536, out_features=1536, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import CustomResNet\n",
    "encoder = CustomResNet(pretrained=False)\n",
    "encoder.load_state_dict(torch.load('/home/arda/dinov2/distillation/checkpoints/best_model.pth')['student_state_dict'])\n",
    "\n",
    "encoder.eval()\n",
    "encoder.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = torch.randn(1, 3, 512, 1024).to(device)\n",
    "encoder(asd)[\"feature_map\"].shape\n",
    "\n",
    "# Freeze all parameters of the encoder\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:56<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Loss: 0.9172\n",
      "Pixel Accuracy: 0.8430\n",
      "Mean Class Accuracy: 0.3394\n",
      "Mean IoU: 0.2454\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9612, IoU: 0.9330\n",
      "Class  1 - Acc: 0.5427, IoU: 0.3984\n",
      "Class  2 - Acc: 0.6960, IoU: 0.6486\n",
      "Class  3 - Acc: 0.4081, IoU: 0.1877\n",
      "Class  4 - Acc: 0.0098, IoU: 0.0003\n",
      "Class  5 - Acc: 0.0248, IoU: 0.0004\n",
      "Class  6 - Acc: 0.0015, IoU: 0.0003\n",
      "Class  7 - Acc: 0.0008, IoU: 0.0001\n",
      "Class  8 - Acc: 0.6637, IoU: 0.5252\n",
      "Class  9 - Acc: 0.7468, IoU: 0.3243\n",
      "Class 10 - Acc: 0.9077, IoU: 0.8505\n",
      "Class 11 - Acc: 0.0021, IoU: 0.0001\n",
      "Class 12 - Acc: 0.0004, IoU: 0.0002\n",
      "Class 13 - Acc: 0.7488, IoU: 0.5134\n",
      "Class 14 - Acc: 0.5864, IoU: 0.2540\n",
      "Class 15 - Acc: 0.1099, IoU: 0.0164\n",
      "Class 16 - Acc: 0.0373, IoU: 0.0093\n",
      "Class 17 - Acc: 0.0004, IoU: 0.0003\n",
      "Class 18 - Acc: 0.0001, IoU: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:55<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "Loss: 0.4546\n",
      "Pixel Accuracy: 0.8839\n",
      "Mean Class Accuracy: 0.4948\n",
      "Mean IoU: 0.3101\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9690, IoU: 0.9489\n",
      "Class  1 - Acc: 0.6911, IoU: 0.5275\n",
      "Class  2 - Acc: 0.7780, IoU: 0.7190\n",
      "Class  3 - Acc: 0.6241, IoU: 0.3933\n",
      "Class  4 - Acc: 0.6419, IoU: 0.0075\n",
      "Class  5 - Acc: 0.4608, IoU: 0.0332\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  8 - Acc: 0.7680, IoU: 0.6387\n",
      "Class  9 - Acc: 0.7430, IoU: 0.5379\n",
      "Class 10 - Acc: 0.9224, IoU: 0.8818\n",
      "Class 11 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 12 - Acc: 0.1276, IoU: 0.0008\n",
      "Class 13 - Acc: 0.7993, IoU: 0.6953\n",
      "Class 14 - Acc: 0.6120, IoU: 0.4460\n",
      "Class 15 - Acc: 0.7237, IoU: 0.0413\n",
      "Class 16 - Acc: 0.4218, IoU: 0.0206\n",
      "Class 17 - Acc: 0.1176, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:56<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n",
      "Loss: 0.3726\n",
      "Pixel Accuracy: 0.8931\n",
      "Mean Class Accuracy: 0.4869\n",
      "Mean IoU: 0.3468\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9711, IoU: 0.9530\n",
      "Class  1 - Acc: 0.7295, IoU: 0.5609\n",
      "Class  2 - Acc: 0.8067, IoU: 0.7419\n",
      "Class  3 - Acc: 0.6447, IoU: 0.4322\n",
      "Class  4 - Acc: 0.5816, IoU: 0.1834\n",
      "Class  5 - Acc: 0.5014, IoU: 0.1217\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  8 - Acc: 0.7835, IoU: 0.6560\n",
      "Class  9 - Acc: 0.7530, IoU: 0.5662\n",
      "Class 10 - Acc: 0.9290, IoU: 0.8901\n",
      "Class 11 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 12 - Acc: 0.3329, IoU: 0.0008\n",
      "Class 13 - Acc: 0.8194, IoU: 0.7199\n",
      "Class 14 - Acc: 0.6521, IoU: 0.5024\n",
      "Class 15 - Acc: 0.6772, IoU: 0.2579\n",
      "Class 16 - Acc: 0.0685, IoU: 0.0027\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:57<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n",
      "Loss: 0.3317\n",
      "Pixel Accuracy: 0.8999\n",
      "Mean Class Accuracy: 0.5636\n",
      "Mean IoU: 0.3756\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9728, IoU: 0.9563\n",
      "Class  1 - Acc: 0.7545, IoU: 0.5897\n",
      "Class  2 - Acc: 0.8207, IoU: 0.7557\n",
      "Class  3 - Acc: 0.6662, IoU: 0.4571\n",
      "Class  4 - Acc: 0.5649, IoU: 0.2340\n",
      "Class  5 - Acc: 0.5011, IoU: 0.1554\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  8 - Acc: 0.7954, IoU: 0.6706\n",
      "Class  9 - Acc: 0.7665, IoU: 0.5868\n",
      "Class 10 - Acc: 0.9345, IoU: 0.8970\n",
      "Class 11 - Acc: 0.7160, IoU: 0.0008\n",
      "Class 12 - Acc: 0.2857, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8352, IoU: 0.7407\n",
      "Class 14 - Acc: 0.7190, IoU: 0.5518\n",
      "Class 15 - Acc: 0.6322, IoU: 0.3823\n",
      "Class 16 - Acc: 0.7434, IoU: 0.1591\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:52<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n",
      "Loss: 0.3048\n",
      "Pixel Accuracy: 0.9049\n",
      "Mean Class Accuracy: 0.6819\n",
      "Mean IoU: 0.4102\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9740, IoU: 0.9576\n",
      "Class  1 - Acc: 0.7619, IoU: 0.5994\n",
      "Class  2 - Acc: 0.8317, IoU: 0.7663\n",
      "Class  3 - Acc: 0.6900, IoU: 0.4808\n",
      "Class  4 - Acc: 0.5677, IoU: 0.2643\n",
      "Class  5 - Acc: 0.5325, IoU: 0.1813\n",
      "Class  6 - Acc: 0.8022, IoU: 0.0004\n",
      "Class  7 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  8 - Acc: 0.8039, IoU: 0.6814\n",
      "Class  9 - Acc: 0.7767, IoU: 0.6076\n",
      "Class 10 - Acc: 0.9373, IoU: 0.9005\n",
      "Class 11 - Acc: 0.6615, IoU: 0.1539\n",
      "Class 12 - Acc: 0.5000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8409, IoU: 0.7524\n",
      "Class 14 - Acc: 0.7723, IoU: 0.5957\n",
      "Class 15 - Acc: 0.7251, IoU: 0.4376\n",
      "Class 16 - Acc: 0.7780, IoU: 0.4144\n",
      "Class 17 - Acc: 1.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:55<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n",
      "Loss: 0.2832\n",
      "Pixel Accuracy: 0.9101\n",
      "Mean Class Accuracy: 0.7562\n",
      "Mean IoU: 0.4449\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9753, IoU: 0.9598\n",
      "Class  1 - Acc: 0.7788, IoU: 0.6227\n",
      "Class  2 - Acc: 0.8425, IoU: 0.7779\n",
      "Class  3 - Acc: 0.7134, IoU: 0.5045\n",
      "Class  4 - Acc: 0.6002, IoU: 0.2923\n",
      "Class  5 - Acc: 0.5614, IoU: 0.2009\n",
      "Class  6 - Acc: 0.6866, IoU: 0.0637\n",
      "Class  7 - Acc: 0.9565, IoU: 0.0031\n",
      "Class  8 - Acc: 0.8097, IoU: 0.6895\n",
      "Class  9 - Acc: 0.7843, IoU: 0.6183\n",
      "Class 10 - Acc: 0.9399, IoU: 0.9040\n",
      "Class 11 - Acc: 0.6230, IoU: 0.3224\n",
      "Class 12 - Acc: 1.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8525, IoU: 0.7674\n",
      "Class 14 - Acc: 0.8023, IoU: 0.6308\n",
      "Class 15 - Acc: 0.8021, IoU: 0.5281\n",
      "Class 16 - Acc: 0.8096, IoU: 0.5647\n",
      "Class 17 - Acc: 0.8288, IoU: 0.0022\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:54<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n",
      "Loss: 0.2661\n",
      "Pixel Accuracy: 0.9140\n",
      "Mean Class Accuracy: 0.7217\n",
      "Mean IoU: 0.4888\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9766, IoU: 0.9614\n",
      "Class  1 - Acc: 0.7826, IoU: 0.6322\n",
      "Class  2 - Acc: 0.8524, IoU: 0.7875\n",
      "Class  3 - Acc: 0.7327, IoU: 0.5271\n",
      "Class  4 - Acc: 0.6175, IoU: 0.3283\n",
      "Class  5 - Acc: 0.5832, IoU: 0.2189\n",
      "Class  6 - Acc: 0.5816, IoU: 0.1512\n",
      "Class  7 - Acc: 0.7832, IoU: 0.2448\n",
      "Class  8 - Acc: 0.8142, IoU: 0.6951\n",
      "Class  9 - Acc: 0.7928, IoU: 0.6308\n",
      "Class 10 - Acc: 0.9428, IoU: 0.9073\n",
      "Class 11 - Acc: 0.6364, IoU: 0.3557\n",
      "Class 12 - Acc: 0.5000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8613, IoU: 0.7797\n",
      "Class 14 - Acc: 0.8260, IoU: 0.6663\n",
      "Class 15 - Acc: 0.8337, IoU: 0.5811\n",
      "Class 16 - Acc: 0.8226, IoU: 0.6128\n",
      "Class 17 - Acc: 0.7725, IoU: 0.2074\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:55<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n",
      "Loss: 0.2531\n",
      "Pixel Accuracy: 0.9171\n",
      "Mean Class Accuracy: 0.7433\n",
      "Mean IoU: 0.5211\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9774, IoU: 0.9626\n",
      "Class  1 - Acc: 0.7902, IoU: 0.6385\n",
      "Class  2 - Acc: 0.8599, IoU: 0.7957\n",
      "Class  3 - Acc: 0.7460, IoU: 0.5475\n",
      "Class  4 - Acc: 0.6368, IoU: 0.3507\n",
      "Class  5 - Acc: 0.5934, IoU: 0.2326\n",
      "Class  6 - Acc: 0.5849, IoU: 0.1762\n",
      "Class  7 - Acc: 0.7644, IoU: 0.3662\n",
      "Class  8 - Acc: 0.8193, IoU: 0.7029\n",
      "Class  9 - Acc: 0.8020, IoU: 0.6455\n",
      "Class 10 - Acc: 0.9444, IoU: 0.9090\n",
      "Class 11 - Acc: 0.6470, IoU: 0.3737\n",
      "Class 12 - Acc: 0.8750, IoU: 0.0018\n",
      "Class 13 - Acc: 0.8645, IoU: 0.7857\n",
      "Class 14 - Acc: 0.8431, IoU: 0.6850\n",
      "Class 15 - Acc: 0.8588, IoU: 0.6215\n",
      "Class 16 - Acc: 0.8244, IoU: 0.6456\n",
      "Class 17 - Acc: 0.6915, IoU: 0.4601\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:54<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n",
      "Loss: 0.2384\n",
      "Pixel Accuracy: 0.9212\n",
      "Mean Class Accuracy: 0.7461\n",
      "Mean IoU: 0.5463\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9792, IoU: 0.9651\n",
      "Class  1 - Acc: 0.8003, IoU: 0.6570\n",
      "Class  2 - Acc: 0.8676, IoU: 0.8046\n",
      "Class  3 - Acc: 0.7646, IoU: 0.5680\n",
      "Class  4 - Acc: 0.6511, IoU: 0.3756\n",
      "Class  5 - Acc: 0.6094, IoU: 0.2464\n",
      "Class  6 - Acc: 0.6011, IoU: 0.1955\n",
      "Class  7 - Acc: 0.7666, IoU: 0.4080\n",
      "Class  8 - Acc: 0.8227, IoU: 0.7088\n",
      "Class  9 - Acc: 0.8097, IoU: 0.6568\n",
      "Class 10 - Acc: 0.9464, IoU: 0.9122\n",
      "Class 11 - Acc: 0.6510, IoU: 0.3866\n",
      "Class 12 - Acc: 0.7656, IoU: 0.0348\n",
      "Class 13 - Acc: 0.8730, IoU: 0.7972\n",
      "Class 14 - Acc: 0.8622, IoU: 0.7193\n",
      "Class 15 - Acc: 0.9052, IoU: 0.7095\n",
      "Class 16 - Acc: 0.8661, IoU: 0.7244\n",
      "Class 17 - Acc: 0.6333, IoU: 0.5092\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:52<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n",
      "Loss: 0.2280\n",
      "Pixel Accuracy: 0.9239\n",
      "Mean Class Accuracy: 0.7501\n",
      "Mean IoU: 0.5702\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9801, IoU: 0.9665\n",
      "Class  1 - Acc: 0.8071, IoU: 0.6662\n",
      "Class  2 - Acc: 0.8732, IoU: 0.8117\n",
      "Class  3 - Acc: 0.7767, IoU: 0.5867\n",
      "Class  4 - Acc: 0.6618, IoU: 0.3966\n",
      "Class  5 - Acc: 0.6204, IoU: 0.2616\n",
      "Class  6 - Acc: 0.6247, IoU: 0.2174\n",
      "Class  7 - Acc: 0.7690, IoU: 0.4349\n",
      "Class  8 - Acc: 0.8273, IoU: 0.7146\n",
      "Class  9 - Acc: 0.8156, IoU: 0.6670\n",
      "Class 10 - Acc: 0.9482, IoU: 0.9142\n",
      "Class 11 - Acc: 0.6630, IoU: 0.3984\n",
      "Class 12 - Acc: 0.7089, IoU: 0.2898\n",
      "Class 13 - Acc: 0.8784, IoU: 0.8042\n",
      "Class 14 - Acc: 0.8755, IoU: 0.7419\n",
      "Class 15 - Acc: 0.8709, IoU: 0.6983\n",
      "Class 16 - Acc: 0.8630, IoU: 0.7175\n",
      "Class 17 - Acc: 0.6885, IoU: 0.5459\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# First, let's create a simple decoder network\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "class SegmentationDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels=2048, num_classes=19):\n",
    "        super().__init__()\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            # 16x32 -> 32x64\n",
    "            torch.nn.ConvTranspose2d(in_channels, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(1024),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 32x64 -> 64x128\n",
    "            torch.nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 64x128 -> 128x256\n",
    "            torch.nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 128x256 -> 256x512\n",
    "            torch.nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 256x512 -> 512x1024\n",
    "            torch.nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # Final 1x1 conv to get to num_classes\n",
    "            torch.nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        # Ensure exact output size\n",
    "        if x.shape[-2:] != (512, 1024):\n",
    "            x = torch.nn.functional.interpolate(\n",
    "                x, size=(512, 1024), \n",
    "                mode='bilinear', \n",
    "                align_corners=False\n",
    "            )\n",
    "        return x\n",
    "\n",
    "# Initialize decoder, optimizer, and loss function\n",
    "decoder = SegmentationDecoder().to(device)\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "def fast_hist(a: np.ndarray, b: np.ndarray, n: int) -> np.ndarray:\n",
    "    k = (b >= 0) & (b < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "def per_class_iou(hist: np.ndarray) -> np.ndarray:\n",
    "    epsilon = 1e-5\n",
    "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)\n",
    "\n",
    "def train_epoch(encoder, decoder, dataloader, optimizer, criterion, device, num_classes=19):\n",
    "    decoder.train()\n",
    "    encoder.eval()  # Keep DINO frozen\n",
    "    \n",
    "    total_loss = 0\n",
    "    hist = np.zeros((num_classes, num_classes))  # Single histogram for entire epoch\n",
    "    total_pixels = 0\n",
    "    correct_pixels = 0\n",
    "    \n",
    "    for images, labels in tqdm.tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Get DINO features\n",
    "        with torch.no_grad():\n",
    "            features = encoder(images)[\"feature_map\"]\n",
    "        \n",
    "        # Forward pass through decoder\n",
    "        outputs = decoder(features)\n",
    "        \n",
    "        # Resize outputs to match label size if needed\n",
    "        if outputs.shape[-2:] != labels.shape[-2:]:\n",
    "            outputs = torch.nn.functional.interpolate(\n",
    "                outputs, size=labels.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        preds = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
    "        \n",
    "        # Pixel Accuracy\n",
    "        valid_mask = labels != 255  # Ignore index\n",
    "        total_pixels += valid_mask.sum().item()\n",
    "        correct_pixels += ((preds == labels) & valid_mask).sum().item()\n",
    "        \n",
    "        # IoU\n",
    "        preds = preds.cpu().numpy()\n",
    "        target = labels.cpu().numpy()\n",
    "        hist += fast_hist(preds.flatten(), target.flatten(), num_classes)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    pixel_acc = correct_pixels / total_pixels\n",
    "    \n",
    "    # Per-class accuracy (mean class accuracy)\n",
    "    class_acc = np.diag(hist) / (hist.sum(1) + np.finfo(np.float32).eps)\n",
    "    mean_class_acc = np.nanmean(class_acc)\n",
    "    \n",
    "    # IoU metrics\n",
    "    iou = per_class_iou(hist)\n",
    "    mean_iou = np.nanmean(iou)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'pixel_acc': pixel_acc,\n",
    "        'mean_class_acc': mean_class_acc,\n",
    "        'mean_iou': mean_iou,\n",
    "        'class_iou': iou,\n",
    "        'class_acc': class_acc\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    GTA5_dataset, \n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    metrics = train_epoch(encoder, decoder, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    print(f\"Pixel Accuracy: {metrics['pixel_acc']:.4f}\")\n",
    "    print(f\"Mean Class Accuracy: {metrics['mean_class_acc']:.4f}\")\n",
    "    print(f\"Mean IoU: {metrics['mean_iou']:.4f}\")\n",
    "    \n",
    "    # Optionally print per-class metrics\n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    for i in range(19):  # Assuming 19 classes\n",
    "        print(f\"Class {i:2d} - Acc: {metrics['class_acc'][i]:.4f}, IoU: {metrics['class_iou'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 3/10\n",
    "# Loss: 1.2027\n",
    "# Pixel Accuracy: 0.6440\n",
    "# Mean Class Accuracy: 0.1213\n",
    "# Mean IoU: 0.0818\n",
    "\n",
    "# Per-class metrics:\n",
    "# Class  0 - Acc: 0.6736, IoU: 0.6670\n",
    "# Class  1 - Acc: 0.1000, IoU: 0.0000\n",
    "# Class  2 - Acc: 0.3823, IoU: 0.1999\n",
    "# Class  3 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class  4 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class  5 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class  6 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class  7 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class  8 - Acc: 0.4519, IoU: 0.0889\n",
    "# Class  9 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 10 - Acc: 0.6970, IoU: 0.5976\n",
    "# Class 11 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 12 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 13 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 14 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 15 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 16 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 17 - Acc: 0.0000, IoU: 0.0000\n",
    "# Class 18 - Acc: 0.0000, IoU: 0.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_id_to_color' from 'datasets' (/home/arda/miniconda3/envs/dinov2/lib/python3.9/site-packages/datasets/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_id_to_color   \n\u001b[1;32m      5\u001b[0m img_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m310\u001b[39m\n\u001b[1;32m      7\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m encoder(GTA5_dataset[img_idx][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device), n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, reshape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_class_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_id_to_color' from 'datasets' (/home/arda/miniconda3/envs/dinov2/lib/python3.9/site-packages/datasets/__init__.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datasets import get_id_to_color   \n",
    "\n",
    "\n",
    "img_idx = 310\n",
    "\n",
    "embeddings = encoder(GTA5_dataset[img_idx][0].unsqueeze(0).to(device), n=1, reshape=True, return_class_token=False, norm=False)[0]\n",
    "out = decoder(embeddings)\n",
    "id_to_color = get_id_to_color()\n",
    "\n",
    "pred = out.argmax(1).cpu().numpy()\n",
    "pred = pred.reshape(518, 1036)\n",
    "# Convert class IDs to RGB colors\n",
    "color_map = np.array([id_to_color.get(i, (0, 0, 0)) for i in range(max(id_to_color.keys()) + 1)])\n",
    "pred_rgb = color_map[pred]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(pred_rgb)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "labels = GTA5_dataset[img_idx][1].cpu().numpy()\n",
    "color_map = np.array([id_to_color.get(i, (0, 0, 0)) for i in range(max(id_to_color.keys()) + 1)])\n",
    "pred_rgb = np.zeros((*labels.shape, 3), dtype=np.uint8)\n",
    "mask = labels < len(color_map)\n",
    "pred_rgb[mask] = color_map[labels[mask]]\n",
    "plt.imshow(pred_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([518, 1036])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GTA5_dataset[img_idx][1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
