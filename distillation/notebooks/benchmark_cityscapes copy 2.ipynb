{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets_gta5 import GTA5, CityScapes\n",
    "import albumentations as A\n",
    "import torch\n",
    "\n",
    "CITYSCAPES_PATH = '/home/arda/.cache/kagglehub/datasets/ardaerendoru/gtagta/versions/1/Cityscapes/Cityscapes'\n",
    "\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(512, 1024),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "CITYSCAPES_dataset = CityScapes(CITYSCAPES_PATH, train_val='train', transform=transform)\n",
    "\n",
    "\n",
    "def load_student_checkpoint(checkpoint_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load and process student model checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path (str): Path to the checkpoint file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processed state dict containing only student model weights\n",
    "    \"\"\"\n",
    "    # Load checkpoint\n",
    "    state_dict = torch.load(checkpoint_path)\n",
    "    \n",
    "    # Extract and process student weights\n",
    "    student_state_dict = {k.replace('student.model.', ''): v \n",
    "                         for k, v in state_dict['state_dict'].items() \n",
    "                         if k.startswith('student') and not k.startswith('student.feature_matchers')}\n",
    "    \n",
    "    return student_state_dict\n",
    "\n",
    "# Load checkpoint and save state dict\n",
    "# checkpoint_path = '/home/arda/dinov2/distillation/logs/resnet50/distillation/version_7/checkpoints/epoch=24-val_similarity=0.37.ckpt'\n",
    "# student_state_dict = load_student_checkpoint(checkpoint_path)\n",
    "# torch.save(student_state_dict, '/home/arda/dinov2/distillation/logs/resnet50/distillation/version_7/checkpoints/student_state_dict.pth')\n",
    "# student_state_dict.keys()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.resnet_wrapper import ResNetWrapper\n",
    "import torchvision\n",
    "encoder = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "# encoder = torchvision.models.resnet50(pretrained=True)\n",
    "encoder = torch.nn.Sequential(*list(encoder.children())[:-2])  # Remove pooling and fc layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoder.eval()\n",
    "encoder.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0212, 0.0141, 0.0000,  ..., 0.2158, 0.1861, 0.0000],\n",
       "          [0.0000, 0.1595, 0.2351,  ..., 0.1786, 0.0847, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1378, 0.0811],\n",
       "          [0.0893, 0.0688, 0.0000,  ..., 0.1983, 0.4144, 0.4044],\n",
       "          [0.2365, 0.3231, 0.3871,  ..., 0.5128, 0.6075, 0.6301]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0675, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.1769,  ..., 0.2568, 0.1633, 0.0000],\n",
       "          [0.1378, 0.2916, 0.4574,  ..., 0.3505, 0.1265, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0673,  ..., 0.3052, 0.2187, 0.0205],\n",
       "          [0.0000, 0.0000, 0.0347,  ..., 0.2146, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0040]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.1675, 0.3418, 0.4222,  ..., 0.4254, 0.3589, 0.2697],\n",
       "          [0.1726, 0.1477, 0.2724,  ..., 0.4953, 0.3270, 0.3492],\n",
       "          [0.0498, 0.0130, 0.1011,  ..., 0.2174, 0.0207, 0.1155],\n",
       "          ...,\n",
       "          [0.0361, 0.0465, 0.0415,  ..., 0.1157, 0.1648, 0.3474],\n",
       "          [0.3851, 0.5125, 0.4933,  ..., 0.3762, 0.4142, 0.5944],\n",
       "          [0.4107, 0.4623, 0.4745,  ..., 0.3192, 0.4577, 0.5115]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0516,  ..., 0.1668, 0.0564, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3739,  ..., 0.5439, 0.3673, 0.0554],\n",
       "          [0.2246, 0.5510, 0.9680,  ..., 1.2862, 0.8617, 0.4454],\n",
       "          ...,\n",
       "          [0.0800, 0.5305, 1.0532,  ..., 1.2534, 0.9125, 0.4479],\n",
       "          [0.2135, 0.7363, 1.2434,  ..., 1.5443, 1.1548, 0.5782],\n",
       "          [0.1095, 0.4412, 0.9944,  ..., 1.1598, 0.8576, 0.4737]]]],\n",
       "       device='cuda:1', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd = torch.randn(1, 3, 512, 1024).to(device)\n",
    "encoder(asd)\n",
    "\n",
    "# # # Freeze all parameters of the encoder\n",
    "# for param in encoder.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e0808805bd4a75b91467995c003e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Loss: 1.0925\n",
      "Pixel Accuracy: 0.8250\n",
      "Mean Class Accuracy: 0.2539\n",
      "Mean IoU: 0.2155\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9333, IoU: 0.8834\n",
      "Class  1 - Acc: 0.6320, IoU: 0.4549\n",
      "Class  2 - Acc: 0.8220, IoU: 0.7669\n",
      "Class  3 - Acc: 0.0146, IoU: 0.0001\n",
      "Class  4 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  5 - Acc: 0.0178, IoU: 0.0001\n",
      "Class  6 - Acc: 0.0005, IoU: 0.0001\n",
      "Class  7 - Acc: 0.0055, IoU: 0.0004\n",
      "Class  8 - Acc: 0.8338, IoU: 0.7382\n",
      "Class  9 - Acc: 0.0074, IoU: 0.0005\n",
      "Class 10 - Acc: 0.8233, IoU: 0.6128\n",
      "Class 11 - Acc: 0.0176, IoU: 0.0004\n",
      "Class 12 - Acc: 0.0108, IoU: 0.0057\n",
      "Class 13 - Acc: 0.6775, IoU: 0.6276\n",
      "Class 14 - Acc: 0.0025, IoU: 0.0020\n",
      "Class 15 - Acc: 0.0028, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0005, IoU: 0.0000\n",
      "Class 17 - Acc: 0.0027, IoU: 0.0020\n",
      "Class 18 - Acc: 0.0199, IoU: 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2cdba6ef2c4fc3ab14e96a853aaccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "Loss: 0.5447\n",
      "Pixel Accuracy: 0.8854\n",
      "Mean Class Accuracy: 0.3830\n",
      "Mean IoU: 0.2704\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9699, IoU: 0.9448\n",
      "Class  1 - Acc: 0.7202, IoU: 0.6388\n",
      "Class  2 - Acc: 0.8488, IoU: 0.8156\n",
      "Class  3 - Acc: 0.2197, IoU: 0.0023\n",
      "Class  4 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  5 - Acc: 0.2267, IoU: 0.0019\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0850, IoU: 0.0052\n",
      "Class  8 - Acc: 0.8706, IoU: 0.8195\n",
      "Class  9 - Acc: 0.0222, IoU: 0.0003\n",
      "Class 10 - Acc: 0.8605, IoU: 0.8129\n",
      "Class 11 - Acc: 0.7324, IoU: 0.2778\n",
      "Class 12 - Acc: 0.0185, IoU: 0.0031\n",
      "Class 13 - Acc: 0.8484, IoU: 0.8001\n",
      "Class 14 - Acc: 0.0045, IoU: 0.0000\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 17 - Acc: 0.0803, IoU: 0.0157\n",
      "Class 18 - Acc: 0.7692, IoU: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990be05c463f4156bc141cc25f4221f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n",
      "Loss: 0.4005\n",
      "Pixel Accuracy: 0.9020\n",
      "Mean Class Accuracy: 0.5113\n",
      "Mean IoU: 0.3197\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9760, IoU: 0.9553\n",
      "Class  1 - Acc: 0.8015, IoU: 0.7176\n",
      "Class  2 - Acc: 0.8747, IoU: 0.8412\n",
      "Class  3 - Acc: 0.2969, IoU: 0.0194\n",
      "Class  4 - Acc: 0.4698, IoU: 0.0206\n",
      "Class  5 - Acc: 0.4092, IoU: 0.1434\n",
      "Class  6 - Acc: 0.4286, IoU: 0.0000\n",
      "Class  7 - Acc: 0.7664, IoU: 0.0786\n",
      "Class  8 - Acc: 0.8761, IoU: 0.8322\n",
      "Class  9 - Acc: 0.6666, IoU: 0.1855\n",
      "Class 10 - Acc: 0.9343, IoU: 0.8853\n",
      "Class 11 - Acc: 0.7321, IoU: 0.5781\n",
      "Class 12 - Acc: 0.0232, IoU: 0.0002\n",
      "Class 13 - Acc: 0.8522, IoU: 0.8151\n",
      "Class 14 - Acc: 0.0259, IoU: 0.0000\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 17 - Acc: 0.1122, IoU: 0.0003\n",
      "Class 18 - Acc: 0.4692, IoU: 0.0016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae4b79f2bcd43809b62911861366656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n",
      "Loss: 0.3208\n",
      "Pixel Accuracy: 0.9169\n",
      "Mean Class Accuracy: 0.5693\n",
      "Mean IoU: 0.4014\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9787, IoU: 0.9607\n",
      "Class  1 - Acc: 0.8477, IoU: 0.7570\n",
      "Class  2 - Acc: 0.9035, IoU: 0.8685\n",
      "Class  3 - Acc: 0.4271, IoU: 0.1017\n",
      "Class  4 - Acc: 0.4895, IoU: 0.2524\n",
      "Class  5 - Acc: 0.5942, IoU: 0.2640\n",
      "Class  6 - Acc: 0.8340, IoU: 0.0101\n",
      "Class  7 - Acc: 0.7153, IoU: 0.4072\n",
      "Class  8 - Acc: 0.9112, IoU: 0.8608\n",
      "Class  9 - Acc: 0.7011, IoU: 0.4697\n",
      "Class 10 - Acc: 0.9504, IoU: 0.9085\n",
      "Class 11 - Acc: 0.7403, IoU: 0.6165\n",
      "Class 12 - Acc: 0.0811, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8749, IoU: 0.8376\n",
      "Class 14 - Acc: 0.1875, IoU: 0.0001\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.5805, IoU: 0.3111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f81fa4d12e4db5ae25182ba1c904dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n",
      "Loss: 0.2748\n",
      "Pixel Accuracy: 0.9247\n",
      "Mean Class Accuracy: 0.6589\n",
      "Mean IoU: 0.4457\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9811, IoU: 0.9641\n",
      "Class  1 - Acc: 0.8695, IoU: 0.7835\n",
      "Class  2 - Acc: 0.9158, IoU: 0.8784\n",
      "Class  3 - Acc: 0.5393, IoU: 0.2383\n",
      "Class  4 - Acc: 0.5712, IoU: 0.3390\n",
      "Class  5 - Acc: 0.6505, IoU: 0.3242\n",
      "Class  6 - Acc: 0.7641, IoU: 0.1565\n",
      "Class  7 - Acc: 0.7253, IoU: 0.4891\n",
      "Class  8 - Acc: 0.9212, IoU: 0.8726\n",
      "Class  9 - Acc: 0.7496, IoU: 0.5518\n",
      "Class 10 - Acc: 0.9485, IoU: 0.9064\n",
      "Class 11 - Acc: 0.7468, IoU: 0.6294\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8918, IoU: 0.8545\n",
      "Class 14 - Acc: 0.3498, IoU: 0.0050\n",
      "Class 15 - Acc: 0.8054, IoU: 0.0021\n",
      "Class 16 - Acc: 0.4835, IoU: 0.0028\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.6054, IoU: 0.4708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5305f790e09540d19e8c6b1fc8ca4cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n",
      "Loss: 0.2403\n",
      "Pixel Accuracy: 0.9315\n",
      "Mean Class Accuracy: 0.6507\n",
      "Mean IoU: 0.4890\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9820, IoU: 0.9664\n",
      "Class  1 - Acc: 0.8806, IoU: 0.7943\n",
      "Class  2 - Acc: 0.9276, IoU: 0.8914\n",
      "Class  3 - Acc: 0.6490, IoU: 0.3822\n",
      "Class  4 - Acc: 0.6604, IoU: 0.4315\n",
      "Class  5 - Acc: 0.6780, IoU: 0.3619\n",
      "Class  6 - Acc: 0.6902, IoU: 0.3300\n",
      "Class  7 - Acc: 0.7944, IoU: 0.5492\n",
      "Class  8 - Acc: 0.9273, IoU: 0.8801\n",
      "Class  9 - Acc: 0.7591, IoU: 0.5696\n",
      "Class 10 - Acc: 0.9547, IoU: 0.9170\n",
      "Class 11 - Acc: 0.7720, IoU: 0.6628\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.9056, IoU: 0.8690\n",
      "Class 14 - Acc: 0.4647, IoU: 0.1399\n",
      "Class 15 - Acc: 0.1896, IoU: 0.0018\n",
      "Class 16 - Acc: 0.4095, IoU: 0.0520\n",
      "Class 17 - Acc: 0.1250, IoU: 0.0000\n",
      "Class 18 - Acc: 0.5942, IoU: 0.4916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eaa8ac8b634861ab99a41a29eb5898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n",
      "Loss: 0.2089\n",
      "Pixel Accuracy: 0.9392\n",
      "Mean Class Accuracy: 0.7336\n",
      "Mean IoU: 0.5295\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9859, IoU: 0.9726\n",
      "Class  1 - Acc: 0.9012, IoU: 0.8298\n",
      "Class  2 - Acc: 0.9380, IoU: 0.9029\n",
      "Class  3 - Acc: 0.7254, IoU: 0.4954\n",
      "Class  4 - Acc: 0.7104, IoU: 0.5000\n",
      "Class  5 - Acc: 0.6972, IoU: 0.3927\n",
      "Class  6 - Acc: 0.6896, IoU: 0.3745\n",
      "Class  7 - Acc: 0.7981, IoU: 0.5661\n",
      "Class  8 - Acc: 0.9335, IoU: 0.8881\n",
      "Class  9 - Acc: 0.7796, IoU: 0.6132\n",
      "Class 10 - Acc: 0.9583, IoU: 0.9234\n",
      "Class 11 - Acc: 0.7854, IoU: 0.6804\n",
      "Class 12 - Acc: 0.7092, IoU: 0.0080\n",
      "Class 13 - Acc: 0.9215, IoU: 0.8820\n",
      "Class 14 - Acc: 0.4576, IoU: 0.2350\n",
      "Class 15 - Acc: 0.0227, IoU: 0.0000\n",
      "Class 16 - Acc: 0.5411, IoU: 0.2726\n",
      "Class 17 - Acc: 0.7723, IoU: 0.0011\n",
      "Class 18 - Acc: 0.6120, IoU: 0.5234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d4c2aefc3442b3aee4125b19c0b47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n",
      "Loss: 0.1941\n",
      "Pixel Accuracy: 0.9417\n",
      "Mean Class Accuracy: 0.7760\n",
      "Mean IoU: 0.5683\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9853, IoU: 0.9716\n",
      "Class  1 - Acc: 0.9000, IoU: 0.8243\n",
      "Class  2 - Acc: 0.9422, IoU: 0.9066\n",
      "Class  3 - Acc: 0.7435, IoU: 0.5203\n",
      "Class  4 - Acc: 0.7343, IoU: 0.5280\n",
      "Class  5 - Acc: 0.7138, IoU: 0.4199\n",
      "Class  6 - Acc: 0.6852, IoU: 0.4073\n",
      "Class  7 - Acc: 0.8111, IoU: 0.5926\n",
      "Class  8 - Acc: 0.9346, IoU: 0.8905\n",
      "Class  9 - Acc: 0.7876, IoU: 0.6253\n",
      "Class 10 - Acc: 0.9570, IoU: 0.9195\n",
      "Class 11 - Acc: 0.7925, IoU: 0.6838\n",
      "Class 12 - Acc: 0.6662, IoU: 0.1942\n",
      "Class 13 - Acc: 0.9445, IoU: 0.9082\n",
      "Class 14 - Acc: 0.5465, IoU: 0.3848\n",
      "Class 15 - Acc: 0.5594, IoU: 0.0082\n",
      "Class 16 - Acc: 0.5207, IoU: 0.3639\n",
      "Class 17 - Acc: 0.8717, IoU: 0.1009\n",
      "Class 18 - Acc: 0.6473, IoU: 0.5480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845d4febfd6d455aa3d066d68770b8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n",
      "Loss: 0.1651\n",
      "Pixel Accuracy: 0.9495\n",
      "Mean Class Accuracy: 0.8138\n",
      "Mean IoU: 0.6284\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9877, IoU: 0.9758\n",
      "Class  1 - Acc: 0.9136, IoU: 0.8467\n",
      "Class  2 - Acc: 0.9506, IoU: 0.9179\n",
      "Class  3 - Acc: 0.7955, IoU: 0.5987\n",
      "Class  4 - Acc: 0.7807, IoU: 0.6031\n",
      "Class  5 - Acc: 0.7322, IoU: 0.4535\n",
      "Class  6 - Acc: 0.7228, IoU: 0.4516\n",
      "Class  7 - Acc: 0.8253, IoU: 0.6220\n",
      "Class  8 - Acc: 0.9410, IoU: 0.9005\n",
      "Class  9 - Acc: 0.8268, IoU: 0.6775\n",
      "Class 10 - Acc: 0.9613, IoU: 0.9281\n",
      "Class 11 - Acc: 0.8274, IoU: 0.7240\n",
      "Class 12 - Acc: 0.6658, IoU: 0.3621\n",
      "Class 13 - Acc: 0.9544, IoU: 0.9222\n",
      "Class 14 - Acc: 0.6454, IoU: 0.5188\n",
      "Class 15 - Acc: 0.8196, IoU: 0.0579\n",
      "Class 16 - Acc: 0.6389, IoU: 0.5182\n",
      "Class 17 - Acc: 0.7746, IoU: 0.2719\n",
      "Class 18 - Acc: 0.6986, IoU: 0.5890\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55ca9860a7942f7b62d28a692a89218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n",
      "Loss: 0.1515\n",
      "Pixel Accuracy: 0.9527\n",
      "Mean Class Accuracy: 0.8330\n",
      "Mean IoU: 0.6640\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9883, IoU: 0.9773\n",
      "Class  1 - Acc: 0.9200, IoU: 0.8551\n",
      "Class  2 - Acc: 0.9547, IoU: 0.9239\n",
      "Class  3 - Acc: 0.8204, IoU: 0.6405\n",
      "Class  4 - Acc: 0.8081, IoU: 0.6445\n",
      "Class  5 - Acc: 0.7439, IoU: 0.4724\n",
      "Class  6 - Acc: 0.7384, IoU: 0.4752\n",
      "Class  7 - Acc: 0.8364, IoU: 0.6432\n",
      "Class  8 - Acc: 0.9434, IoU: 0.9036\n",
      "Class  9 - Acc: 0.8194, IoU: 0.6683\n",
      "Class 10 - Acc: 0.9629, IoU: 0.9305\n",
      "Class 11 - Acc: 0.8365, IoU: 0.7350\n",
      "Class 12 - Acc: 0.7009, IoU: 0.4385\n",
      "Class 13 - Acc: 0.9544, IoU: 0.9223\n",
      "Class 14 - Acc: 0.7445, IoU: 0.5843\n",
      "Class 15 - Acc: 0.8245, IoU: 0.0964\n",
      "Class 16 - Acc: 0.6154, IoU: 0.5346\n",
      "Class 17 - Acc: 0.8647, IoU: 0.5406\n",
      "Class 18 - Acc: 0.7510, IoU: 0.6294\n"
     ]
    }
   ],
   "source": [
    "# First, let's create a simple decoder network\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "class SegmentationDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels=2048, num_classes=19):\n",
    "        super().__init__()\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            # 16x32 -> 32x64\n",
    "            torch.nn.ConvTranspose2d(in_channels, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(1024),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 32x64 -> 64x128\n",
    "            torch.nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 64x128 -> 128x256\n",
    "            torch.nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 128x256 -> 256x512\n",
    "            torch.nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 256x512 -> 512x1024\n",
    "            torch.nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # Final 1x1 conv to get to num_classes\n",
    "            torch.nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        # Ensure exact output size\n",
    "        if x.shape[-2:] != (512, 1024):\n",
    "            x = torch.nn.functional.interpolate(\n",
    "                x, size=(512, 1024), \n",
    "                mode='bilinear', \n",
    "                align_corners=False\n",
    "            )\n",
    "        return x\n",
    "\n",
    "# Initialize decoder, optimizer, and loss function\n",
    "decoder = SegmentationDecoder().to(device)\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "def fast_hist(a: np.ndarray, b: np.ndarray, n: int) -> np.ndarray:\n",
    "    k = (b >= 0) & (b < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "def per_class_iou(hist: np.ndarray) -> np.ndarray:\n",
    "    epsilon = 1e-5\n",
    "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)\n",
    "\n",
    "def train_epoch(encoder, decoder, dataloader, optimizer, criterion, device, num_classes=19):\n",
    "    decoder.train()\n",
    "    encoder.eval()  # Keep DINO frozen\n",
    "    \n",
    "    total_loss = 0\n",
    "    hist = np.zeros((num_classes, num_classes))  # Single histogram for entire epoch\n",
    "    total_pixels = 0\n",
    "    correct_pixels = 0\n",
    "    \n",
    "    for images, labels in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Get DINO features\n",
    "        # with torch.no_grad():\n",
    "        features = encoder(images)\n",
    "        \n",
    "        # Forward pass through decoder\n",
    "        outputs = decoder(features)\n",
    "        \n",
    "        # Resize outputs to match label size if needed\n",
    "        if outputs.shape[-2:] != labels.shape[-2:]:\n",
    "            outputs = torch.nn.functional.interpolate(\n",
    "                outputs, size=labels.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        preds = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
    "        \n",
    "        # Pixel Accuracy\n",
    "        valid_mask = labels != 255  # Ignore index\n",
    "        total_pixels += valid_mask.sum().item()\n",
    "        correct_pixels += ((preds == labels) & valid_mask).sum().item()\n",
    "        \n",
    "        # IoU\n",
    "        preds = preds.cpu().numpy()\n",
    "        target = labels.cpu().numpy()\n",
    "        hist += fast_hist(preds.flatten(), target.flatten(), num_classes)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    pixel_acc = correct_pixels / total_pixels\n",
    "    \n",
    "    # Per-class accuracy (mean class accuracy)\n",
    "    class_acc = np.diag(hist) / (hist.sum(1) + np.finfo(np.float32).eps)\n",
    "    mean_class_acc = np.nanmean(class_acc)\n",
    "    \n",
    "    # IoU metrics\n",
    "    iou = per_class_iou(hist)\n",
    "    mean_iou = np.nanmean(iou)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'pixel_acc': pixel_acc,\n",
    "        'mean_class_acc': mean_class_acc,\n",
    "        'mean_iou': mean_iou,\n",
    "        'class_iou': iou,\n",
    "        'class_acc': class_acc\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CITYSCAPES_dataset, \n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    metrics = train_epoch(encoder, decoder, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    print(f\"Pixel Accuracy: {metrics['pixel_acc']:.4f}\")\n",
    "    print(f\"Mean Class Accuracy: {metrics['mean_class_acc']:.4f}\")\n",
    "    print(f\"Mean IoU: {metrics['mean_iou']:.4f}\")\n",
    "    \n",
    "    # Optionally print per-class metrics\n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    for i in range(19):  # Assuming 19 classes\n",
    "        print(f\"Class {i:2d} - Acc: {metrics['class_acc'][i]:.4f}, IoU: {metrics['class_iou'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
