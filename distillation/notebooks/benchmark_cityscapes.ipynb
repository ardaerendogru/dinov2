{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arda/miniconda3/envs/dinov2/lib/python3.9/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets_gta5 import GTA5, CityScapes\n",
    "import albumentations as A\n",
    "import torch\n",
    "\n",
    "CITYSCAPES_PATH = '/home/arda/.cache/kagglehub/datasets/ardaerendoru/gtagta/versions/1/Cityscapes/Cityscapes'\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(512, 1024),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "CITYSCAPES_dataset = CityScapes(CITYSCAPES_PATH, train_val='train', transform=transform)\n",
    "\n",
    "\n",
    "def load_student_checkpoint(checkpoint_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load and process student model checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path (str): Path to the checkpoint file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processed state dict containing only student model weights\n",
    "    \"\"\"\n",
    "    # Load checkpoint\n",
    "    state_dict = torch.load(checkpoint_path)\n",
    "    \n",
    "    # Extract and process student weights\n",
    "    student_state_dict = {k.replace('student.model.', ''): v \n",
    "                         for k, v in state_dict['state_dict'].items() \n",
    "                         if k.startswith('student') and not k.startswith('student.feature_matchers')}\n",
    "    \n",
    "    return student_state_dict\n",
    "\n",
    "# Load checkpoint and save state dict\n",
    "checkpoint_path = '/home/arda/dinov2/distillation/logs/stdc2/distillation/version_144/checkpoints/last.ckpt'\n",
    "student_state_dict = load_student_checkpoint(checkpoint_path)\n",
    "# torch.save(student_state_dict, '/home/arda/dinov2/distillation/logs/resnet50/distillation/version_7/checkpoints/student_state_dict.pth')\n",
    "# student_state_dict.keys()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/arda/dinov2/distillation')\n",
    "from models.stdc_wrapper import STDCWrapper\n",
    "encoder = STDCWrapper()\n",
    "encoder.load_state_dict(student_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder.eval()\n",
    "encoder.to(device)\n",
    "encoder.model.eval()\n",
    "encoder = encoder.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = torch.randn(1, 3, 512, 1024).to(device)\n",
    "encoder(asd)[\"res5\"].shape\n",
    "\n",
    "# # Freeze all parameters of the encoder\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:59<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Loss: 1.1482\n",
      "Pixel Accuracy: 0.8062\n",
      "Mean Class Accuracy: 0.2691\n",
      "Mean IoU: 0.2060\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9333, IoU: 0.8824\n",
      "Class  1 - Acc: 0.5396, IoU: 0.4129\n",
      "Class  2 - Acc: 0.8299, IoU: 0.7430\n",
      "Class  3 - Acc: 0.0137, IoU: 0.0007\n",
      "Class  4 - Acc: 0.0202, IoU: 0.0008\n",
      "Class  5 - Acc: 0.0323, IoU: 0.0016\n",
      "Class  6 - Acc: 0.0010, IoU: 0.0008\n",
      "Class  7 - Acc: 0.0051, IoU: 0.0013\n",
      "Class  8 - Acc: 0.7395, IoU: 0.6839\n",
      "Class  9 - Acc: 0.3263, IoU: 0.0159\n",
      "Class 10 - Acc: 0.8010, IoU: 0.5600\n",
      "Class 11 - Acc: 0.0605, IoU: 0.0205\n",
      "Class 12 - Acc: 0.0013, IoU: 0.0003\n",
      "Class 13 - Acc: 0.7810, IoU: 0.5808\n",
      "Class 14 - Acc: 0.0070, IoU: 0.0001\n",
      "Class 15 - Acc: 0.0032, IoU: 0.0004\n",
      "Class 16 - Acc: 0.0001, IoU: 0.0001\n",
      "Class 17 - Acc: 0.0020, IoU: 0.0006\n",
      "Class 18 - Acc: 0.0160, IoU: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:59<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "Loss: 0.6058\n",
      "Pixel Accuracy: 0.8665\n",
      "Mean Class Accuracy: 0.3939\n",
      "Mean IoU: 0.2810\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9522, IoU: 0.9181\n",
      "Class  1 - Acc: 0.7002, IoU: 0.5675\n",
      "Class  2 - Acc: 0.8410, IoU: 0.7895\n",
      "Class  3 - Acc: 0.0377, IoU: 0.0001\n",
      "Class  4 - Acc: 0.5044, IoU: 0.0051\n",
      "Class  5 - Acc: 0.0446, IoU: 0.0005\n",
      "Class  6 - Acc: 0.0075, IoU: 0.0016\n",
      "Class  7 - Acc: 0.1253, IoU: 0.0006\n",
      "Class  8 - Acc: 0.8372, IoU: 0.7698\n",
      "Class  9 - Acc: 0.5755, IoU: 0.3032\n",
      "Class 10 - Acc: 0.8786, IoU: 0.8005\n",
      "Class 11 - Acc: 0.6337, IoU: 0.3313\n",
      "Class 12 - Acc: 0.0037, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8140, IoU: 0.7533\n",
      "Class 14 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 15 - Acc: 0.0224, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 17 - Acc: 0.0005, IoU: 0.0000\n",
      "Class 18 - Acc: 0.5051, IoU: 0.0972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:59<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n",
      "Loss: 0.4690\n",
      "Pixel Accuracy: 0.8816\n",
      "Mean Class Accuracy: 0.4825\n",
      "Mean IoU: 0.3277\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9584, IoU: 0.9279\n",
      "Class  1 - Acc: 0.7488, IoU: 0.6120\n",
      "Class  2 - Acc: 0.8497, IoU: 0.8035\n",
      "Class  3 - Acc: 0.3028, IoU: 0.0004\n",
      "Class  4 - Acc: 0.5300, IoU: 0.1452\n",
      "Class  5 - Acc: 0.3054, IoU: 0.0023\n",
      "Class  6 - Acc: 0.0035, IoU: 0.0000\n",
      "Class  7 - Acc: 0.7309, IoU: 0.0163\n",
      "Class  8 - Acc: 0.8591, IoU: 0.7927\n",
      "Class  9 - Acc: 0.6554, IoU: 0.4041\n",
      "Class 10 - Acc: 0.8948, IoU: 0.8207\n",
      "Class 11 - Acc: 0.6690, IoU: 0.5141\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8717, IoU: 0.8115\n",
      "Class 14 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.2222, IoU: 0.0000\n",
      "Class 17 - Acc: 0.0024, IoU: 0.0000\n",
      "Class 18 - Acc: 0.5640, IoU: 0.3758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:45<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n",
      "Loss: 0.4043\n",
      "Pixel Accuracy: 0.8901\n",
      "Mean Class Accuracy: 0.4959\n",
      "Mean IoU: 0.3653\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9606, IoU: 0.9322\n",
      "Class  1 - Acc: 0.7748, IoU: 0.6348\n",
      "Class  2 - Acc: 0.8664, IoU: 0.8186\n",
      "Class  3 - Acc: 0.5150, IoU: 0.0311\n",
      "Class  4 - Acc: 0.5592, IoU: 0.3023\n",
      "Class  5 - Acc: 0.4451, IoU: 0.0710\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.6554, IoU: 0.2719\n",
      "Class  8 - Acc: 0.8781, IoU: 0.8118\n",
      "Class  9 - Acc: 0.6619, IoU: 0.4402\n",
      "Class 10 - Acc: 0.9018, IoU: 0.8295\n",
      "Class 11 - Acc: 0.6815, IoU: 0.5372\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8766, IoU: 0.8180\n",
      "Class 14 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 17 - Acc: 0.0185, IoU: 0.0000\n",
      "Class 18 - Acc: 0.6270, IoU: 0.4418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:57<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n",
      "Loss: 0.3639\n",
      "Pixel Accuracy: 0.8961\n",
      "Mean Class Accuracy: 0.6162\n",
      "Mean IoU: 0.3890\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9629, IoU: 0.9357\n",
      "Class  1 - Acc: 0.7904, IoU: 0.6530\n",
      "Class  2 - Acc: 0.8763, IoU: 0.8280\n",
      "Class  3 - Acc: 0.6182, IoU: 0.1874\n",
      "Class  4 - Acc: 0.6128, IoU: 0.3525\n",
      "Class  5 - Acc: 0.4628, IoU: 0.1155\n",
      "Class  6 - Acc: 0.0513, IoU: 0.0000\n",
      "Class  7 - Acc: 0.6357, IoU: 0.3427\n",
      "Class  8 - Acc: 0.8882, IoU: 0.8219\n",
      "Class  9 - Acc: 0.6847, IoU: 0.4678\n",
      "Class 10 - Acc: 0.9107, IoU: 0.8420\n",
      "Class 11 - Acc: 0.6927, IoU: 0.5565\n",
      "Class 12 - Acc: 1.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8826, IoU: 0.8245\n",
      "Class 14 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0833, IoU: 0.0000\n",
      "Class 17 - Acc: 0.9429, IoU: 0.0001\n",
      "Class 18 - Acc: 0.6122, IoU: 0.4624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:59<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n",
      "Loss: 0.3351\n",
      "Pixel Accuracy: 0.9005\n",
      "Mean Class Accuracy: 0.6994\n",
      "Mean IoU: 0.4035\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9652, IoU: 0.9394\n",
      "Class  1 - Acc: 0.8057, IoU: 0.6701\n",
      "Class  2 - Acc: 0.8833, IoU: 0.8338\n",
      "Class  3 - Acc: 0.6529, IoU: 0.2839\n",
      "Class  4 - Acc: 0.6328, IoU: 0.3817\n",
      "Class  5 - Acc: 0.4969, IoU: 0.1440\n",
      "Class  6 - Acc: 0.0664, IoU: 0.0000\n",
      "Class  7 - Acc: 0.6380, IoU: 0.3604\n",
      "Class  8 - Acc: 0.8919, IoU: 0.8281\n",
      "Class  9 - Acc: 0.7205, IoU: 0.5114\n",
      "Class 10 - Acc: 0.9103, IoU: 0.8389\n",
      "Class 11 - Acc: 0.7037, IoU: 0.5724\n",
      "Class 12 - Acc: 0.7778, IoU: 0.0000\n",
      "Class 13 - Acc: 0.8860, IoU: 0.8317\n",
      "Class 14 - Acc: 0.3256, IoU: 0.0000\n",
      "Class 15 - Acc: 1.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.5882, IoU: 0.0000\n",
      "Class 17 - Acc: 0.7414, IoU: 0.0003\n",
      "Class 18 - Acc: 0.6028, IoU: 0.4708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:57<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n",
      "Loss: 0.3115\n",
      "Pixel Accuracy: 0.9047\n",
      "Mean Class Accuracy: 0.7111\n",
      "Mean IoU: 0.4134\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9673, IoU: 0.9420\n",
      "Class  1 - Acc: 0.8132, IoU: 0.6844\n",
      "Class  2 - Acc: 0.8899, IoU: 0.8423\n",
      "Class  3 - Acc: 0.6550, IoU: 0.3242\n",
      "Class  4 - Acc: 0.6714, IoU: 0.4206\n",
      "Class  5 - Acc: 0.5131, IoU: 0.1608\n",
      "Class  6 - Acc: 0.6680, IoU: 0.0004\n",
      "Class  7 - Acc: 0.6484, IoU: 0.3849\n",
      "Class  8 - Acc: 0.8973, IoU: 0.8349\n",
      "Class  9 - Acc: 0.7201, IoU: 0.5144\n",
      "Class 10 - Acc: 0.9163, IoU: 0.8491\n",
      "Class 11 - Acc: 0.7160, IoU: 0.5857\n",
      "Class 12 - Acc: 0.8618, IoU: 0.0041\n",
      "Class 13 - Acc: 0.8897, IoU: 0.8367\n",
      "Class 14 - Acc: 0.2112, IoU: 0.0018\n",
      "Class 15 - Acc: 1.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.1275, IoU: 0.0001\n",
      "Class 17 - Acc: 0.7679, IoU: 0.0011\n",
      "Class 18 - Acc: 0.5768, IoU: 0.4678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:58<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n",
      "Loss: 0.2939\n",
      "Pixel Accuracy: 0.9083\n",
      "Mean Class Accuracy: 0.6959\n",
      "Mean IoU: 0.4294\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9696, IoU: 0.9455\n",
      "Class  1 - Acc: 0.8235, IoU: 0.6998\n",
      "Class  2 - Acc: 0.8925, IoU: 0.8463\n",
      "Class  3 - Acc: 0.6674, IoU: 0.3440\n",
      "Class  4 - Acc: 0.6844, IoU: 0.4330\n",
      "Class  5 - Acc: 0.5291, IoU: 0.1729\n",
      "Class  6 - Acc: 0.5759, IoU: 0.0004\n",
      "Class  7 - Acc: 0.6614, IoU: 0.3928\n",
      "Class  8 - Acc: 0.9001, IoU: 0.8389\n",
      "Class  9 - Acc: 0.7395, IoU: 0.5398\n",
      "Class 10 - Acc: 0.9193, IoU: 0.8528\n",
      "Class 11 - Acc: 0.7253, IoU: 0.5947\n",
      "Class 12 - Acc: 0.8087, IoU: 0.0945\n",
      "Class 13 - Acc: 0.8963, IoU: 0.8467\n",
      "Class 14 - Acc: 0.5936, IoU: 0.0561\n",
      "Class 15 - Acc: 0.1929, IoU: 0.0000\n",
      "Class 16 - Acc: 0.2280, IoU: 0.0001\n",
      "Class 17 - Acc: 0.8335, IoU: 0.0245\n",
      "Class 18 - Acc: 0.5816, IoU: 0.4747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:45<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n",
      "Loss: 0.2783\n",
      "Pixel Accuracy: 0.9116\n",
      "Mean Class Accuracy: 0.7617\n",
      "Mean IoU: 0.4674\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9698, IoU: 0.9467\n",
      "Class  1 - Acc: 0.8335, IoU: 0.7086\n",
      "Class  2 - Acc: 0.8990, IoU: 0.8512\n",
      "Class  3 - Acc: 0.6977, IoU: 0.3961\n",
      "Class  4 - Acc: 0.7022, IoU: 0.4635\n",
      "Class  5 - Acc: 0.5377, IoU: 0.1842\n",
      "Class  6 - Acc: 0.8475, IoU: 0.0076\n",
      "Class  7 - Acc: 0.6731, IoU: 0.4108\n",
      "Class  8 - Acc: 0.9009, IoU: 0.8420\n",
      "Class  9 - Acc: 0.7524, IoU: 0.5590\n",
      "Class 10 - Acc: 0.9183, IoU: 0.8514\n",
      "Class 11 - Acc: 0.7407, IoU: 0.6085\n",
      "Class 12 - Acc: 0.7053, IoU: 0.2626\n",
      "Class 13 - Acc: 0.9048, IoU: 0.8564\n",
      "Class 14 - Acc: 0.4975, IoU: 0.1844\n",
      "Class 15 - Acc: 0.8755, IoU: 0.0038\n",
      "Class 16 - Acc: 0.5576, IoU: 0.0214\n",
      "Class 17 - Acc: 0.8201, IoU: 0.2078\n",
      "Class 18 - Acc: 0.6383, IoU: 0.5137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:57<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n",
      "Loss: 0.2610\n",
      "Pixel Accuracy: 0.9165\n",
      "Mean Class Accuracy: 0.7726\n",
      "Mean IoU: 0.5073\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.9718, IoU: 0.9496\n",
      "Class  1 - Acc: 0.8389, IoU: 0.7203\n",
      "Class  2 - Acc: 0.9047, IoU: 0.8594\n",
      "Class  3 - Acc: 0.7106, IoU: 0.4210\n",
      "Class  4 - Acc: 0.7314, IoU: 0.4982\n",
      "Class  5 - Acc: 0.5576, IoU: 0.2008\n",
      "Class  6 - Acc: 0.7993, IoU: 0.0609\n",
      "Class  7 - Acc: 0.6991, IoU: 0.4338\n",
      "Class  8 - Acc: 0.9072, IoU: 0.8496\n",
      "Class  9 - Acc: 0.7633, IoU: 0.5684\n",
      "Class 10 - Acc: 0.9253, IoU: 0.8627\n",
      "Class 11 - Acc: 0.7552, IoU: 0.6243\n",
      "Class 12 - Acc: 0.7016, IoU: 0.3323\n",
      "Class 13 - Acc: 0.9169, IoU: 0.8678\n",
      "Class 14 - Acc: 0.5265, IoU: 0.2987\n",
      "Class 15 - Acc: 0.9206, IoU: 0.0847\n",
      "Class 16 - Acc: 0.5714, IoU: 0.1052\n",
      "Class 17 - Acc: 0.8039, IoU: 0.3658\n",
      "Class 18 - Acc: 0.6744, IoU: 0.5353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First, let's create a simple decoder network\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "class SegmentationDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels=1024, num_classes=19):\n",
    "        super().__init__()\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            # 16x32 -> 32x64\n",
    "            torch.nn.ConvTranspose2d(in_channels, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(1024),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 32x64 -> 64x128\n",
    "            torch.nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 64x128 -> 128x256\n",
    "            torch.nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 128x256 -> 256x512\n",
    "            torch.nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 256x512 -> 512x1024\n",
    "            torch.nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # Final 1x1 conv to get to num_classes\n",
    "            torch.nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        # Ensure exact output size\n",
    "        if x.shape[-2:] != (512, 1024):\n",
    "            x = torch.nn.functional.interpolate(\n",
    "                x, size=(512, 1024), \n",
    "                mode='bilinear', \n",
    "                align_corners=False\n",
    "            )\n",
    "        return x\n",
    "\n",
    "# Initialize decoder, optimizer, and loss function\n",
    "decoder = SegmentationDecoder().to(device)\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "def fast_hist(a: np.ndarray, b: np.ndarray, n: int) -> np.ndarray:\n",
    "    k = (b >= 0) & (b < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "def per_class_iou(hist: np.ndarray) -> np.ndarray:\n",
    "    epsilon = 1e-5\n",
    "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)\n",
    "\n",
    "def train_epoch(encoder, decoder, dataloader, optimizer, criterion, device, num_classes=19):\n",
    "    decoder.train()\n",
    "    encoder.train()  # Keep DINO frozen\n",
    "    \n",
    "    total_loss = 0\n",
    "    hist = np.zeros((num_classes, num_classes))  # Single histogram for entire epoch\n",
    "    total_pixels = 0\n",
    "    correct_pixels = 0\n",
    "    \n",
    "    for images, labels in tqdm.tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Get DINO features\n",
    "        # with torch.no_grad():\n",
    "        features = encoder(images)[\"res5\"]\n",
    "        \n",
    "        # Forward pass through decoder\n",
    "        outputs = decoder(features)\n",
    "        \n",
    "        # Resize outputs to match label size if needed\n",
    "        if outputs.shape[-2:] != labels.shape[-2:]:\n",
    "            outputs = torch.nn.functional.interpolate(\n",
    "                outputs, size=labels.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        preds = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
    "        \n",
    "        # Pixel Accuracy\n",
    "        valid_mask = labels != 255  # Ignore index\n",
    "        total_pixels += valid_mask.sum().item()\n",
    "        correct_pixels += ((preds == labels) & valid_mask).sum().item()\n",
    "        \n",
    "        # IoU\n",
    "        preds = preds.cpu().numpy()\n",
    "        target = labels.cpu().numpy()\n",
    "        hist += fast_hist(preds.flatten(), target.flatten(), num_classes)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    pixel_acc = correct_pixels / total_pixels\n",
    "    \n",
    "    # Per-class accuracy (mean class accuracy)\n",
    "    class_acc = np.diag(hist) / (hist.sum(1) + np.finfo(np.float32).eps)\n",
    "    mean_class_acc = np.nanmean(class_acc)\n",
    "    \n",
    "    # IoU metrics\n",
    "    iou = per_class_iou(hist)\n",
    "    mean_iou = np.nanmean(iou)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'pixel_acc': pixel_acc,\n",
    "        'mean_class_acc': mean_class_acc,\n",
    "        'mean_iou': mean_iou,\n",
    "        'class_iou': iou,\n",
    "        'class_acc': class_acc\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CITYSCAPES_dataset, \n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    metrics = train_epoch(encoder, decoder, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    print(f\"Pixel Accuracy: {metrics['pixel_acc']:.4f}\")\n",
    "    print(f\"Mean Class Accuracy: {metrics['mean_class_acc']:.4f}\")\n",
    "    print(f\"Mean IoU: {metrics['mean_iou']:.4f}\")\n",
    "    \n",
    "    # Optionally print per-class metrics\n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    for i in range(19):  # Assuming 19 classes\n",
    "        print(f\"Class {i:2d} - Acc: {metrics['class_acc'][i]:.4f}, IoU: {metrics['class_iou'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1867324368.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Epoch 10/10\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Epoch 1/10\n",
    "Loss: 1.0804\n",
    "Pixel Accuracy: 0.8199\n",
    "Mean Class Accuracy: 0.2722\n",
    "Mean IoU: 0.2217\n",
    "\n",
    "Per-class metrics:\n",
    "Class  0 - Acc: 0.9248, IoU: 0.8810\n",
    "Class  1 - Acc: 0.5940, IoU: 0.4342\n",
    "Class  2 - Acc: 0.8282, IoU: 0.7515\n",
    "Class  3 - Acc: 0.0153, IoU: 0.0037\n",
    "Class  4 - Acc: 0.1686, IoU: 0.0064\n",
    "Class  5 - Acc: 0.0268, IoU: 0.0022\n",
    "Class  6 - Acc: 0.0011, IoU: 0.0002\n",
    "Class  7 - Acc: 0.0038, IoU: 0.0000\n",
    "Class  8 - Acc: 0.8135, IoU: 0.7149\n",
    "Class  9 - Acc: 0.0188, IoU: 0.0061\n",
    "Class 10 - Acc: 0.7689, IoU: 0.6534\n",
    "Class 11 - Acc: 0.2046, IoU: 0.0687\n",
    "Class 12 - Acc: 0.0019, IoU: 0.0009\n",
    "Class 13 - Acc: 0.7896, IoU: 0.6825\n",
    "Class 14 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 15 - Acc: 0.0004, IoU: 0.0000\n",
    "Class 16 - Acc: 0.0039, IoU: 0.0028\n",
    "Class 17 - Acc: 0.0014, IoU: 0.0007\n",
    "Class 18 - Acc: 0.0059, IoU: 0.0032\n",
    "100%|██████████| 393/393 [01:59<00:00,  3.29it/s]\n",
    "\n",
    "Epoch 2/10\n",
    "Loss: 0.5921\n",
    "Pixel Accuracy: 0.8667\n",
    "Mean Class Accuracy: 0.4243\n",
    "Mean IoU: 0.2693\n",
    "\n",
    "Per-class metrics:\n",
    "Class  0 - Acc: 0.9499, IoU: 0.9164\n",
    "Class  1 - Acc: 0.6833, IoU: 0.5565\n",
    "Class  2 - Acc: 0.8429, IoU: 0.7943\n",
    "Class  3 - Acc: 0.1755, IoU: 0.0008\n",
    "Class  4 - Acc: 0.3265, IoU: 0.0441\n",
    "Class  5 - Acc: 0.0000, IoU: 0.0000\n",
    "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
    "Class  7 - Acc: 0.8625, IoU: 0.0008\n",
    "Class  8 - Acc: 0.8498, IoU: 0.7810\n",
    "Class  9 - Acc: 0.6544, IoU: 0.1346\n",
    "Class 10 - Acc: 0.8494, IoU: 0.7781\n",
    "Class 11 - Acc: 0.5073, IoU: 0.3340\n",
    "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 13 - Acc: 0.8419, IoU: 0.7770\n",
    "Class 14 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 17 - Acc: 0.5185, IoU: 0.0000\n",
    "Class 18 - Acc: 0.0000, IoU: 0.0000\n",
    "100%|██████████| 393/393 [01:56<00:00,  3.37it/s]\n",
    "\n",
    "Epoch 3/10\n",
    "Loss: 0.4732\n",
    "Pixel Accuracy: 0.8788\n",
    "Mean Class Accuracy: 0.5255\n",
    "Mean IoU: 0.3166\n",
    "\n",
    "Per-class metrics:\n",
    "Class  0 - Acc: 0.9529, IoU: 0.9216\n",
    "Class  1 - Acc: 0.7350, IoU: 0.5924\n",
    "Class  2 - Acc: 0.8512, IoU: 0.8028\n",
    "Class  3 - Acc: 0.3163, IoU: 0.0065\n",
    "Class  4 - Acc: 0.4898, IoU: 0.2711\n",
    "Class  5 - Acc: 0.6530, IoU: 0.0001\n",
    "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
    "Class  7 - Acc: 0.7375, IoU: 0.1374\n",
    "Class  8 - Acc: 0.8674, IoU: 0.7979\n",
    "Class  9 - Acc: 0.6460, IoU: 0.3652\n",
    "Class 10 - Acc: 0.8977, IoU: 0.8232\n",
    "Class 11 - Acc: 0.6725, IoU: 0.4984\n",
    "Class 12 - Acc: 0.0722, IoU: 0.0000\n",
    "Class 13 - Acc: 0.8550, IoU: 0.7957\n",
    "Class 14 - Acc: 0.4718, IoU: 0.0002\n",
    "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 18 - Acc: 0.7669, IoU: 0.0037\n",
    "100%|██████████| 393/393 [01:59<00:00,  3.29it/s]\n",
    "\n",
    "Epoch 4/10\n",
    "Loss: 0.4095\n",
    "Pixel Accuracy: 0.8876\n",
    "Mean Class Accuracy: 0.5370\n",
    "Mean IoU: 0.3550\n",
    "\n",
    "Per-class metrics:\n",
    "Class  0 - Acc: 0.9565, IoU: 0.9275\n",
    "Class  1 - Acc: 0.7604, IoU: 0.6160\n",
    "Class  2 - Acc: 0.8707, IoU: 0.8215\n",
    "Class  3 - Acc: 0.6204, IoU: 0.0553\n",
    "Class  4 - Acc: 0.5190, IoU: 0.3313\n",
    "Class  5 - Acc: 0.5279, IoU: 0.0226\n",
    "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
    "Class  7 - Acc: 0.6574, IoU: 0.3039\n",
    "Class  8 - Acc: 0.8781, IoU: 0.8118\n",
    "Class  9 - Acc: 0.6756, IoU: 0.4226\n",
    "Class 10 - Acc: 0.9052, IoU: 0.8327\n",
    "Class 11 - Acc: 0.6879, IoU: 0.5296\n",
    "Class 12 - Acc: 0.4548, IoU: 0.0003\n",
    "Class 13 - Acc: 0.8530, IoU: 0.7984\n",
    "Class 14 - Acc: 0.0374, IoU: 0.0000\n",
    "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 17 - Acc: 0.1667, IoU: 0.0000\n",
    "Class 18 - Acc: 0.6328, IoU: 0.2716\n",
    "100%|██████████| 393/393 [02:00<00:00,  3.27it/s]\n",
    "\n",
    "Epoch 5/10\n",
    "Loss: 0.3688\n",
    "Pixel Accuracy: 0.8946\n",
    "Mean Class Accuracy: 0.5375\n",
    "Mean IoU: 0.3832\n",
    "\n",
    "Per-class metrics:\n",
    "Class  0 - Acc: 0.9593, IoU: 0.9311\n",
    "Class  1 - Acc: 0.7775, IoU: 0.6356\n",
    "Class  2 - Acc: 0.8833, IoU: 0.8345\n",
    "Class  3 - Acc: 0.6123, IoU: 0.2143\n",
    "Class  4 - Acc: 0.5975, IoU: 0.3719\n",
    "Class  5 - Acc: 0.4950, IoU: 0.0902\n",
    "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
    "Class  7 - Acc: 0.6794, IoU: 0.3441\n",
    "Class  8 - Acc: 0.8865, IoU: 0.8228\n",
    "Class  9 - Acc: 0.6978, IoU: 0.4548\n",
    "Class 10 - Acc: 0.9104, IoU: 0.8398\n",
    "Class 11 - Acc: 0.6921, IoU: 0.5434\n",
    "Class 12 - Acc: 0.5197, IoU: 0.0134\n",
    "Class 13 - Acc: 0.8658, IoU: 0.8111\n",
    "Class 14 - Acc: 0.0234, IoU: 0.0003\n",
    "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 17 - Acc: 0.0625, IoU: 0.0000\n",
    "Class 18 - Acc: 0.5505, IoU: 0.3739\n",
    "100%|██████████| 393/393 [01:47<00:00,  3.66it/s]\n",
    "\n",
    "Epoch 6/10\n",
    "Loss: 0.3383\n",
    "Pixel Accuracy: 0.8999\n",
    "Mean Class Accuracy: 0.5900\n",
    "Mean IoU: 0.4068\n",
    "\n",
    "Per-class metrics:\n",
    "Class  0 - Acc: 0.9621, IoU: 0.9353\n",
    "Class  1 - Acc: 0.7931, IoU: 0.6533\n",
    "Class  2 - Acc: 0.8925, IoU: 0.8431\n",
    "Class  3 - Acc: 0.6518, IoU: 0.2993\n",
    "Class  4 - Acc: 0.6223, IoU: 0.3914\n",
    "Class  5 - Acc: 0.4808, IoU: 0.1278\n",
    "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
    "Class  7 - Acc: 0.6993, IoU: 0.3745\n",
    "Class  8 - Acc: 0.8920, IoU: 0.8302\n",
    "Class  9 - Acc: 0.7077, IoU: 0.4828\n",
    "Class 10 - Acc: 0.9139, IoU: 0.8461\n",
    "Class 11 - Acc: 0.7020, IoU: 0.5560\n",
    "Class 12 - Acc: 0.5079, IoU: 0.1365\n",
    "Class 13 - Acc: 0.8770, IoU: 0.8254\n",
    "Class 14 - Acc: 0.3341, IoU: 0.0313\n",
    "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 17 - Acc: 0.6476, IoU: 0.0009\n",
    "Class 18 - Acc: 0.5267, IoU: 0.3943\n",
    "100%|██████████| 393/393 [01:57<00:00,  3.34it/s]\n",
    "\n",
    "Epoch 7/10\n",
    "Loss: 0.3132\n",
    "Pixel Accuracy: 0.9046\n",
    "Mean Class Accuracy: 0.6116\n",
    "Mean IoU: 0.4342\n",
    "\n",
    "Per-class metrics:\n",
    "Class  0 - Acc: 0.9645, IoU: 0.9384\n",
    "Class  1 - Acc: 0.8041, IoU: 0.6683\n",
    "Class  2 - Acc: 0.8976, IoU: 0.8499\n",
    "Class  3 - Acc: 0.6763, IoU: 0.3529\n",
    "Class  4 - Acc: 0.6583, IoU: 0.4310\n",
    "Class  5 - Acc: 0.4748, IoU: 0.1467\n",
    "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
    "Class  7 - Acc: 0.7080, IoU: 0.3954\n",
    "Class  8 - Acc: 0.8977, IoU: 0.8366\n",
    "Class  9 - Acc: 0.7146, IoU: 0.5002\n",
    "Class 10 - Acc: 0.9180, IoU: 0.8529\n",
    "Class 11 - Acc: 0.7111, IoU: 0.5655\n",
    "Class 12 - Acc: 0.5126, IoU: 0.2226\n",
    "Class 13 - Acc: 0.8906, IoU: 0.8390\n",
    "Class 14 - Acc: 0.3960, IoU: 0.1433\n",
    "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
    "Class 17 - Acc: 0.8021, IoU: 0.0645\n",
    "Class 18 - Acc: 0.5951, IoU: 0.4418\n",
    "100%|██████████| 393/393 [01:59<00:00,  3.30it/s]\n",
    "\n",
    "Epoch 8/10\n",
    "Loss: 0.2945\n",
    "Pixel Accuracy: 0.9085\n",
    "Mean Class Accuracy: 0.7302\n",
    "Mean IoU: 0.4629\n",
    "\n",
    "Per-class metrics:\n",
    "Class  0 - Acc: 0.9667, IoU: 0.9420\n",
    "Class  1 - Acc: 0.8166, IoU: 0.6851\n",
    "Class  2 - Acc: 0.9008, IoU: 0.8529\n",
    "Class  3 - Acc: 0.6885, IoU: 0.3750\n",
    "Class  4 - Acc: 0.6791, IoU: 0.4547\n",
    "Class  5 - Acc: 0.4792, IoU: 0.1614\n",
    "Class  6 - Acc: 0.7800, IoU: 0.0077\n",
    "Class  7 - Acc: 0.7181, IoU: 0.4115\n",
    "Class  8 - Acc: 0.9007, IoU: 0.8416\n",
    "Class  9 - Acc: 0.7311, IoU: 0.5272\n",
    "Class 10 - Acc: 0.9191, IoU: 0.8550\n",
    "Class 11 - Acc: 0.7238, IoU: 0.5808\n",
    "Class 12 - Acc: 0.5949, IoU: 0.3069\n",
    "Class 13 - Acc: 0.9001, IoU: 0.8475\n",
    "Class 14 - Acc: 0.4454, IoU: 0.2258\n",
    "Class 15 - Acc: 0.2458, IoU: 0.0001\n",
    "Class 16 - Acc: 0.9798, IoU: 0.0001\n",
    "Class 17 - Acc: 0.7477, IoU: 0.2295\n",
    "Class 18 - Acc: 0.6556, IoU: 0.4907\n",
    "100%|██████████| 393/393 [01:59<00:00,  3.29it/s]\n",
    "\n",
    "Epoch 9/10\n",
    "Loss: 0.2726\n",
    "Pixel Accuracy: 0.9135\n",
    "Mean Class Accuracy: 0.7577\n",
    "Mean IoU: 0.4908\n",
    "\n",
    "Per-class metrics:\n",
    "Class  0 - Acc: 0.9696, IoU: 0.9462\n",
    "Class  1 - Acc: 0.8290, IoU: 0.7039\n",
    "Class  2 - Acc: 0.9067, IoU: 0.8607\n",
    "Class  3 - Acc: 0.7221, IoU: 0.4184\n",
    "Class  4 - Acc: 0.7113, IoU: 0.4963\n",
    "Class  5 - Acc: 0.5224, IoU: 0.1762\n",
    "Class  6 - Acc: 0.7757, IoU: 0.1308\n",
    "Class  7 - Acc: 0.7232, IoU: 0.4289\n",
    "Class  8 - Acc: 0.9048, IoU: 0.8460\n",
    "Class  9 - Acc: 0.7436, IoU: 0.5466\n",
    "Class 10 - Acc: 0.9203, IoU: 0.8577\n",
    "Class 11 - Acc: 0.7327, IoU: 0.5933\n",
    "Class 12 - Acc: 0.6154, IoU: 0.3383\n",
    "Class 13 - Acc: 0.9101, IoU: 0.8596\n",
    "Class 14 - Acc: 0.4096, IoU: 0.2638\n",
    "Class 15 - Acc: 0.6476, IoU: 0.0117\n",
    "Class 16 - Acc: 0.9485, IoU: 0.0138\n",
    "Class 17 - Acc: 0.7313, IoU: 0.3245\n",
    "Class 18 - Acc: 0.6727, IoU: 0.5081\n",
    "100%|██████████| 393/393 [02:00<00:00,  3.25it/s]\n",
    "Epoch 10/10\n",
    "Loss: 0.2589\n",
    "Pixel Accuracy: 0.9167\n",
    "Mean Class Accuracy: 0.7606\n",
    "Mean IoU: 0.5258\n",
    "\n",
    "Per-class metrics:\n",
    "Class  0 - Acc: 0.9703, IoU: 0.9476\n",
    "Class  1 - Acc: 0.8346, IoU: 0.7116\n",
    "Class  2 - Acc: 0.9116, IoU: 0.8657\n",
    "Class  3 - Acc: 0.7337, IoU: 0.4497\n",
    "Class  4 - Acc: 0.7450, IoU: 0.5394\n",
    "Class  5 - Acc: 0.5560, IoU: 0.1903\n",
    "Class  6 - Acc: 0.7002, IoU: 0.2374\n",
    "Class  7 - Acc: 0.7371, IoU: 0.4402\n",
    "Class  8 - Acc: 0.9063, IoU: 0.8491\n",
    "Class  9 - Acc: 0.7590, IoU: 0.5671\n",
    "Class 10 - Acc: 0.9229, IoU: 0.8600\n",
    "Class 11 - Acc: 0.7403, IoU: 0.6005\n",
    "Class 12 - Acc: 0.6436, IoU: 0.3547\n",
    "Class 13 - Acc: 0.9147, IoU: 0.8628\n",
    "Class 14 - Acc: 0.4679, IoU: 0.3213\n",
    "Class 15 - Acc: 0.6989, IoU: 0.1052\n",
    "Class 16 - Acc: 0.7634, IoU: 0.1535\n",
    "Class 17 - Acc: 0.7544, IoU: 0.4113\n",
    "Class 18 - Acc: 0.6910, IoU: 0.5232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated_student_map shape: torch.Size([2, 256, 16, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arda/tmp/ipykernel_2938576/3080879353.py:73: UserWarning: Using a target size (torch.Size([2, 768, 16, 16])) that is different to the input size (torch.Size([2, 256, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(F.normalize(updated_student_map, dim=1),\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (768) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 73\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# => [2, 256, 16, 16]\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Distillation loss (example)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# You'd typically need to align teacher_map shape or do some pooling, \u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# but let's just do a simple MSE with naive upsampling of teacher_map:\u001b[39;00m\n\u001b[1;32m     72\u001b[0m teacher_map_upsampled \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(teacher_map, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdated_student_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher_map_upsampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistillation loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/nn/functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3292\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (768) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CrossAttentionDistiller(nn.Module):\n",
    "    def __init__(self, \n",
    "                 student_dim,   # e.g., 256 or 512\n",
    "                 teacher_dim,   # e.g., 768\n",
    "                 hidden_dim,    # dimension for cross-attention\n",
    "                 num_heads=8):\n",
    "        super().__init__()\n",
    "        # Linear projections to match dimension\n",
    "        self.student_proj = nn.Linear(student_dim, hidden_dim, bias=False)\n",
    "        self.teacher_proj = nn.Linear(teacher_dim, hidden_dim, bias=False)\n",
    "        \n",
    "        # Using PyTorch's multi-head attention\n",
    "        # batch_first=True means input shape is [B, seq_len, dim]\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim=hidden_dim, \n",
    "                                                num_heads=num_heads, \n",
    "                                                batch_first=True)\n",
    "        \n",
    "        # Optional final projection back to student_dim\n",
    "        self.proj_back = nn.Linear(hidden_dim, student_dim, bias=False)\n",
    "\n",
    "    def forward(self, student_map, teacher_map):\n",
    "        \"\"\"\n",
    "        student_map: [B, C_s, H_s, W_s]\n",
    "        teacher_map: [B, C_t, H_t, W_t]\n",
    "        returns cross_attended_map: [B, C_s, H_s, W_s] (updated student features)\n",
    "        \"\"\"\n",
    "        B, C_s, H_s, W_s = student_map.shape\n",
    "        _, C_t, H_t, W_t = teacher_map.shape\n",
    "        \n",
    "        # Flatten [B, C_s, H_s, W_s] -> [B, H_s*W_s, C_s], then project\n",
    "        student_tokens = student_map.permute(0,2,3,1).reshape(B, H_s*W_s, C_s)\n",
    "        student_tokens = self.student_proj(student_tokens)  # => [B, H_s*W_s, hidden_dim]\n",
    "        \n",
    "        # Flatten teacher -> [B, H_t*W_t, C_t], then project\n",
    "        teacher_tokens = teacher_map.permute(0,2,3,1).reshape(B, H_t*W_t, C_t)\n",
    "        teacher_tokens = self.teacher_proj(teacher_tokens)  # => [B, H_t*W_t, hidden_dim]\n",
    "        \n",
    "        # Cross-Attention: Q=student, K=teacher, V=teacher\n",
    "        cross_attended, _ = self.cross_attn(query=student_tokens,\n",
    "                                            key=teacher_tokens,\n",
    "                                            value=teacher_tokens)\n",
    "        \n",
    "        # Project back to student dimension if needed\n",
    "        cross_attended = self.proj_back(cross_attended)  # [B, H_s*W_s, C_s]\n",
    "        \n",
    "        # Reshape back to [B, C_s, H_s, W_s]\n",
    "        cross_attended_map = cross_attended.view(B, H_s, W_s, C_s).permute(0, 3, 1, 2)\n",
    "        \n",
    "        return cross_attended_map\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    B = 2\n",
    "    student_map = torch.randn(B, 256, 16, 16)  # e.g., [B, C_s, H_s, W_s]\n",
    "    teacher_map = torch.randn(B, 768, 8, 8)    # [B, C_t, H_t, W_t]\n",
    "    \n",
    "    # Suppose we choose hidden_dim=384\n",
    "    distiller = CrossAttentionDistiller(student_dim=256, teacher_dim=768, hidden_dim=384, num_heads=6)\n",
    "    updated_student_map = distiller(student_map, teacher_map)\n",
    "    \n",
    "    print(\"updated_student_map shape:\", updated_student_map.shape)\n",
    "    # => [2, 256, 16, 16]\n",
    "    \n",
    "    # Distillation loss (example)\n",
    "    # You'd typically need to align teacher_map shape or do some pooling, \n",
    "    # but let's just do a simple MSE with naive upsampling of teacher_map:\n",
    "    teacher_map_upsampled = F.interpolate(teacher_map, size=(16,16), mode='bilinear')\n",
    "    loss = F.mse_loss(F.normalize(updated_student_map, dim=1),\n",
    "                      F.normalize(teacher_map_upsampled, dim=1))\n",
    "    print(\"distillation loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
