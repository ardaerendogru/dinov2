{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arda/miniconda3/envs/dinov2/lib/python3.9/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets_gta5 import GTA5, CityScapes\n",
    "import albumentations as A\n",
    "import torch\n",
    "\n",
    "CITYSCAPES_PATH = '/home/arda/.cache/kagglehub/datasets/ardaerendoru/gtagta/versions/1/Cityscapes/Cityscapes'\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(512, 1024),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "CITYSCAPES_dataset = CityScapes(CITYSCAPES_PATH, train_val='train', transform=transform)\n",
    "\n",
    "\n",
    "def load_student_checkpoint(checkpoint_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load and process student model checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path (str): Path to the checkpoint file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processed state dict containing only student model weights\n",
    "    \"\"\"\n",
    "    # Load checkpoint\n",
    "    state_dict = torch.load(checkpoint_path)\n",
    "    \n",
    "    # Extract and process student weights\n",
    "    student_state_dict = {k.replace('student.model.', ''): v \n",
    "                         for k, v in state_dict['state_dict'].items() \n",
    "                         if k.startswith('student') and not k.startswith('student.feature_matchers')}\n",
    "    \n",
    "    return student_state_dict\n",
    "\n",
    "# Load checkpoint and save state dict\n",
    "checkpoint_path = '/home/arda/dinov2/distillation/logs/resnet50/distillation/version_69/checkpoints/epoch=2-val_similarity=1.00.ckpt'\n",
    "student_state_dict = load_student_checkpoint(checkpoint_path)\n",
    "# torch.save(student_state_dict, '/home/arda/dinov2/distillation/logs/resnet50/distillation/version_7/checkpoints/student_state_dict.pth')\n",
    "# student_state_dict.keys()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.stem.conv1.weight': tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan],\n",
       "           [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.stem.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.stem.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.stem.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.stem.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.stem.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res2.0.shortcut.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res2.0.shortcut.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.shortcut.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.shortcut.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.shortcut.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.shortcut.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res2.0.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res2.0.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res2.0.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res2.0.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res2.0.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res2.0.conv3.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv3.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv3.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv3.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.0.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res2.1.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res2.1.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res2.1.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res2.1.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res2.1.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res2.1.conv3.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv3.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv3.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv3.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.1.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res2.2.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res2.2.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res2.2.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res2.2.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res2.2.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res2.2.conv3.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv3.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv3.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv3.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res2.2.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.0.shortcut.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res3.0.shortcut.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.shortcut.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.shortcut.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.shortcut.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.shortcut.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.0.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res3.0.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.0.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res3.0.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.0.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res3.0.conv3.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv3.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv3.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv3.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.0.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.1.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res3.1.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.1.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res3.1.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.1.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res3.1.conv3.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv3.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv3.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv3.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.1.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.2.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res3.2.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.2.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res3.2.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.2.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res3.2.conv3.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv3.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv3.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv3.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.2.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.3.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res3.3.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.3.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res3.3.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res3.3.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res3.3.conv3.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv3.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv3.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv3.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res3.3.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.0.shortcut.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.0.shortcut.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.0.shortcut.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.0.shortcut.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.0.shortcut.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.0.shortcut.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.0.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.0.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.0.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.0.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.0.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.0.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.0.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res4.0.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.0.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.0.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.0.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.0.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.0.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.0.conv3.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.0.conv3.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.0.conv3.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.0.conv3.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.0.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.1.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.1.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.1.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.1.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.1.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.1.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.1.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res4.1.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.1.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.1.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.1.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.1.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.1.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.1.conv3.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.1.conv3.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.1.conv3.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.1.conv3.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.1.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.2.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.2.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.2.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.2.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.2.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.2.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.2.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res4.2.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.2.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.2.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.2.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.2.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.2.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.2.conv3.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.2.conv3.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.2.conv3.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.2.conv3.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.2.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.3.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.3.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.3.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.3.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.3.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.3.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.3.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res4.3.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.3.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.3.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.3.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.3.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.3.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.3.conv3.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.3.conv3.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.3.conv3.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.3.conv3.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.3.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.4.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.4.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.4.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.4.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.4.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.4.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.4.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res4.4.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.4.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.4.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.4.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.4.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.4.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.4.conv3.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.4.conv3.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.4.conv3.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.4.conv3.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.4.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.5.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.5.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.5.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.5.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.5.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.5.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.5.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res4.5.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.5.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.5.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.5.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        device='cuda:0'),\n",
       " 'model.res4.5.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res4.5.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res4.5.conv3.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.5.conv3.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.5.conv3.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.5.conv3.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res4.5.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res5.0.shortcut.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res5.0.shortcut.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.shortcut.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.shortcut.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.shortcut.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.shortcut.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res5.0.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res5.0.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res5.0.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res5.0.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res5.0.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res5.0.conv3.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv3.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv3.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv3.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.0.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res5.1.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res5.1.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res5.1.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res5.1.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res5.1.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res5.1.conv3.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv3.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv3.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv3.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.1.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res5.2.conv1.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res5.2.conv1.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv1.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv1.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv1.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv1.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res5.2.conv2.weight': tensor([[[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]],\n",
       " \n",
       " \n",
       "         [[[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]],\n",
       " \n",
       "          [[nan, nan, nan],\n",
       "           [nan, nan, nan],\n",
       "           [nan, nan, nan]]]], device='cuda:0'),\n",
       " 'model.res5.2.conv2.norm.weight': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv2.norm.bias': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv2.norm.running_mean': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv2.norm.running_var': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv2.norm.num_batches_tracked': tensor(62220, device='cuda:0'),\n",
       " 'model.res5.2.conv3.weight': tensor([[[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]],\n",
       " \n",
       " \n",
       "         [[[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]],\n",
       " \n",
       "          [[nan]]]], device='cuda:0'),\n",
       " 'model.res5.2.conv3.norm.weight': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv3.norm.bias': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv3.norm.running_mean': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv3.norm.running_var': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0'),\n",
       " 'model.res5.2.conv3.norm.num_batches_tracked': tensor(62220, device='cuda:0')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/arda/dinov2/distillation')\n",
    "from models.resnet_wrapper import ResNetWrapper\n",
    "encoder = ResNetWrapper(depth=50, out_features=['res5'])\n",
    "encoder.load_state_dict(student_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder.eval()\n",
    "encoder.to(device)\n",
    "encoder.model.eval()\n",
    "encoder = encoder.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 16, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd = torch.randn(1, 3, 512, 1024).to(device)\n",
    "encoder(asd)[\"res5\"].shape\n",
    "\n",
    "# # Freeze all parameters of the encoder\n",
    "# for param in encoder.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [03:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Loss: nan\n",
      "Pixel Accuracy: 0.3638\n",
      "Mean Class Accuracy: 0.0191\n",
      "Mean IoU: 0.0191\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.3638, IoU: 0.3638\n",
      "Class  1 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  2 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  3 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  4 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  5 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  8 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  9 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 10 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 11 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 14 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [02:59<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "Loss: nan\n",
      "Pixel Accuracy: 0.3638\n",
      "Mean Class Accuracy: 0.0191\n",
      "Mean IoU: 0.0191\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.3638, IoU: 0.3638\n",
      "Class  1 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  2 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  3 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  4 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  5 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  8 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  9 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 10 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 11 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 14 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [03:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n",
      "Loss: nan\n",
      "Pixel Accuracy: 0.3638\n",
      "Mean Class Accuracy: 0.0191\n",
      "Mean IoU: 0.0191\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.3638, IoU: 0.3638\n",
      "Class  1 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  2 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  3 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  4 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  5 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  8 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  9 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 10 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 11 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 14 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [03:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n",
      "Loss: nan\n",
      "Pixel Accuracy: 0.3638\n",
      "Mean Class Accuracy: 0.0191\n",
      "Mean IoU: 0.0191\n",
      "\n",
      "Per-class metrics:\n",
      "Class  0 - Acc: 0.3638, IoU: 0.3638\n",
      "Class  1 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  2 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  3 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  4 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  5 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  6 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  7 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  8 - Acc: 0.0000, IoU: 0.0000\n",
      "Class  9 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 10 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 11 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 12 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 13 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 14 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 15 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 16 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 17 - Acc: 0.0000, IoU: 0.0000\n",
      "Class 18 - Acc: 0.0000, IoU: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 344/393 [02:36<00:22,  2.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 139\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 93\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(encoder, decoder, dataloader, optimizer, criterion, device, num_classes)\u001b[0m\n\u001b[1;32m     90\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     91\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 93\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[1;32m     96\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(torch\u001b[38;5;241m.\u001b[39msoftmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First, let's create a simple decoder network\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "class SegmentationDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels=2048, num_classes=19):\n",
    "        super().__init__()\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            # 16x32 -> 32x64\n",
    "            torch.nn.ConvTranspose2d(in_channels, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(1024),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 32x64 -> 64x128\n",
    "            torch.nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 64x128 -> 128x256\n",
    "            torch.nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 128x256 -> 256x512\n",
    "            torch.nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 256x512 -> 512x1024\n",
    "            torch.nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # Final 1x1 conv to get to num_classes\n",
    "            torch.nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        # Ensure exact output size\n",
    "        if x.shape[-2:] != (512, 1024):\n",
    "            x = torch.nn.functional.interpolate(\n",
    "                x, size=(512, 1024), \n",
    "                mode='bilinear', \n",
    "                align_corners=False\n",
    "            )\n",
    "        return x\n",
    "\n",
    "# Initialize decoder, optimizer, and loss function\n",
    "decoder = SegmentationDecoder().to(device)\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "def fast_hist(a: np.ndarray, b: np.ndarray, n: int) -> np.ndarray:\n",
    "    k = (b >= 0) & (b < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "def per_class_iou(hist: np.ndarray) -> np.ndarray:\n",
    "    epsilon = 1e-5\n",
    "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)\n",
    "\n",
    "def train_epoch(encoder, decoder, dataloader, optimizer, criterion, device, num_classes=19):\n",
    "    decoder.train()\n",
    "    encoder.train()  # Keep DINO frozen\n",
    "    \n",
    "    total_loss = 0\n",
    "    hist = np.zeros((num_classes, num_classes))  # Single histogram for entire epoch\n",
    "    total_pixels = 0\n",
    "    correct_pixels = 0\n",
    "    \n",
    "    for images, labels in tqdm.tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Get DINO features\n",
    "        # with torch.no_grad():\n",
    "        features = encoder(images)[\"res5\"]\n",
    "        \n",
    "        # Forward pass through decoder\n",
    "        outputs = decoder(features)\n",
    "        \n",
    "        # Resize outputs to match label size if needed\n",
    "        if outputs.shape[-2:] != labels.shape[-2:]:\n",
    "            outputs = torch.nn.functional.interpolate(\n",
    "                outputs, size=labels.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Calculate loss\n",
    "        print(outputs.shape, labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        preds = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
    "        \n",
    "        # Pixel Accuracy\n",
    "        valid_mask = labels != 255  # Ignore index\n",
    "        total_pixels += valid_mask.sum().item()\n",
    "        correct_pixels += ((preds == labels) & valid_mask).sum().item()\n",
    "        \n",
    "        # IoU\n",
    "        preds = preds.cpu().numpy()\n",
    "        target = labels.cpu().numpy()\n",
    "        hist += fast_hist(preds.flatten(), target.flatten(), num_classes)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    pixel_acc = correct_pixels / total_pixels\n",
    "    \n",
    "    # Per-class accuracy (mean class accuracy)\n",
    "    class_acc = np.diag(hist) / (hist.sum(1) + np.finfo(np.float32).eps)\n",
    "    mean_class_acc = np.nanmean(class_acc)\n",
    "    \n",
    "    # IoU metrics\n",
    "    iou = per_class_iou(hist)\n",
    "    mean_iou = np.nanmean(iou)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'pixel_acc': pixel_acc,\n",
    "        'mean_class_acc': mean_class_acc,\n",
    "        'mean_iou': mean_iou,\n",
    "        'class_iou': iou,\n",
    "        'class_acc': class_acc\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CITYSCAPES_dataset, \n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    metrics = train_epoch(encoder, decoder, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    print(f\"Pixel Accuracy: {metrics['pixel_acc']:.4f}\")\n",
    "    print(f\"Mean Class Accuracy: {metrics['mean_class_acc']:.4f}\")\n",
    "    print(f\"Mean IoU: {metrics['mean_iou']:.4f}\")\n",
    "    \n",
    "    # Optionally print per-class metrics\n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    for i in range(19):  # Assuming 19 classes\n",
    "        print(f\"Class {i:2d} - Acc: {metrics['class_acc'][i]:.4f}, IoU: {metrics['class_iou'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.3624,  0.8973, -1.0784,  0.3372, -1.4589, -0.1333,  0.2062,  0.4842,\n",
       "          1.9451, -0.1368]),\n",
       " tensor([-0.2461,  0.7652,  0.0446, -0.3514,  0.1806,  0.4895,  0.2342,  0.8889,\n",
       "         -0.8288, -0.6070]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(10)\n",
    "y = torch.randn(10)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated_student_map shape: torch.Size([2, 256, 16, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arda/tmp/ipykernel_2938576/3080879353.py:73: UserWarning: Using a target size (torch.Size([2, 768, 16, 16])) that is different to the input size (torch.Size([2, 256, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(F.normalize(updated_student_map, dim=1),\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (768) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 73\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# => [2, 256, 16, 16]\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Distillation loss (example)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# You'd typically need to align teacher_map shape or do some pooling, \u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# but let's just do a simple MSE with naive upsampling of teacher_map:\u001b[39;00m\n\u001b[1;32m     72\u001b[0m teacher_map_upsampled \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(teacher_map, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdated_student_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher_map_upsampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistillation loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/nn/functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3292\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (768) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CrossAttentionDistiller(nn.Module):\n",
    "    def __init__(self, \n",
    "                 student_dim,   # e.g., 256 or 512\n",
    "                 teacher_dim,   # e.g., 768\n",
    "                 hidden_dim,    # dimension for cross-attention\n",
    "                 num_heads=8):\n",
    "        super().__init__()\n",
    "        # Linear projections to match dimension\n",
    "        self.student_proj = nn.Linear(student_dim, hidden_dim, bias=False)\n",
    "        self.teacher_proj = nn.Linear(teacher_dim, hidden_dim, bias=False)\n",
    "        \n",
    "        # Using PyTorch's multi-head attention\n",
    "        # batch_first=True means input shape is [B, seq_len, dim]\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim=hidden_dim, \n",
    "                                                num_heads=num_heads, \n",
    "                                                batch_first=True)\n",
    "        \n",
    "        # Optional final projection back to student_dim\n",
    "        self.proj_back = nn.Linear(hidden_dim, student_dim, bias=False)\n",
    "\n",
    "    def forward(self, student_map, teacher_map):\n",
    "        \"\"\"\n",
    "        student_map: [B, C_s, H_s, W_s]\n",
    "        teacher_map: [B, C_t, H_t, W_t]\n",
    "        returns cross_attended_map: [B, C_s, H_s, W_s] (updated student features)\n",
    "        \"\"\"\n",
    "        B, C_s, H_s, W_s = student_map.shape\n",
    "        _, C_t, H_t, W_t = teacher_map.shape\n",
    "        \n",
    "        # Flatten [B, C_s, H_s, W_s] -> [B, H_s*W_s, C_s], then project\n",
    "        student_tokens = student_map.permute(0,2,3,1).reshape(B, H_s*W_s, C_s)\n",
    "        student_tokens = self.student_proj(student_tokens)  # => [B, H_s*W_s, hidden_dim]\n",
    "        \n",
    "        # Flatten teacher -> [B, H_t*W_t, C_t], then project\n",
    "        teacher_tokens = teacher_map.permute(0,2,3,1).reshape(B, H_t*W_t, C_t)\n",
    "        teacher_tokens = self.teacher_proj(teacher_tokens)  # => [B, H_t*W_t, hidden_dim]\n",
    "        \n",
    "        # Cross-Attention: Q=student, K=teacher, V=teacher\n",
    "        cross_attended, _ = self.cross_attn(query=student_tokens,\n",
    "                                            key=teacher_tokens,\n",
    "                                            value=teacher_tokens)\n",
    "        \n",
    "        # Project back to student dimension if needed\n",
    "        cross_attended = self.proj_back(cross_attended)  # [B, H_s*W_s, C_s]\n",
    "        \n",
    "        # Reshape back to [B, C_s, H_s, W_s]\n",
    "        cross_attended_map = cross_attended.view(B, H_s, W_s, C_s).permute(0, 3, 1, 2)\n",
    "        \n",
    "        return cross_attended_map\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    B = 2\n",
    "    student_map = torch.randn(B, 256, 16, 16)  # e.g., [B, C_s, H_s, W_s]\n",
    "    teacher_map = torch.randn(B, 768, 8, 8)    # [B, C_t, H_t, W_t]\n",
    "    \n",
    "    # Suppose we choose hidden_dim=384\n",
    "    distiller = CrossAttentionDistiller(student_dim=256, teacher_dim=768, hidden_dim=384, num_heads=6)\n",
    "    updated_student_map = distiller(student_map, teacher_map)\n",
    "    \n",
    "    print(\"updated_student_map shape:\", updated_student_map.shape)\n",
    "    # => [2, 256, 16, 16]\n",
    "    \n",
    "    # Distillation loss (example)\n",
    "    # You'd typically need to align teacher_map shape or do some pooling, \n",
    "    # but let's just do a simple MSE with naive upsampling of teacher_map:\n",
    "    teacher_map_upsampled = F.interpolate(teacher_map, size=(16,16), mode='bilinear')\n",
    "    loss = F.mse_loss(F.normalize(updated_student_map, dim=1),\n",
    "                      F.normalize(teacher_map_upsampled, dim=1))\n",
    "    print(\"distillation loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
