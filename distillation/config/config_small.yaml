student:
  model_name: resnet
  student_key: [res5, res4]
  # pretrained: true
  checkpoint_path: /home/arda/dinov2/distillation/checkpoints/resnet50.pth
  kwargs:
    depth: 50
    out_features: ['res4', 'res5']
    freeze_at: 0
    norm_type: BN
##Example for STDC
# kwargs:
#   base_channels: 64
#   layers: [4, 5, 3]
#   block_num: 4
#   block_type: cat
#   use_conv_last: false


teacher:
  model_name: dinov2_vits14
  teacher_key: feature_map
  out_dim: 384
  n_patches: 256



data_transform:
  n_global_crops: 2
  n_local_crops: 8
  global_crops_scale: [0.32, 1.0]
  local_crops_scale: [0.05, 0.32]
  global_crops_size: [224, 224]
  local_crops_size: [224, 224]




optimizer:
  type: AdamW
  kwargs:
    lr: 2.5e-4
    betas: [0.9, 0.999]
    weight_decay: 0.05
  scheduler:
    type: CosineAnnealingLR
    kwargs:
      T_max: 30
      eta_min: 2.5e-5
    monitor: val_loss
    interval: epoch
    frequency: 1

loss:
  losses:
    - type: scalekd
      weight: 1
      kwargs:
        alpha: [0.08, 0.06]
        student_dims: 1024
        teacher_dims: 384
        query_hw: [16, 16]
        pos_hw: [16, 16]
        pos_dims: 384
        window_shapes: [1, 1]
        self_query: True
        softmax_scale: [5.0, 5.0]
        dis_freq: high
        num_heads: 16
        name: scalekd_n
        use_this: true
    - type: scalekd
      weight: 1.0
      kwargs:
        alpha: [0.08, 0.06]
        student_dims: 2048
        teacher_dims: 384
        query_hw: [16, 16]
        pos_hw: [16, 16]
        pos_dims: 384
        window_shapes: [1, 1]
        self_query: False
        softmax_scale: [5.0, 5.0]
        dis_freq: high
        num_heads: 24
        name: scalekd_last
        use_this: true

    # - type: dinoiser
    #   weight: 1.0
    #   kwargs:
    #     student_dims: 2048
    #     teacher_dims: 1536



train:
  name: resnet50
  max_epochs: 10
  accelerator: gpu
  devices: [0,1]
  num_nodes: 1
  strategy: ddp
  # resume_from_checkpoint: "/path/to/your/checkpoint.ckpt"  # Add this line
data_loader:
  data_dir: /storage/disk2/sam_resized
  batch_size: 64
  num_workers: 8
  


feature_matcher:
  res5:
    out_channels: 2048
    kernel_size: 1
    stride: 1
    padding: 0
  res4:
    out_channels: 1024
    kernel_size: 3
    stride: 1
    padding: 1


checkpoints:
  dirpath: checkpoints
  monitor: val_loss
  mode: max
  save_top_k: 3


wandb:
  project: "dinov2-distillation"  # Project name in W&B
  name: resnet50  # Run name (will use train.name if null)
  tags: ["distillation", "resnet", "dinov2"]  # Searchable tags
  notes: "Knowledge distillation from DINOv2 to ResNet50"  # Run description

