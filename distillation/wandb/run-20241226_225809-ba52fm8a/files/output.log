Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Starting training from scratch.
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name    | Type         | Params | Mode
-------------------------------------------------
0 | student | ModelWrapper | 26.7 M | train
1 | teacher | DINOv2ViT    | 1.1 B  | train
-------------------------------------------------
26.7 M    Trainable params
1.1 B     Non-trainable params
1.2 B     Total params
4,652.544 Total estimated model params size (MB)
742       Modules in train mode
0         Modules in eval mode
Epoch 0:   0%|                                                                                                                      | 0/1830 [00:00<?, ?it/s]
[rank0]: Traceback (most recent call last):
[rank0]:   File "/storage/disk0/arda/dinov2/distillation/train.py", line 202, in <module>
[rank0]:     main()
[rank0]:   File "/storage/disk0/arda/dinov2/distillation/train.py", line 198, in main
[rank0]:     trainer.train()
[rank0]:   File "/storage/disk0/arda/dinov2/distillation/train.py", line 159, in train
[rank0]:     self.trainer.fit(self.distillation_module, self.data_module)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
[rank0]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/amp.py", line 78, in optimizer_step
[rank0]:     closure_result = closure()
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 389, in training_step
[rank0]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 640, in __call__
[rank0]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 633, in wrapped_forward
[rank0]:     out = method(*_args, **_kwargs)
[rank0]:   File "/storage/disk0/arda/dinov2/distillation/train/distillation_module.py", line 56, in training_step
[rank0]:     self._log_training_metrics(losses, features)
[rank0]:   File "/storage/disk0/arda/dinov2/distillation/train/distillation_module.py", line 86, in _log_training_metrics
[rank0]:     self.log('train_cosine_loss', losses['cosine'], sync_dist=True)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 479, in log
[rank0]:     value = apply_to_collection(value, (Tensor, numbers.Number), self.__to_tensor, name)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py", line 64, in apply_to_collection
[rank0]:     return function(data, *args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 659, in __to_tensor
[rank0]:     raise ValueError(
[rank0]: ValueError: `self.log(train_cosine_loss, tensor([[[0.9820, 0.9873, 0.9792,  ..., 0.9519, 0.9784, 0.9742],
[rank0]:          [1.0175, 1.0004, 1.0008,  ..., 0.9717, 0.9618, 0.9651],
[rank0]:          [0.9851, 0.9896, 0.9935,  ..., 0.9671, 0.9647, 0.9815],
[rank0]:          ...,
[rank0]:          [1.0100, 1.0066, 1.0033,  ..., 0.9927, 1.0110, 1.0172],
[rank0]:          [1.0398, 1.0134, 0.9865,  ..., 1.0084, 1.0003, 0.9927],
[rank0]:          [1.0330, 0.9787, 1.0438,  ..., 0.9714, 0.9696, 0.9831]],

[rank0]:         [[0.9879, 0.9935, 1.0096,  ..., 1.0131, 1.0534, 1.0554],
[rank0]:          [1.0371, 1.0081, 0.9745,  ..., 1.0195, 1.0355, 1.0486],
[rank0]:          [1.0140, 1.0078, 1.0374,  ..., 1.0113, 1.0306, 1.0386],
[rank0]:          ...,
[rank0]:          [1.0157, 0.9803, 1.0148,  ..., 1.0039, 1.0057, 1.0039],
[rank0]:          [1.0044, 0.9829, 1.0266,  ..., 1.0123, 1.0101, 1.0138],
[rank0]:          [0.9891, 0.9925, 0.9912,  ..., 1.0456, 1.0064, 1.0344]],

[rank0]:         [[1.0087, 0.9996, 1.0111,  ..., 0.9864, 1.0531, 1.0249],
[rank0]:          [0.9718, 0.9981, 1.0209,  ..., 1.0222, 1.0451, 1.0475],
[rank0]:          [0.9915, 1.0005, 1.0085,  ..., 1.0079, 1.0091, 1.0280],
[rank0]:          ...,
[rank0]:          [1.0042, 1.0179, 0.9665,  ..., 0.9952, 1.0186, 1.0157],
[rank0]:          [0.9777, 1.0094, 0.9763,  ..., 0.9876, 1.0017, 0.9866],
[rank0]:          [0.9647, 1.0186, 0.9639,  ..., 1.0180, 1.0333, 0.9688]],

[rank0]:         ...,

[rank0]:         [[0.9946, 0.9872, 1.0101,  ..., 0.9759, 0.9940, 1.0143],
[rank0]:          [1.0267, 1.0008, 1.0159,  ..., 1.0141, 1.0260, 1.0165],
[rank0]:          [0.9964, 0.9969, 0.9881,  ..., 1.0154, 0.9921, 0.9841],
[rank0]:          ...,
[rank0]:          [1.0196, 0.9941, 0.9868,  ..., 0.9722, 1.0242, 1.0352],
[rank0]:          [0.9637, 0.9847, 0.9966,  ..., 1.0117, 0.9743, 0.9966],
[rank0]:          [0.9824, 0.9601, 0.9611,  ..., 0.9951, 1.0078, 1.0011]],

[rank0]:         [[0.9989, 1.0070, 1.0067,  ..., 0.9800, 0.9875, 1.0289],
[rank0]:          [1.0118, 0.9851, 1.0085,  ..., 1.0077, 0.9818, 1.0103],
[rank0]:          [1.0209, 0.9676, 1.0031,  ..., 0.9891, 0.9981, 0.9791],
[rank0]:          ...,
[rank0]:          [0.9868, 0.9782, 1.0244,  ..., 1.0011, 1.0126, 1.0069],
[rank0]:          [0.9707, 0.9742, 0.9847,  ..., 1.0084, 1.0147, 0.9897],
[rank0]:          [0.9895, 0.9519, 1.0042,  ..., 0.9987, 0.9987, 0.9975]],

[rank0]:         [[0.9983, 1.0002, 1.0014,  ..., 0.9813, 0.9982, 0.9922],
[rank0]:          [0.9888, 1.0061, 0.9848,  ..., 0.9486, 0.9984, 0.9888],
[rank0]:          [1.0103, 0.9968, 0.9784,  ..., 1.0194, 0.9894, 1.0062],
[rank0]:          ...,
[rank0]:          [1.0073, 1.0066, 1.0021,  ..., 1.0368, 0.9926, 0.9892],
[rank0]:          [0.9961, 0.9766, 0.9763,  ..., 0.9923, 1.0325, 1.0178],
[rank0]:          [0.9976, 1.0044, 0.9990,  ..., 0.9969, 1.0119, 1.0193]]],
[rank0]:        device='cuda:0'))` was called, but the tensor must have a single element. You can try doing `self.log(train_cosine_loss, tensor([[[0.9820, 0.9873, 0.9792,  ..., 0.9519, 0.9784, 0.9742],
[rank0]:          [1.0175, 1.0004, 1.0008,  ..., 0.9717, 0.9618, 0.9651],
[rank0]:          [0.9851, 0.9896, 0.9935,  ..., 0.9671, 0.9647, 0.9815],
[rank0]:          ...,
[rank0]:          [1.0100, 1.0066, 1.0033,  ..., 0.9927, 1.0110, 1.0172],
[rank0]:          [1.0398, 1.0134, 0.9865,  ..., 1.0084, 1.0003, 0.9927],
[rank0]:          [1.0330, 0.9787, 1.0438,  ..., 0.9714, 0.9696, 0.9831]],

[rank0]:         [[0.9879, 0.9935, 1.0096,  ..., 1.0131, 1.0534, 1.0554],
[rank0]:          [1.0371, 1.0081, 0.9745,  ..., 1.0195, 1.0355, 1.0486],
[rank0]:          [1.0140, 1.0078, 1.0374,  ..., 1.0113, 1.0306, 1.0386],
[rank0]:          ...,
[rank0]:          [1.0157, 0.9803, 1.0148,  ..., 1.0039, 1.0057, 1.0039],
[rank0]:          [1.0044, 0.9829, 1.0266,  ..., 1.0123, 1.0101, 1.0138],
[rank0]:          [0.9891, 0.9925, 0.9912,  ..., 1.0456, 1.0064, 1.0344]],

[rank0]:         [[1.0087, 0.9996, 1.0111,  ..., 0.9864, 1.0531, 1.0249],
[rank0]:          [0.9718, 0.9981, 1.0209,  ..., 1.0222, 1.0451, 1.0475],
[rank0]:          [0.9915, 1.0005, 1.0085,  ..., 1.0079, 1.0091, 1.0280],
[rank0]:          ...,
[rank0]:          [1.0042, 1.0179, 0.9665,  ..., 0.9952, 1.0186, 1.0157],
[rank0]:          [0.9777, 1.0094, 0.9763,  ..., 0.9876, 1.0017, 0.9866],
[rank0]:          [0.9647, 1.0186, 0.9639,  ..., 1.0180, 1.0333, 0.9688]],

[rank0]:         ...,

[rank0]:         [[0.9946, 0.9872, 1.0101,  ..., 0.9759, 0.9940, 1.0143],
[rank0]:          [1.0267, 1.0008, 1.0159,  ..., 1.0141, 1.0260, 1.0165],
[rank0]:          [0.9964, 0.9969, 0.9881,  ..., 1.0154, 0.9921, 0.9841],
[rank0]:          ...,
[rank0]:          [1.0196, 0.9941, 0.9868,  ..., 0.9722, 1.0242, 1.0352],
[rank0]:          [0.9637, 0.9847, 0.9966,  ..., 1.0117, 0.9743, 0.9966],
[rank0]:          [0.9824, 0.9601, 0.9611,  ..., 0.9951, 1.0078, 1.0011]],

[rank0]:         [[0.9989, 1.0070, 1.0067,  ..., 0.9800, 0.9875, 1.0289],
[rank0]:          [1.0118, 0.9851, 1.0085,  ..., 1.0077, 0.9818, 1.0103],
[rank0]:          [1.0209, 0.9676, 1.0031,  ..., 0.9891, 0.9981, 0.9791],
[rank0]:          ...,
[rank0]:          [0.9868, 0.9782, 1.0244,  ..., 1.0011, 1.0126, 1.0069],
[rank0]:          [0.9707, 0.9742, 0.9847,  ..., 1.0084, 1.0147, 0.9897],
[rank0]:          [0.9895, 0.9519, 1.0042,  ..., 0.9987, 0.9987, 0.9975]],

[rank0]:         [[0.9983, 1.0002, 1.0014,  ..., 0.9813, 0.9982, 0.9922],
[rank0]:          [0.9888, 1.0061, 0.9848,  ..., 0.9486, 0.9984, 0.9888],
[rank0]:          [1.0103, 0.9968, 0.9784,  ..., 1.0194, 0.9894, 1.0062],
[rank0]:          ...,
[rank0]:          [1.0073, 1.0066, 1.0021,  ..., 1.0368, 0.9926, 0.9892],
[rank0]:          [0.9961, 0.9766, 0.9763,  ..., 0.9923, 1.0325, 1.0178],
[rank0]:          [0.9976, 1.0044, 0.9990,  ..., 0.9969, 1.0119, 1.0193]]],
[rank0]:        device='cuda:0').mean())`
[rank0]: Traceback (most recent call last):
[rank0]:   File "/storage/disk0/arda/dinov2/distillation/train.py", line 202, in <module>
[rank0]:     main()
[rank0]:   File "/storage/disk0/arda/dinov2/distillation/train.py", line 198, in main
[rank0]:     trainer.train()
[rank0]:   File "/storage/disk0/arda/dinov2/distillation/train.py", line 159, in train
[rank0]:     self.trainer.fit(self.distillation_module, self.data_module)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 153, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
[rank0]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/amp.py", line 78, in optimizer_step
[rank0]:     closure_result = closure()
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 389, in training_step
[rank0]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 640, in __call__
[rank0]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 633, in wrapped_forward
[rank0]:     out = method(*_args, **_kwargs)
[rank0]:   File "/storage/disk0/arda/dinov2/distillation/train/distillation_module.py", line 56, in training_step
[rank0]:     self._log_training_metrics(losses, features)
[rank0]:   File "/storage/disk0/arda/dinov2/distillation/train/distillation_module.py", line 86, in _log_training_metrics
[rank0]:     self.log('train_cosine_loss', losses['cosine'], sync_dist=True)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 479, in log
[rank0]:     value = apply_to_collection(value, (Tensor, numbers.Number), self.__to_tensor, name)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py", line 64, in apply_to_collection
[rank0]:     return function(data, *args, **kwargs)
[rank0]:   File "/home/arda/miniconda3/envs/distillation/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 659, in __to_tensor
[rank0]:     raise ValueError(
[rank0]: ValueError: `self.log(train_cosine_loss, tensor([[[0.9820, 0.9873, 0.9792,  ..., 0.9519, 0.9784, 0.9742],
[rank0]:          [1.0175, 1.0004, 1.0008,  ..., 0.9717, 0.9618, 0.9651],
[rank0]:          [0.9851, 0.9896, 0.9935,  ..., 0.9671, 0.9647, 0.9815],
[rank0]:          ...,
[rank0]:          [1.0100, 1.0066, 1.0033,  ..., 0.9927, 1.0110, 1.0172],
[rank0]:          [1.0398, 1.0134, 0.9865,  ..., 1.0084, 1.0003, 0.9927],
[rank0]:          [1.0330, 0.9787, 1.0438,  ..., 0.9714, 0.9696, 0.9831]],

[rank0]:         [[0.9879, 0.9935, 1.0096,  ..., 1.0131, 1.0534, 1.0554],
[rank0]:          [1.0371, 1.0081, 0.9745,  ..., 1.0195, 1.0355, 1.0486],
[rank0]:          [1.0140, 1.0078, 1.0374,  ..., 1.0113, 1.0306, 1.0386],
[rank0]:          ...,
[rank0]:          [1.0157, 0.9803, 1.0148,  ..., 1.0039, 1.0057, 1.0039],
[rank0]:          [1.0044, 0.9829, 1.0266,  ..., 1.0123, 1.0101, 1.0138],
[rank0]:          [0.9891, 0.9925, 0.9912,  ..., 1.0456, 1.0064, 1.0344]],

[rank0]:         [[1.0087, 0.9996, 1.0111,  ..., 0.9864, 1.0531, 1.0249],
[rank0]:          [0.9718, 0.9981, 1.0209,  ..., 1.0222, 1.0451, 1.0475],
[rank0]:          [0.9915, 1.0005, 1.0085,  ..., 1.0079, 1.0091, 1.0280],
[rank0]:          ...,
[rank0]:          [1.0042, 1.0179, 0.9665,  ..., 0.9952, 1.0186, 1.0157],
[rank0]:          [0.9777, 1.0094, 0.9763,  ..., 0.9876, 1.0017, 0.9866],
[rank0]:          [0.9647, 1.0186, 0.9639,  ..., 1.0180, 1.0333, 0.9688]],

[rank0]:         ...,

[rank0]:         [[0.9946, 0.9872, 1.0101,  ..., 0.9759, 0.9940, 1.0143],
[rank0]:          [1.0267, 1.0008, 1.0159,  ..., 1.0141, 1.0260, 1.0165],
[rank0]:          [0.9964, 0.9969, 0.9881,  ..., 1.0154, 0.9921, 0.9841],
[rank0]:          ...,
[rank0]:          [1.0196, 0.9941, 0.9868,  ..., 0.9722, 1.0242, 1.0352],
[rank0]:          [0.9637, 0.9847, 0.9966,  ..., 1.0117, 0.9743, 0.9966],
[rank0]:          [0.9824, 0.9601, 0.9611,  ..., 0.9951, 1.0078, 1.0011]],

[rank0]:         [[0.9989, 1.0070, 1.0067,  ..., 0.9800, 0.9875, 1.0289],
[rank0]:          [1.0118, 0.9851, 1.0085,  ..., 1.0077, 0.9818, 1.0103],
[rank0]:          [1.0209, 0.9676, 1.0031,  ..., 0.9891, 0.9981, 0.9791],
[rank0]:          ...,
[rank0]:          [0.9868, 0.9782, 1.0244,  ..., 1.0011, 1.0126, 1.0069],
[rank0]:          [0.9707, 0.9742, 0.9847,  ..., 1.0084, 1.0147, 0.9897],
[rank0]:          [0.9895, 0.9519, 1.0042,  ..., 0.9987, 0.9987, 0.9975]],

[rank0]:         [[0.9983, 1.0002, 1.0014,  ..., 0.9813, 0.9982, 0.9922],
[rank0]:          [0.9888, 1.0061, 0.9848,  ..., 0.9486, 0.9984, 0.9888],
[rank0]:          [1.0103, 0.9968, 0.9784,  ..., 1.0194, 0.9894, 1.0062],
[rank0]:          ...,
[rank0]:          [1.0073, 1.0066, 1.0021,  ..., 1.0368, 0.9926, 0.9892],
[rank0]:          [0.9961, 0.9766, 0.9763,  ..., 0.9923, 1.0325, 1.0178],
[rank0]:          [0.9976, 1.0044, 0.9990,  ..., 0.9969, 1.0119, 1.0193]]],
[rank0]:        device='cuda:0'))` was called, but the tensor must have a single element. You can try doing `self.log(train_cosine_loss, tensor([[[0.9820, 0.9873, 0.9792,  ..., 0.9519, 0.9784, 0.9742],
[rank0]:          [1.0175, 1.0004, 1.0008,  ..., 0.9717, 0.9618, 0.9651],
[rank0]:          [0.9851, 0.9896, 0.9935,  ..., 0.9671, 0.9647, 0.9815],
[rank0]:          ...,
[rank0]:          [1.0100, 1.0066, 1.0033,  ..., 0.9927, 1.0110, 1.0172],
[rank0]:          [1.0398, 1.0134, 0.9865,  ..., 1.0084, 1.0003, 0.9927],
[rank0]:          [1.0330, 0.9787, 1.0438,  ..., 0.9714, 0.9696, 0.9831]],

[rank0]:         [[0.9879, 0.9935, 1.0096,  ..., 1.0131, 1.0534, 1.0554],
[rank0]:          [1.0371, 1.0081, 0.9745,  ..., 1.0195, 1.0355, 1.0486],
[rank0]:          [1.0140, 1.0078, 1.0374,  ..., 1.0113, 1.0306, 1.0386],
[rank0]:          ...,
[rank0]:          [1.0157, 0.9803, 1.0148,  ..., 1.0039, 1.0057, 1.0039],
[rank0]:          [1.0044, 0.9829, 1.0266,  ..., 1.0123, 1.0101, 1.0138],
[rank0]:          [0.9891, 0.9925, 0.9912,  ..., 1.0456, 1.0064, 1.0344]],

[rank0]:         [[1.0087, 0.9996, 1.0111,  ..., 0.9864, 1.0531, 1.0249],
[rank0]:          [0.9718, 0.9981, 1.0209,  ..., 1.0222, 1.0451, 1.0475],
[rank0]:          [0.9915, 1.0005, 1.0085,  ..., 1.0079, 1.0091, 1.0280],
[rank0]:          ...,
[rank0]:          [1.0042, 1.0179, 0.9665,  ..., 0.9952, 1.0186, 1.0157],
[rank0]:          [0.9777, 1.0094, 0.9763,  ..., 0.9876, 1.0017, 0.9866],
[rank0]:          [0.9647, 1.0186, 0.9639,  ..., 1.0180, 1.0333, 0.9688]],

[rank0]:         ...,

[rank0]:         [[0.9946, 0.9872, 1.0101,  ..., 0.9759, 0.9940, 1.0143],
[rank0]:          [1.0267, 1.0008, 1.0159,  ..., 1.0141, 1.0260, 1.0165],
[rank0]:          [0.9964, 0.9969, 0.9881,  ..., 1.0154, 0.9921, 0.9841],
[rank0]:          ...,
[rank0]:          [1.0196, 0.9941, 0.9868,  ..., 0.9722, 1.0242, 1.0352],
[rank0]:          [0.9637, 0.9847, 0.9966,  ..., 1.0117, 0.9743, 0.9966],
[rank0]:          [0.9824, 0.9601, 0.9611,  ..., 0.9951, 1.0078, 1.0011]],

[rank0]:         [[0.9989, 1.0070, 1.0067,  ..., 0.9800, 0.9875, 1.0289],
[rank0]:          [1.0118, 0.9851, 1.0085,  ..., 1.0077, 0.9818, 1.0103],
[rank0]:          [1.0209, 0.9676, 1.0031,  ..., 0.9891, 0.9981, 0.9791],
[rank0]:          ...,
[rank0]:          [0.9868, 0.9782, 1.0244,  ..., 1.0011, 1.0126, 1.0069],
[rank0]:          [0.9707, 0.9742, 0.9847,  ..., 1.0084, 1.0147, 0.9897],
[rank0]:          [0.9895, 0.9519, 1.0042,  ..., 0.9987, 0.9987, 0.9975]],

[rank0]:         [[0.9983, 1.0002, 1.0014,  ..., 0.9813, 0.9982, 0.9922],
[rank0]:          [0.9888, 1.0061, 0.9848,  ..., 0.9486, 0.9984, 0.9888],
[rank0]:          [1.0103, 0.9968, 0.9784,  ..., 1.0194, 0.9894, 1.0062],
[rank0]:          ...,
[rank0]:          [1.0073, 1.0066, 1.0021,  ..., 1.0368, 0.9926, 0.9892],
[rank0]:          [0.9961, 0.9766, 0.9763,  ..., 0.9923, 1.0325, 1.0178],
[rank0]:          [0.9976, 1.0044, 0.9990,  ..., 0.9969, 1.0119, 1.0193]]],
[rank0]:        device='cuda:0').mean())`
