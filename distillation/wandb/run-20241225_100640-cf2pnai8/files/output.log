Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Starting training from scratch.
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name    | Type         | Params | Mode
-------------------------------------------------
0 | student | ModelWrapper | 26.7 M | train
1 | teacher | DINOv2ViT    | 1.1 B  | train
-------------------------------------------------
26.7 M    Trainable params
1.1 B     Non-trainable params
1.2 B     Total params
4,652.544 Total estimated model params size (MB)
742       Modules in train mode
0         Modules in eval mode
Epoch 0:   0%|                                                                                                                                           | 0/1830 [00:00<?, ?it/s]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   0%|                                                                                                                       | 1/1830 [00:05<2:39:46,  0.19it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   0%|▏                                                                                                                      | 2/1830 [00:05<1:29:59,  0.34it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   0%|▏                                                                                                                      | 3/1830 [00:06<1:06:45,  0.46it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   0%|▎                                                                                                                        | 4/1830 [00:07<55:21,  0.55it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   0%|▎                                                                                                                        | 5/1830 [00:07<48:16,  0.63it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   0%|▍                                                                                                                        | 6/1830 [00:08<43:32,  0.70it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   0%|▍                                                                                                                        | 7/1830 [00:09<40:10,  0.76it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   0%|▌                                                                                                                        | 8/1830 [00:09<37:39,  0.81it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   0%|▌                                                                                                                        | 9/1830 [00:10<35:40,  0.85it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|▋                                                                                                                       | 10/1830 [00:11<34:06,  0.89it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|▋                                                                                                                       | 11/1830 [00:11<32:50,  0.92it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|▊                                                                                                                       | 12/1830 [00:12<31:45,  0.95it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|▊                                                                                                                       | 13/1830 [00:13<30:50,  0.98it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|▉                                                                                                                       | 14/1830 [00:13<30:02,  1.01it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|▉                                                                                                                       | 15/1830 [00:14<29:21,  1.03it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█                                                                                                                       | 16/1830 [00:15<28:46,  1.05it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█                                                                                                                       | 17/1830 [00:15<28:14,  1.07it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█▏                                                                                                                      | 18/1830 [00:16<27:46,  1.09it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█▏                                                                                                                      | 19/1830 [00:17<27:20,  1.10it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█▎                                                                                                                      | 20/1830 [00:17<26:57,  1.12it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█▍                                                                                                                      | 21/1830 [00:18<26:36,  1.13it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█▍                                                                                                                      | 22/1830 [00:19<26:17,  1.15it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█▌                                                                                                                      | 23/1830 [00:19<26:00,  1.16it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█▌                                                                                                                      | 24/1830 [00:20<25:45,  1.17it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█▋                                                                                                                      | 25/1830 [00:21<25:31,  1.18it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█▋                                                                                                                      | 26/1830 [00:21<25:19,  1.19it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   1%|█▊                                                                                                                      | 27/1830 [00:22<25:06,  1.20it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   2%|█▊                                                                                                                      | 28/1830 [00:23<24:54,  1.21it/s, v_num=12]teacher_features: torch.Size([64, 1536, 256])
student_features: torch.Size([64, 1536, 256])
teacher_features: torch.Size([64, 256, 256])
student_features: torch.Size([64, 256, 256])
Epoch 0:   2%|█▉                                                                                                                      | 29/1830 [00:23<24:44,  1.21it/s, v_num=12]

Detected KeyboardInterrupt, attempting graceful shutdown ...
