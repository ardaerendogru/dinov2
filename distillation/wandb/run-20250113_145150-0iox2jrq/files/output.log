Starting training from scratch.
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
Unused parameters: {'student.model.model.res2.0.conv2.norm.weight', 'student.model.model.res3.3.conv2.norm.bias', 'student.model.model.res4.5.conv1.norm.weight', 'losses.0.projector_0.norm.bias', 'losses.1.projector_1.ffn.2.weight', 'student.model.model.res3.3.conv3.weight', 'losses.1.projector_0.proj_student.1.weight', 'student.model.model.res2.0.conv3.norm.weight', 'losses.1.projector_0.proj_pos.0.bias', 'student.model.model.res3.1.conv1.norm.weight', 'student.model.model.res3.0.conv3.weight', 'student.model.model.res4.3.conv2.norm.weight', 'losses.1.projector_0.pos_attention.v.bias', 'student.model.model.res4.4.conv1.norm.bias', 'losses.1.projector_1.query.weight', 'student.model.model.stem.conv1.norm.weight', 'student.model.model.res4.1.conv2.norm.bias', 'student.model.model.res5.2.conv3.weight', 'student.model.model.res4.3.conv3.weight', 'student.model.model.res5.1.conv2.norm.weight', 'student.model.model.res4.2.conv2.weight', 'losses.1.projector_0.ffn.2.bias', 'student.model.model.res3.1.conv2.norm.weight', 'student.model.model.res2.0.conv3.norm.bias', 'student.model.model.res4.5.conv3.norm.weight', 'losses.0.projector_1.proj_pos.0.bias', 'student.model.model.res5.1.conv2.weight', 'student.model.model.res5.2.conv2.weight', 'student.feature_matchers.res5.matcher.0.bias', 'student.model.model.res5.1.conv2.norm.bias', 'losses.0.projector_0.pos_attention.q.weight', 'student.model.model.res4.5.conv3.norm.bias', 'student.model.model.res4.2.conv1.norm.bias', 'losses.1.projector_0.pos_embed', 'student.model.model.res3.2.conv3.weight', 'student.model.model.res4.0.shortcut.weight', 'losses.0.projector_0.proj_student.0.bias', 'student.model.model.res3.1.conv2.norm.bias', 'student.model.model.res2.0.conv1.norm.weight', 'student.model.model.res4.0.conv1.norm.weight', 'losses.1.projector_0.ffn.0.weight', 'losses.1.projector_1.pos_attention.k.bias', 'losses.1.projector_0.proj_student.0.weight', 'student.model.model.res2.2.conv2.norm.weight', 'student.model.model.res2.2.conv2.norm.bias', 'student.model.model.res4.4.conv3.norm.weight', 'losses.1.projector_1.pos_attention.q.weight', 'student.model.model.res2.0.shortcut.weight', 'student.model.model.res4.1.conv3.norm.weight', 'losses.0.projector_0.pos_attention.proj.weight', 'student.model.model.res3.0.conv1.norm.weight', 'student.model.model.res3.0.conv2.norm.weight', 'student.model.model.res4.1.conv2.norm.weight', 'student.model.model.res5.0.conv1.norm.weight', 'losses.0.projector_0.proj_student.1.bias', 'student.model.model.res3.0.conv3.norm.bias', 'student.model.model.res4.3.conv3.norm.weight', 'student.model.model.res5.2.conv1.norm.weight', 'student.model.model.res3.3.conv3.norm.weight', 'losses.0.projector_1.pos_attention.q.weight', 'losses.0.projector_0.proj_student.1.weight', 'student.model.model.res5.2.conv2.norm.bias', 'losses.1.projector_0.pos_attention.k.bias', 'losses.0.projector_1.pos_attention.proj.bias', 'student.model.model.res3.2.conv1.norm.bias', 'losses.1.projector_0.pos_attention.q.weight', 'student.model.model.res2.2.conv3.weight', 'losses.1.projector_1.proj_student.1.bias', 'student.model.model.res5.1.conv3.weight', 'student.model.model.res2.0.conv1.norm.bias', 'student.model.model.res4.1.conv3.weight', 'student.model.model.res4.5.conv1.weight', 'student.model.model.res3.1.conv1.norm.bias', 'student.model.model.res2.2.conv3.norm.weight', 'student.model.model.res2.0.conv2.norm.bias', 'student.model.model.res4.1.conv1.norm.weight', 'losses.0.projector_1.ffn.0.weight', 'losses.1.projector_0.proj_student.0.bias', 'student.model.model.res3.1.conv3.norm.bias', 'student.model.model.stem.conv1.weight', 'losses.1.projector_1.pos_attention.proj.weight', 'student.model.model.res4.3.conv1.norm.bias', 'student.model.model.res3.2.conv1.weight', 'student.model.model.res4.0.conv3.norm.weight', 'student.model.model.res5.0.conv1.norm.bias', 'losses.0.projector_1.ffn.0.bias', 'student.model.model.res4.2.conv1.norm.weight', 'losses.1.projector_1.pos_attention.proj.bias', 'student.model.model.res2.1.conv3.norm.weight', 'losses.0.projector_1.pos_attention.q.bias', 'student.model.mod
Used parameters: set()
