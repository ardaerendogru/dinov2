Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Starting training from scratch.
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name    | Type         | Params | Mode
-------------------------------------------------
0 | student | ModelWrapper | 28.8 M | train
1 | teacher | DINOv2ViT    | 86.6 M | eval
2 | losses  | ModuleList   | 132 M  | train
-------------------------------------------------
160 M     Trainable params
86.6 M    Non-trainable params
247 M     Total params
990.041   Total estimated model params size (MB)
232       Modules in train mode
212       Modules in eval mode
Epoch 0:   0%|                                                                                                                                | 0/1830 [00:00<?, ?it/s]Unused parameters: {'student.model.model.res2.0.conv1.norm.bias', 'student.model.model.res4.0.conv1.norm.bias', 'losses.0.projector_0.ffn.2.bias', 'losses.0.projector_0.ffn.0.bias', 'losses.1.projector_1.ffn.0.weight', 'losses.1.projector_1.pos_attention.q.bias', 'student.model.model.res4.2.conv3.weight', 'student.model.model.res2.2.conv1.norm.weight', 'student.model.model.res3.1.conv1.norm.bias', 'losses.1.projector_1.pos_attention.q.weight', 'losses.1.projector_0.ffn.2.bias', 'student.model.model.res4.4.conv3.norm.weight', 'student.model.model.res5.0.shortcut.norm.weight', 'student.model.model.res3.1.conv3.norm.bias', 'losses.0.projector_0.proj_student.1.weight', 'student.model.model.res3.1.conv3.norm.weight', 'losses.1.projector_0.proj_student.1.bias', 'student.model.model.res2.2.conv2.weight', 'student.model.model.res3.3.conv2.norm.bias', 'student.model.model.res4.2.conv2.norm.bias', 'student.model.model.res3.3.conv3.weight', 'student.model.model.res2.2.conv3.weight', 'student.model.model.res4.1.conv1.weight', 'student.model.model.res3.3.conv1.weight', 'student.model.model.res5.2.conv2.norm.bias', 'student.model.model.res4.3.conv2.norm.bias', 'losses.0.projector_1.pos_attention.proj.bias', 'student.model.model.res3.0.conv2.norm.bias', 'student.model.model.res4.5.conv2.norm.weight', 'student.model.model.res3.2.conv3.norm.bias', 'losses.1.projector_1.proj_student.0.bias', 'losses.0.projector_1.ffn.0.weight', 'losses.0.projector_0.norm.weight', 'student.model.model.res4.0.shortcut.norm.bias', 'student.model.model.res2.0.conv3.weight', 'losses.0.projector_1.proj_student.1.weight', 'student.model.model.res5.0.conv1.norm.weight', 'student.model.model.res4.4.conv1.norm.weight', 'losses.1.projector_1.query.weight', 'student.model.model.res3.0.conv3.norm.weight', 'student.model.model.res4.4.conv2.norm.weight', 'student.model.model.res5.2.conv3.norm.weight', 'losses.1.projector_1.pos_attention.k.weight', 'student.model.model.res4.0.conv3.norm.weight', 'student.model.model.res4.1.conv3.norm.weight', 'student.model.model.res4.2.conv2.norm.weight', 'student.model.model.res3.0.shortcut.weight', 'student.model.model.res4.0.conv2.norm.weight', 'student.model.model.res3.0.conv2.norm.weight', 'losses.0.projector_0.proj_student.0.weight', 'student.model.model.res4.0.conv1.weight', 'losses.1.projector_1.pos_attention.proj.bias', 'student.model.model.res4.0.conv2.weight', 'losses.0.projector_1.pos_attention.k.weight', 'student.model.model.res3.0.conv1.weight', 'student.model.model.res3.1.conv1.norm.weight', 'student.model.model.res2.0.shortcut.weight', 'student.model.model.res4.0.conv1.norm.weight', 'student.model.model.res2.0.conv3.norm.weight', 'losses.1.projector_1.proj_pos.0.bias', 'losses.1.projector_0.pos_attention.proj.weight', 'losses.1.projector_0.query.weight', 'losses.1.projector_1.norm.bias', 'losses.0.projector_1.pos_attention.q.bias', 'losses.1.projector_0.pos_attention.q.bias', 'student.model.model.res5.1.conv2.norm.bias', 'student.model.model.res2.2.conv1.norm.bias', 'student.model.model.res3.2.conv2.weight', 'student.model.model.res4.0.shortcut.weight', 'losses.0.projector_0.proj_student.0.bias', 'losses.1.projector_0.norm.weight', 'student.model.model.res5.1.conv3.norm.bias', 'losses.0.projector_1.proj_student.0.weight', 'losses.1.projector_1.pos_attention.v.bias', 'student.model.model.res4.0.conv2.norm.bias', 'student.model.model.res4.1.conv1.norm.bias', 'student.model.model.res4.4.conv3.norm.bias', 'student.model.model.res4.2.conv2.weight', 'losses.0.projector_0.proj_pos.0.bias', 'losses.0.projector_1.pos_attention.k.bias', 'losses.1.projector_0.proj_pos.0.weight', 'student.feature_matchers.res5.matcher.0.weight', 'losses.1.projector_0.pos_attention.v.bias', 'student.model.model.res4.3.conv3.norm.weight', 'student.model.model.res5.0.conv3.norm.weight', 'student.model.model.res5.0.conv1.norm.bias', 'student.model.model.res3.2.conv2.norm.weight', 'student.
Used parameters: set()
Epoch 0:   8%|████████▍                                                                                                   | 143/1830 [01:07<13:16,  2.12it/s, v_num=75]

Detected KeyboardInterrupt, attempting graceful shutdown ...
